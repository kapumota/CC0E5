{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f3be8c-1925-4f29-9051-4f39136ecb55",
   "metadata": {},
   "source": [
    "### **Práctica calificada 1-CC0E5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3baed-3ff9-4125-8732-027da26b4ff9",
   "metadata": {},
   "source": [
    "#### **Pregunta 1**\n",
    "\n",
    " \n",
    "Un **heater** es un caso especial de árbol de búsqueda con prioridades (a veces llamados *Cartesian trees*).  Cada nodo tiene  \n",
    "\n",
    "* una **clave de búsqueda** `key` generada de forma i.i.d. continua en el intervalo $[0,1]$;  \n",
    "* una **prioridad** única elegida por el usuario.  \n",
    "\n",
    "El árbol simultáneamente satisface :\n",
    "\n",
    "* la propiedad de **BST** (in-order por `key`), y  \n",
    "* la propiedad de **heap mínimo** sobre la prioridad.  \n",
    "\n",
    "Para los problemas (a)-(f) fijamos  \n",
    "\n",
    "* $n\\in\\mathbb N$ (tamaño del árbol),  \n",
    "* prioridades $1,2,\\dots ,n$ $\\bigl(1=\\min \\text{-prioridad}\\bigr)$.  \n",
    "\n",
    "Identificamos el nodo con prioridad $p$ como **nodo $p$**; así, el nodo 1 es la raíz de $T$.\n",
    "\n",
    "\n",
    "**(a) Probabilidad de adyacencia de $i$ y $j$ en una permutación aleatoria**\n",
    "\n",
    "Sea  \n",
    "$$\n",
    "S=\\{1,2,\\dots ,i,j\\}\\quad (i<j).\n",
    "$$  \n",
    "El número total de permutaciones es $(i+1)!$.\n",
    "\n",
    "Agrupemos los casos en los que $i$ y $j$ aparecen **adyacentes** (como $\\langle i,j\\rangle$ o $\\langle j,i\\rangle$).  \n",
    "1. Fijemos la pareja $[i,j]$ como un \"bloque\" indivisible. Entonces contamos:\n",
    "2. \n",
    "$$\n",
    "i!\\quad\\text{permutaciones}\n",
    "$$  \n",
    "de $i$ bloques (el bloque $[i,j]$ + los $i-1$ elementos restantes).  \n",
    "3. Análogamente para el bloque $[j,i]$.\n",
    "\n",
    "Por lo tanto el número de permutaciones \"buenas\" es $2\\cdot i!$. La probabilidad pedida es\n",
    "\n",
    "$$\n",
    "\\Pr\\bigl[\\text{$i$ y $j$ adyacentes}\\bigr]\n",
    "=\\frac{2\\,i!}{(i+1)!}\n",
    "=\\frac{2}{i+1}.\n",
    "$$\n",
    "\n",
    "\n",
    "**(b) Probabilidad de que $i$ sea ancestro de $j$**\n",
    "\n",
    "La construcción de un heater es idéntica a la del \"treap canónico\" si se invierten los roles de claves y prioridades:  \n",
    "\n",
    "* el **índice de prioridad** $p$ decide la altura: cuanto más pequeño, más arriba,  \n",
    "* las **claves** deciden el corte izquierda/derecha.\n",
    "\n",
    "Considera el sub-conjunto  \n",
    "$$\n",
    "A=\\{1,2,\\dots ,i,j\\}.\n",
    "$$  \n",
    "El nodo con prioridad mínima en $A$ (es decir, $1$) será la raíz del sub-árbol $T[A]$.  \n",
    "El nodo $i$ será **ancestro** de $j$ si:  \n",
    "\n",
    "1. $\\min\\{1,2,\\dots ,i-1\\}=1$ o, de manera equivalente, **ningún nodo con prioridad $\\le i$ distinto de $i$ cae entre las claves de $i$ y $j$**;  \n",
    "2. los nodos de prioridad estrictamente menor que $i$ se sitúan **todos** en el mismo lado (izq. o der.) de la clave de $i$.  \n",
    "\n",
    "Este suceso se modela exactamente con la siguiente observación clásica sobre árboles cartesianas:\n",
    "\n",
    "> **Lema** Sea $B\\subseteq \\{1,\\dots ,n\\}$ y $x,y\\in B$ con $\\text{prio}(x)<\\text{prio}(y)$. $x$ es ancestro de $y$ iff $x,y$ son **adyacentes** en la permutación de prioridades de $B$ ordenada de menor a mayor.  \n",
    "\n",
    "Aplicando el lema al conjunto $A$ y recordando el apartado (a):\n",
    "\n",
    "$$\n",
    "\\Pr\\bigl[\\text{$i$ ancestro de $j$}\\bigr]\n",
    "=\\Pr\\bigl[\\text{$i$ y $j$ adyacentes en una perm. de $A$}\\bigr]\n",
    "=\\frac{2}{i+1}.\n",
    "$$\n",
    "\n",
    "\n",
    "**(c) Probabilidad de que $i$ sea descendiente de $j$**\n",
    "\n",
    "El heap mínimo sobre prioridades impone  \n",
    "\n",
    "$$\n",
    "\\text{prio}(i)=i<j=\\text{prio}(j)\n",
    "\\;\\Longrightarrow\\;\n",
    "\\text{profundidad}(i)<\\text{profundidad}(j)\n",
    "$$  \n",
    "(i está **por encima** de $j$). Por lo tanto\n",
    "\n",
    "$$\n",
    "\\Pr\\bigl[\\text{$i$ descendiente de $j$}\\bigr]=0.\n",
    "$$\n",
    "\n",
    "Más formalmente, ningún nodo de prioridad baja puede violar la propiedad de heap estando debajo de una prioridad mayor; la distribución de claves no altera esa restricción vertical.\n",
    "\n",
    "\n",
    "**(d) Profundidad esperada exacta del nodo $j$**\n",
    "\n",
    "Sea la variable aleatoria\n",
    "\n",
    "$$\n",
    "D_j=\\bigl|\\{\\,i\\in\\{1,\\dots ,j-1\\}:\\text{$i$ ancestro de $j$}\\,\\}\\bigr|.\n",
    "$$\n",
    "\n",
    "Usando linealidad de la esperanza:\n",
    "\n",
    "$$\n",
    "\\mathbb E[D_j]\n",
    "=\\sum_{i=1}^{j-1} \\Pr[\\text{$i$ ancestro de $j$}]\n",
    "=\\sum_{i=1}^{j-1} \\frac{2}{i+1}.\n",
    "$$\n",
    "\n",
    "El sumatorio es el número armónico desplazado:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{j-1}\\frac{1}{i+1}\n",
    "=H_{j}-1, \n",
    "\\qquad\n",
    "H_{j}=1+\\tfrac12+\\tfrac13+\\cdots+\\tfrac1{j}.\n",
    "$$\n",
    "\n",
    "Por tanto\n",
    "\n",
    "$$\n",
    "\\boxed{\\;\n",
    "\\mathbb E[D_j]=2\\bigl(H_{j}-1\\bigr)=2H_{j}-2\\; }.\n",
    "$$\n",
    "\n",
    "Asintóticamente $H_j\\approx \\ln j+\\gamma$ ($\\gamma$ constante de Euler-Mascheroni), luego\n",
    "\n",
    "$$\n",
    "\\mathbb E[D_j]=2\\ln j+O(1).\n",
    "$$\n",
    "\n",
    "\n",
    "**Inserción de un nuevo nodo**\n",
    "\n",
    "La inserción en un heater se hace en dos fases, igual que en un treap tradicional:\n",
    "\n",
    "1. **Inserción BST** por la `key` generada al vuelo.  \n",
    "2. **Burbujeo** (*bubble-up*) mediante **rotaciones** hasta que se restaure la propiedad de heap por prioridad.\n",
    "\n",
    "La complejidad se controla observando que el número esperado de rotaciones = profundidad esperada del nodo justo antes de la fase 2.\n",
    "\n",
    "Sea $r$ el **rango** de la prioridad nueva (es decir, cuántas prioridades existentes son menores). Añadamos $p$ tal que $p=r+1$.  \n",
    "\n",
    "Por (d) con $j=p$:\n",
    "\n",
    "$$\n",
    "\\mathbb E[\\text{rotaciones}]\n",
    "= \\mathbb E[D_{p}]\n",
    "= 2H_{p}-2\n",
    "=O(\\log r).\n",
    "$$\n",
    "\n",
    "La búsqueda BST cuesta la misma cantidad en media. Resultado: tiempo esperado $O(\\log r)$.\n",
    "\n",
    "\n",
    "**(f) Eliminación del mínimo (pop-root)**\n",
    "\n",
    "Al igual que en **treaps**, se usa la operación *join* de dos sub-árboles $L$ y $R$ sabiendo que  \n",
    "$\\forall x\\in L, y\\in R: x.\\text{key}<y.\\text{key}$. La función `join(L,R)` devuelve un heater con todas las claves de $L\\cup R$.\n",
    "\n",
    "**Esquema de `join`**\n",
    "\n",
    "```text\n",
    "join(L, R):\n",
    "    si L == ∅: return R\n",
    "    si R == ∅: return L\n",
    "    if L.root.prio < R.root.prio:\n",
    "        L.right = join(L.right, R)\n",
    "        L.right.parent = L\n",
    "        return L\n",
    "    else:\n",
    "        R.left = join(L, R.left)\n",
    "        R.left.parent = R\n",
    "        return R\n",
    "```\n",
    "\n",
    "**Algoritmo `delete_min`**\n",
    "\n",
    "```python\n",
    "def delete_min(root):\n",
    "    L, R = root.left, root.right\n",
    "    if L: L.parent = None\n",
    "    if R: R.parent = None\n",
    "    new_root = join(L, R)\n",
    "    return new_root\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "El coste de `join` es la profundidad de la raíz con menor prioridad entre `L` y `R`. Sea $k$ la prioridad más pequeña $\\ge2$ que queda en el árbol: es el nuevo mínimo que subirá. Por la sección (d) con $j=k$ tenemos\n",
    "\n",
    "$$\n",
    "\\mathbb E[\\text{profundidad}(k)]\n",
    "=2H_k-2\n",
    "=O(\\log k)\n",
    "\\le O(\\log n).\n",
    "$$\n",
    "\n",
    "Además, la recursión de `join` baja monótonamente por claves, de modo que el número esperado de llamadas recursivas $\\approx\\mathbb E[\\text{profundidad}(k)]$. Por lo tanto\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{Tiempo esperado de }delete\\_min = O(\\log n).}\n",
    "$$\n",
    "\n",
    "En la práctica la constante es baja: para $k=2$, $E[D_2]=1$ => apenas una rotación media.\n",
    "\n",
    "\n",
    "**Dibujos**\n",
    "\n",
    "```\n",
    "Inserto nodo p=7 (prio 7, key=0.42)\n",
    "\n",
    "        (1,0.63)\n",
    "       /        \\\n",
    "  (5,0.20)     (2,0.85)\n",
    "                /\n",
    "          (7,0.42)   <- recién creado\n",
    "\n",
    "Bubble-up paso 1: rotación izquierda sobre (2)\n",
    "\n",
    "        (1,0.63)\n",
    "       /        \\\n",
    "  (5,0.20)     (7,0.42)\n",
    "                      \\\n",
    "                     (2,0.85)\n",
    "Bubble-up termina: prio(7)=7>1 y <2 ⇒ heap ok\n",
    "```\n",
    "\n",
    "> Derivación analítica del *bubble-up* esperado\n",
    "\n",
    "Sea $r=\\text{prio}(x)-1$.  \n",
    "La probabilidad de que cualquier nodo más pequeño que $x$ sea ancestro es $2/(i+1)$ por (b), de ahí:\n",
    "\n",
    "$$\n",
    "\\mathbb E[\\text{Rotaciones bubble-up}]\n",
    "=\\sum_{i=1}^{r} \\frac{2}{i+1}\n",
    "= 2\\bigl(H_{r+1}-1\\bigr)\n",
    "\\in \\Theta(\\log r).\n",
    "$$\n",
    "\n",
    "El mismo cálculo vale para la fase de búsqueda previa. Por lo tanto la inserción conserva el \"log-esperado\" característico de los árboles cartesianos.\n",
    "\n",
    "**Diagrama resumido del flujo de operaciones**\n",
    "\n",
    "```\n",
    "digraph HeaterOps {\n",
    "  node [shape=box];\n",
    "  Insert -> {BST_search BubbleUp}\n",
    "  DeleteMin -> {SplitLeftRight Join}\n",
    "  BubbleUp -> {RotateLeft|RotateRight}\n",
    "  Join -> {RecurseLeft RecurseRight}\n",
    "}\n",
    "```\n",
    "\n",
    "Este grafo captura las dependencias de alto nivel entre las rutinas empleadas.\n",
    "\n",
    "Además\n",
    "\n",
    "\n",
    "$$\n",
    "H_n = \\sum_{k=1}^{n}\\frac1k, \\qquad\n",
    "H_n = \\ln n + \\gamma + \\frac{1}{2n} - O\\!\\bigl(\\tfrac1{12n^2}\\bigr).\n",
    "$$\n",
    "\n",
    "De aquí se desprenden las cotas asintóticas:  \n",
    "\n",
    "* Profundidad esperada de cualquier nodo = $\\Theta(\\log n)$.  \n",
    "* Inserción / eliminación mínima = $\\Theta(\\log n)$ en esperanza.  \n",
    "\n",
    "La \"antitesis\" respecto a los treaps clásicos (donde tanto claves como prioridades son i.i.d.) es que los heaters conservan rendimiento logarítmico, pero la **varianza** se dispara: la raíz es siempre el mismo nodo, y las trayectorias de búsqueda tienden a ser más desbalanceadas (cola pesada). Aun así, los valores medios dependen del armónico y siguen siendo sub-lineales, como se ha demostrado en los apartados anteriores.\n",
    "\n",
    "**(g) Invariante del heap.**\n",
    "\n",
    "\n",
    "Sea $T$ un treap sobre pares $(\\mathit{key},\\mathit{priority})$. Definimos:\n",
    "\n",
    "1. **BST (Search-Tree Invariant)**  \n",
    "   $$\n",
    "     \\forall\\,n\\in T:\\quad\n",
    "       \\bigl(\\forall x\\in\\mathit{left}(n):x.key \\le n.key\\bigr)\n",
    "     \\;\\wedge\\;\n",
    "       \\bigl(\\forall x\\in\\mathit{right}(n):x.key > n.key\\bigr).\n",
    "   $$\n",
    "\n",
    "2. **Min-Heap (Heap Invariant)**  \n",
    "   $$\n",
    "     \\forall\\,n\\in T,\\;n\\neq\\mathit{root}:\\quad\n",
    "       n.priority \\;\\ge\\; n.parent.priority.\n",
    "   $$\n",
    "\n",
    "Antes de llamar a `update_priority`, suponemos que ambas invariantes se cumplen en todo $T$.\n",
    "\n",
    "\n",
    "Al invocar `update_priority(new_priority)` en un nodo $u$:\n",
    "\n",
    "1. **Asignación de prioridad**  \n",
    "   Se sobreescribe  \n",
    "   $$\n",
    "     \\mathit{old\\_pr} := u.priority\n",
    "     \\quad\\longrightarrow\\quad\n",
    "     u.priority := \\mathit{new\\_pr}.\n",
    "   $$\n",
    "   Esto no altera claves, de modo que la **invariante BST** sigue válida inmediatamente tras el cambio de prioridad.\n",
    "\n",
    "   Sin embargo, tras cambiar la prioridad pueden violarse:\n",
    "   - Con los **ancestros** (si $\\mathit{new\\_pr}<\\text{pr}\\bigl(u.parent\\bigr)$).\n",
    "   - Con los **descendientes** (si algún hijo tiene $\\mathit{child.priority}<\\mathit{new\\_pr}$).\n",
    "\n",
    "2. **Fase \"Bubble-up\"**  \n",
    "   Mientras $u$ tenga padre y $u.priority < u.parent.priority$, rotamos $u$ hacia arriba (rotación derecha o izquierda según sea hijo izquierdo o derecho).  \n",
    "   - Cada **rotación** local es un reacomodo de subárboles que **preserva** el orden in-order (y por tanto la invariante BST).  \n",
    "   - Además, tras cada rotación $u$ queda en un nivel más alto, acercándolo a la raíz, y corrige esa violación de heap con sus ancestros.\n",
    "\n",
    "   Al término de esta fase, **no quedan** violaciones de heap entre $u$ y **ninguno** de sus ancestros.\n",
    "\n",
    "3. **Fase \"Push-down\"**  \n",
    "   Ahora iteramos mientras exista algún hijo $c$ de $u$ con $c.priority < u.priority$:\n",
    "   - Si $u.left.priority < u.priority$ rotamos a la derecha,  \n",
    "   - Si $u.right.priority < u.priority$ rotamos a la izquierda.  \n",
    "   Cada rotación preserva el in-order ( BST ) y reduce las violaciones de heap con los **descendientes**.\n",
    "\n",
    "   Al acabar, $u$ ya no viola heap ni con sus ancestros (porque no sube más) ni con sus hijos (porque ya no baja más).\n",
    "\n",
    "Por composición, **tras ambas fases**:\n",
    "\n",
    "- Las **claves** no se han movido en sentido que rompa el in-order global, luego la invariante BST se mantiene.\n",
    "- Tanto ancestros como descendientes verifican ahora la propiedad de prioridad, de modo que la invariante de min-heap está restaurada.\n",
    "\n",
    "\n",
    "**Contra-ejemplo sin la fase bubble-up**\n",
    "\n",
    "Supongamos que **omitimos** todo el paso de \"bubble-up\" y solo hacemos \"push-down\". Consideremos este treap pequeño, inicialmente válido:\n",
    "\n",
    "```\n",
    "       (key=2, pr=1)\n",
    "       /           \\\n",
    " (key=1, pr=2)  (key=3, pr=3)\n",
    "```\n",
    "\n",
    "- **BST**: $1\\le2<3$.  \n",
    "- **Heap**: $1\\le2$ y $1\\le3$.\n",
    "\n",
    "Ahora ejecutamos `update_priority` sobre el nodo $\\,(key=1)$, cambiando su prioridad de 2 a 0:\n",
    "\n",
    "1. **Asignación**: el nodo pasa a $(key=1, pr=0)$.  \n",
    "2. **(Sin bubble-up)** salta directo al \"push-down\".  \n",
    "   - Pero $(key=1)$ no tiene hijos, así que no rota.  \n",
    "3. El resultado **queda**:\n",
    "\n",
    "```\n",
    "       (key=2, pr=1)\n",
    "       /\n",
    " (key=1, pr=0)\n",
    "        \\\n",
    "       (ninguno)\n",
    "```\n",
    "\n",
    "Ahora la invariante de heap **se viola**, pues el hijo tiene $\\,0<1$, es decir, un nodo con prioridad mayor (0) está **por debajo** de uno con prioridad menor (1).\n",
    "\n",
    "> **Violación**: el padre $(pr=1)$ ya no es ≤ que el hijo $(pr=0)$.\n",
    "\n",
    "Este ejemplo muestra que, sin la fase de *bubble-up*, bastaría con rebajar la prioridad de un nodo a un valor menor que su ancestro para romper la propiedad de min-heap.\n",
    "\n",
    "  \n",
    "**(h)Concurrencia**\n",
    "\n",
    "El treap implementado emplea un `threading.RLock` para garantizar que las operaciones públicas (`add`, `remove_key`, etc.) no se interrumpan mutuamente. Sin embargo, si elimináramos ese candado, dos hilos inesperadamente podrían entrelazar sus acciones y dejar la estructura interna del árbol en un estado inconsistente o incluso corrupto.\n",
    "\n",
    "**Descripción de la sección crítica**\n",
    "\n",
    "La zona crítica principal es el punto donde un hilo:\n",
    "\n",
    "1. Desciende recursivamente o por rotaciones y actualiza punteros hijo/padre.  \n",
    "2. Ajusta la referencia `treap.root` al rotar en la raíz.  \n",
    "\n",
    "Sin sincronización, dos hilos pueden sobreescribir punteros parciales o mezclar subárboles. El invariant principal que se viola es:  \n",
    "> **BST**: para cada nodo `x`, todos los de la izquierda < `x.key` y todos los de la derecha > `x.key`.  \n",
    "> **Heap (min-heap)** en prioridades: cada hijo tiene prioridad ≥ la de su padre.  \n",
    "\n",
    "**Escenario de carrera propuesto**\n",
    "\n",
    "Imaginemos un Treap inicialmente con tres nodos:\n",
    "\n",
    "```\n",
    "       (10│p=10)\n",
    "       /       \\\n",
    "   (5│p=5)   (15│p=15)\n",
    "```\n",
    "\n",
    "Los números antes de la barra son claves, los de `p=` prioridades (menor -> más \"alto\" en el heap).  \n",
    "\n",
    "Queremos correr **concurrentemente**:\n",
    "\n",
    "- **Hilo A**: inserta `(7│p=7)`  \n",
    "- **Hilo B**: elimina la clave `5` con prioridad `5`  \n",
    "\n",
    "Supongamos que la inserción de A provoca una **rotación** a la izquierda en `(5│p=5)` porque el nuevo nodo `(7│p=7)` tiene prioridad menor (7 < 5 no es cierto, pero para el ejemplo supongamos prioridades invertidas o un escenario análogo con rotación derecha). Lo importante es que A invoca:\n",
    "```pseudocode\n",
    "# Dentro de _TreapNode.rotate_left(treap)\n",
    "y = self.right             # y apunta a (7│p=7)\n",
    "self.right = y.left        # reasigna puntero\n",
    "y.left = self              # reestructura hijos\n",
    "...\n",
    "if self.parent is None:\n",
    "    treap.root = y\n",
    "else:\n",
    "    # ajusta self.parent.left/right\n",
    "```\n",
    "\n",
    "Mientras tanto, B hace:\n",
    "```pseudocode\n",
    "# Dentro de remove_key(key)\n",
    "node = root.search(target_key=5)           # localiza (5│p=5)\n",
    "new_root, deleted = root._remove(5,5,treap)  \n",
    "treap.root = new_root                      # reasigna raíz\n",
    "```\n",
    "\n",
    "**Pseudocódigo simplificado de los hilos**\n",
    "\n",
    "```pseudocode\n",
    "// Sin RLock: ambos hilos actúan simultáneamente\n",
    "\n",
    "// Hilo A: inserta y rota\n",
    "function hiloA(treap):\n",
    "    entry = TreapEntry(7, 7)\n",
    "    treap.root.add(entry.key, entry.priority, treap)\n",
    "    // Durante add, llega a rotate_left en nodo (5)\n",
    "\n",
    "// Hilo B: elimina\n",
    "function hiloB(treap):\n",
    "    // Podría llegar aquí justo cuando A está reestructurando\n",
    "    treap.remove_key(5)\n",
    "```\n",
    "\n",
    "**Diagrama de tiempo (Time-Line)**\n",
    "\n",
    "```text\n",
    "Tiempo ->\n",
    "\n",
    "T0:   Estado inicial:\n",
    "        treap.root = (10)\n",
    "                   /    \\\n",
    "                (5)    (15)\n",
    "\n",
    "T1:   A: entra en add(7,7) en subárbol izquierdo de (10)\n",
    "      B: comienza remove_key(5)\n",
    "\n",
    "// A desciende hasta (5), B llama a search(5) simultáneo\n",
    "T2:   A: en nodo (5): self.right = None? No, hay subárbol potencial\n",
    "      A: decide insertar (7) como hijo derecho de (5)\n",
    "      A: crea nodo y enlace:\n",
    "           (5).right --> (7)\n",
    "      A: ahora prioridad(7) < prioridad(5)? (supongamos sí)\n",
    "T3:   A: llama a rotate_left en (5)\n",
    "      -- tänner: comienza rotate_left sin terminar --\n",
    "      A: y = self.right       // y=(7)\n",
    "      A: self.right = y.left  // y.left=None, bien\n",
    "      A: y.left = self        // vincula (5) como hijo izquierdo de (7)\n",
    "T4:   B: en medio de la rotación A, B también entra en remove_key:\n",
    "      B: find target = search(5) <--encuentra el nodo original (5)\n",
    "      B: invoca _remove en (5)\n",
    "      B: detecta self.left o self.right y decide reestructurar\n",
    "// B modifica punteros de (5) mientras A no ha acabado su rotate_left\n",
    "T5:   A: retoma rotate_left:\n",
    "      A: if self.parent is None: treap.root = y\n",
    "      A: self.parent = y\n",
    "T6:   B: tras _remove, asigna treap.root = new_subtree\n",
    "      // pisando la asignación de A a treap.root\n",
    "\n",
    "T7:   Estado final corrupto:\n",
    "      - Algunas referencias de padre/hijo apuntan a nodos \"fantasma\"\n",
    "      - El subárbol izquierdo de (10) podría quedar a medias\n",
    "      - check_treap_invariants() falla o recorre en bucle\n",
    "```\n",
    "\n",
    "**Explicación**  \n",
    "1. **T3-T4**: A está en medio de la rotación: ya cambió `self.right`, pero no ha terminado de reasignar `parent` y `treap.root`.  \n",
    "2. **T4-T6**: B encuentra el mismo nodo en un estado intermedio (clave 5 con hijos parcialmente cambiados) y aplica `_remove`, reconfigurando punteros `parent` y `root`.  \n",
    "3. Cuando A retoma, sobreescribe `treap.root` sin conocer el trabajo de B, y algunos hijos apuntan a `parent` viejo, generando hiperenlaces o nodos huérfanos.  \n",
    "\n",
    ":::note\n",
    "**Clave**: sin `RLock`, las secciones de relectura y escritura de punteros quedan expuestas a interleavings arbitrarios que violan los invariantes BST y heap.\n",
    ":::\n",
    "\n",
    "\n",
    "**(i) Pruebas automatizadas con pytest y coste experimental**\n",
    "\n",
    "Ahora implementamos un test parametrizado que, para cada $k=1,\\dots,10^4$:\n",
    "\n",
    "1. Inserta $k$ claves aleatorias con prioridades estrictamente crecientes (de 1 a $k$).  \n",
    "2. Verifica que `treap.check_treap_invariants()` devuelve `True`.\n",
    "\n",
    "**Código de test parametrizado**\n",
    "\n",
    "```python\n",
    "\n",
    "import pytest\n",
    "import random\n",
    "#from treap_module import Treap, TreapEntry  # asume tu Treap está en treap_module.py\n",
    "\n",
    "# Fijamos semilla para reproducibilidad\n",
    "SEED = 12345\n",
    "\n",
    "@pytest.mark.parametrize(\"k\", range(1, 10_001))\n",
    "def test_invariants_after_inserts(k):\n",
    "    \"\"\"\n",
    "    Para cada k en [1..10000], \n",
    "    inserta k claves aleatorias con prioridades crecientes y\n",
    "    comprueba que se mantienen los invariantes del Treap.\n",
    "    \"\"\"\n",
    "    random.seed(SEED + k)  # distinta muestra por valor de k\n",
    "    t = Treap[int, int]()\n",
    "    # Generamos k claves únicas en un rango amplio\n",
    "    keys = random.sample(range(1, 10**7), k)\n",
    "    # Insertamos con prioridades 1..k (estrictamente crecientes)\n",
    "    for priority, key in enumerate(keys, start=1):\n",
    "        entry = TreapEntry(key, priority)\n",
    "        added = t.add(entry)\n",
    "        assert added, f\"Fallo al insertar entrada {entry.key}|{entry.priority}\"\n",
    "    # Tras todas las inserciones, verificamos BST+Heap\n",
    "    assert t.check_treap_invariants(), f\"Invariante Treap violado para k={k}\"\n",
    "```\n",
    "\n",
    "**Detalles del test**\n",
    "\n",
    "- **Parametrización**:  \n",
    "  - `@pytest.mark.parametrize(\"k\", range(1, 10_001))` genera 10 000 ejecuciones independientes.  \n",
    "- **Reproducibilidad**:  \n",
    "  - Se usa `random.seed(SEED + k)` para que cada `k` produzca siempre el mismo conjunto de claves, evitando falsos fallos debidos a muestras adversas fortuitas.  \n",
    "- **Prioridades crecientes**:  \n",
    "  - Al asignar prioridad $i$ a la $i$-ésima clave insertada, garantizamos que nunca se produzca una \"burbujeo\" hacia arriba (bubble-up) tras la inserción, simplificando la forma del árbol, pero aún así se pueden formar rotaciones por la combinación clave vs. posición.  \n",
    "- **Assertions**:  \n",
    "  - Se comprueba `added == True` (aunque en tu implementación `add` siempre retorna `True`).  \n",
    "  - Se comprueba finalmente `check_treap_invariants()` y reporta en qué `k` falló, en caso de violación.\n",
    "\n",
    "**Análisis del coste experimental**\n",
    "\n",
    "Para entender el tiempo que tardará esta suite:\n",
    "\n",
    "1. **Costo por un solo k**  \n",
    "   - **Inserciones**: cada `add` tarda $O(\\log n)$ amortizado (altura esperada del Treap $\\approx O(\\log n)$).  \n",
    "     - Total de inserciones: $\\sum_{i=1}^k O(\\log i) \\in O(k \\log k)$.  \n",
    "   - **Chequeo de invariantes**: recorre todos los nodos exactamente una vez: $O(k)$.  \n",
    "   - **Total para un valor k**:  \n",
    "     $$\n",
    "       T(k) = O(k \\log k) + O(k) \\;=\\; O(k \\log k).\n",
    "     $$\n",
    "\n",
    "2. **Costo agregado sobre k = 1..N**  \n",
    "   $$\n",
    "     \\sum_{k=1}^{N} T(k)\n",
    "     \\;\\approx\\;\\sum_{k=1}^{N} O(k \\log k)\n",
    "     \\;=\\;O\\!\\Bigl(\\sum_{k=1}^N k \\log k\\Bigr).\n",
    "   $$\n",
    "   Usando aproximación integral:\n",
    "   $$\n",
    "     \\sum_{k=1}^N k \\log k\n",
    "     \\approx \\int_1^N x \\log x \\,dx\n",
    "     = \\left[\\tfrac{x^2}{2}\\log x - \\tfrac{x^2}{4}\\right]_1^N\n",
    "     = \\frac{N^2}{2}\\log N - \\frac{N^2}{4} + O(1).\n",
    "   $$\n",
    "   Por lo tanto:\n",
    "   $$\n",
    "     \\sum_{k=1}^N T(k)\n",
    "     = O\\bigl(N^2 \\log N\\bigr).\n",
    "   $$\n",
    "\n",
    "3. **Estimación numérica**  \n",
    "   - Con $N = 10^4$:  \n",
    "     $$\n",
    "       \\frac{N^2}{2}\\log_2 N \\approx \\frac{10^8}{2}\\times 13.3 \\approx 6.65\\times 10^8 \n",
    "     $$\n",
    "     operaciones de comparación/rotación.  \n",
    "   - Suponiendo que cada operación de inserción (un nivel de árbol) consume unos $0.1$ µs en Python puro (optimista):  \n",
    "     $$\n",
    "       6.65\\times 10^8 \\times 0.1\\;\\mu s\n",
    "       = 6.65\\times 10^7\\;\\mu s\n",
    "       = 66.5\\;s\n",
    "     $$\n",
    "     a lo que hay que añadir la sobrecarga de pytest (creación de fixtures, parametrización, reporting), que fácilmente puede multiplicar por $1.5$–$2$.  \n",
    "   - **Tiempo total esperado**: entre **1 y 2 minutos** en hardware típico de desarrollo.  \n",
    "\n",
    "4. **Conclusiones del análisis de coste**  \n",
    "   - La parametrización **directa** de 10 000 casos individuales es **muy costosa**.  \n",
    "   - Alternativas para acelerar:  \n",
    "     - Reducir la muestra de $k$ (por ejemplo, probar sólo potencias de 2 o saltos mayores).  \n",
    "     - Combinar varios $k$ en una sola ejecución de test (usar bucle interno en vez de `@parametrize`).  \n",
    "     - Paralelizar con `pytest-xdist` (opción `-n auto`) si se dispone de varios núcleos.  \n",
    "\n",
    "**(j) Familia de entrada de altura lineal**\n",
    "\n",
    "Sea  \n",
    "$$\n",
    "(\\text{key}_i,\\ \\text{priority}_i)=(i,\\;i)\\qquad i=1,\\dots,n .\n",
    "$$\n",
    "\n",
    "* Claves estrictamente crecientes => cada nodo nuevo se inserta como **hijo derecho** del anterior (propiedad BST).\n",
    "* Prioridades también crecientes => `priority_{i}` nunca es **más alta** (recuerda: \"más alta\" significa numéricamente **menor**) que la de su padre, por lo que **no se ejecuta ninguna rotación** durante `add`.\n",
    "\n",
    "El resultado es una cadena:\n",
    "\n",
    "```text\n",
    "(1,1)\n",
    "   \\\n",
    "  (2,2)\n",
    "     \\\n",
    "    (3,3)\n",
    "       \\\n",
    "       ...\n",
    "          \\\n",
    "         (n,n)\n",
    "```\n",
    "\n",
    "Altura `h(n)=n`.  \n",
    "Esta secuencia **elimina la aleatorización** que normalmente balancea al treap porque:\n",
    "\n",
    "1. El algoritmo espera que las prioridades formen una permutación aleatoria independiente de las claves.  \n",
    "2. Al elegir prioridades **monótonamente crecientes** y correlacionadas con el orden de inserción, simulamos el peor caso de un BST puro, impidiendo las rotaciones que mezclarían la estructura.\n",
    "\n",
    "De forma equivalente, suministrar claves crecientes y prioridades decrecientes. Por ejemplo `(i, n−i)` genera un camino lineal por el lado izquierdo.\n",
    "\n",
    "> En ambos casos la estructura resultante alcanza la complejidad $O(n)$ en altura y degrada las operaciones de búsqueda, inserción y borrado al peor caso $\\Theta(n)$.\n",
    "\n",
    "**(k) Extensión de la API**\n",
    "\n",
    "Sea una operación de **split**, que dado un Treap `T` y una clave `k`, devuelve dos Treaps:\n",
    "\n",
    "- `L` con todas las claves ≤ `k`,  \n",
    "- `R` con todas las claves >  `k`.\n",
    "\n",
    "\n",
    "La operación `split(T, k)` sobre un treap recursivo se basa en la siguiente intuición:\n",
    "\n",
    "1. **Caso base**: si `T` está vacío, devolvemos dos treaps vacíos  \n",
    "2. Si `T.root.key ≤ k`, entonces **todo el subárbol izquierdo** de la raíz cumple $\\leq k$, pero en el subárbol derecho hay claves que pueden ser $\\leq $ `k` o > `k`.  \n",
    "   - Recurre sobre el subárbol derecho:  \n",
    "     $$\n",
    "       (L', R) \\;=\\; \\mathrm{split}(T.\\mathrm{right},\\;k)\n",
    "     $$\n",
    "   - Después, el nuevo treap de \"izquierda\" combina la raíz con su subárbol izquierdo **original** y con `L'`.  \n",
    "   - El treap de \"derecha\" es simplemente `R`.  \n",
    "3. Si `T.root.key > k`, entonces **todo el subárbol derecho** de la raíz es > `k`, pero en el subárbol izquierdo hay claves $\\leq$ `k` o > `k`.  \n",
    "   - Recurre sobre el subárbol izquierdo:  \n",
    "     $$\n",
    "       (L,\\;R') \\;=\\; \\mathrm{split}(T.\\mathrm{left},\\;k)\n",
    "     $$\n",
    "   - El treap \"derecha\" combina la raíz con su subárbol derecho original y con `R'`.  \n",
    "   - El treap \"izquierda\" es `L`.  \n",
    "\n",
    "**Pseudocódigo**\n",
    "\n",
    "```pseudocode\n",
    "function SPLIT(node, k):\n",
    "    if node is None:\n",
    "        return (None, None)\n",
    "\n",
    "    if node.key ≤ k:\n",
    "        // Particionamos el subárbol derecho\n",
    "        (L_sub, R) = SPLIT(node.right, k)\n",
    "        node.right = L_sub\n",
    "        if L_sub ≠ None:\n",
    "            L_sub.parent = node\n",
    "        // El Treap izquierdo es \"node\" con su parte derecha ajustada\n",
    "        return (node, R)\n",
    "    else:\n",
    "        // node.key > k: particionamos el subárbol izquierdo\n",
    "        (L, R_sub) = SPLIT(node.left, k)\n",
    "        node.left = R_sub\n",
    "        if R_sub ≠ None:\n",
    "            R_sub.parent = node\n",
    "        // El Treap derecho es \"node\" con su parte izquierda ajustada\n",
    "        return (L, node)\n",
    "```\n",
    "\n",
    "Al final, hay que envolver estos nodos raíz resultantes en dos objetos `Treap` independientes, fijando los `parent=None` de las nuevas raíces.\n",
    "\n",
    "\n",
    "A continuación, integramos `split` como método estático externo (podría también pertenecer a la clase `Treap`) que trabaja directamente con nodos internos y luego construye dos instancias `Treap`.\n",
    "\n",
    "```python\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def split_treap(t: Treap[T, S], key: T) -> Tuple[Treap[T, S], Treap[T, S]]:\n",
    "    \"\"\"\n",
    "    Separa el Treap t en dos:\n",
    "      - left_tree: todas las claves ≤ key\n",
    "      - right_tree: todas las claves > key\n",
    "    Returns (left_tree, right_tree).\n",
    "    \"\"\"\n",
    "\n",
    "    def _split_node(node: Optional[Treap._TreapNode], key: T\n",
    "                   ) -> Tuple[Optional[Treap._TreapNode], Optional[Treap._TreapNode]]:\n",
    "        if node is None:\n",
    "            return (None, None)\n",
    "\n",
    "        if node.key <= key:\n",
    "            # Clave de la raíz va a la parte izquierda\n",
    "            left_sub, right_sub = _split_node(node.right, key)\n",
    "            node.right = left_sub\n",
    "            if left_sub is not None:\n",
    "                left_sub.parent = node\n",
    "            # Asegurar que la nueva raíz de la parte derecha ya no apunta a padre\n",
    "            if right_sub is not None:\n",
    "                right_sub.parent = None\n",
    "            node.parent = None\n",
    "            return (node, right_sub)\n",
    "        else:\n",
    "            # Clave de la raíz va a la parte derecha\n",
    "            left_sub, right_sub = _split_node(node.left, key)\n",
    "            node.left = right_sub\n",
    "            if right_sub is not None:\n",
    "                right_sub.parent = node\n",
    "            if left_sub is not None:\n",
    "                left_sub.parent = None\n",
    "            node.parent = None\n",
    "            return (left_sub, node)\n",
    "\n",
    "    # Ejecutar el split recursivo sobre la raíz original\n",
    "    with t._lock:\n",
    "        left_root, right_root = _split_node(t.root, key)\n",
    "\n",
    "    # Construir dos Treaps nuevos\n",
    "    left_tree = Treap[T, S]()\n",
    "    right_tree = Treap[T, S]()\n",
    "    left_tree.root = left_root\n",
    "    right_tree.root = right_root\n",
    "    return (left_tree, right_tree)\n",
    "```\n",
    "\n",
    "**Notas de implementación**:\n",
    "\n",
    "- Se hace `with t._lock` para proteger la lectura de `t.root` aunque estemos construyendo dos nuevas estructuras inmutables para `t`.\n",
    "- Cada subárbol resultante desconecta su `parent` de niveles superiores.\n",
    "- Las prioridades no se tocan; el split únicamente usa la clave para particionar sin alterar el heap de prioridades.\n",
    "\n",
    "\n",
    "Durante cada recursión:\n",
    "\n",
    "- Cuando movemos `node.right = left_sub`, **actualizamos** `left_sub.parent = node`.  \n",
    "- Cuando retornamos `right_sub` como raíz de la parte derecha, **limpiamos** `right_sub.parent = None` para marcarlo como raíz.\n",
    "- De igual manera en el caso simétrico al asignar `node.left = right_sub`.\n",
    "\n",
    "Este cuidadoso manejo de `parent` garantiza que al terminar tengamos dos árboles **válidos** con padres correctamente asignados o nulos en las raíces.\n",
    "\n",
    "\n",
    "**Invariantes mantenidos tras el split**\n",
    "\n",
    "1. **Propiedad BST**:  \n",
    "   - Todas las claves en `left_tree` satisfacen $\\leq$ `key`, pues:\n",
    "     - Si `node.key <= key`, la raíz va en `left_tree`, y las claves de su subárbol izquierdo eran $\\leq$ `node.key`.  \n",
    "     - Al recursar en `node.right`, sólo extraemos de allí nodos $\\leq$ `key`.  \n",
    "   - Simétricamente para `right_tree`.\n",
    "\n",
    "2. **Propiedad heap**:  \n",
    "   - No se altera el campo `priority` ni las rotaciones: cada subárbol mantiene las relaciones padre-hijo de heap.  \n",
    "   - El proceso no rompe el mínimo-heap, pues no se comparan prioridades; únicamente se reencadenan punteros.\n",
    "\n",
    "\n",
    "**Análisis de complejidad esperada**\n",
    "\n",
    "Sea $n$ el número de nodos del Treap original. En un Treap aleatorizado:\n",
    "\n",
    "- La **altura esperada** es $O(\\log n)$.  \n",
    "- Cada llamada recursiva baja un nivel en el camino hacia la clave de split, recorriendo a lo sumo un único camino desde la raíz hasta una hoja.  \n",
    "\n",
    "Por tanto, el número de llamadas recursivas y reasignaciones de puntero es proporcional a la **profundidad** de la clave de partición, es decir, $O(h)$ donde $h$ es la altura del Treap.\n",
    "\n",
    "> **Conclusión**: la complejidad esperada de `split` es **$O(\\log n)$**.\n",
    "\n",
    "En el peor caso adversarial (árbol muy desbalanceado), podría degenerar a $O(n)$, pero las propiedades aleatorias de prioridad aseguran que casi seguro no veamos este caso.\n",
    "\n",
    "**Ejemplo paso a paso**\n",
    "\n",
    "Supongamos el treap:\n",
    "\n",
    "```\n",
    "        (10│p=50)\n",
    "        /       \\\n",
    "   (5│p=80)    (15│p=30)\n",
    "     /   \\        \\\n",
    "(2│p=90)(7│p=40) (20│p=60)\n",
    "```\n",
    "\n",
    "y hacemos `split(T, key=7)`:\n",
    "\n",
    "1. **Raíz = 10**, 10 > 7 -> entramos en rama izquierda:  \n",
    "   - Recursión: `_split_node(node=5, key=7)`.\n",
    "2. **Nodo=5**, 5 ≤ 7 -> rama derecha:  \n",
    "   - Recursión: `_split_node(node=7, key=7)`.\n",
    "3. **Nodo=7**, 7 ≤ 7 -> rama derecha:  \n",
    "   - Recursión: `_split_node(node=None, key=7)` -> devuelve `(None, None)`.\n",
    "   - Asigna `7.right = None`, retorna `(7, None)`.\n",
    "4. Volviendo a nodo = 5:  \n",
    "   - Recibimos `(L′=7, R=None)`.  \n",
    "   - Asignamos `5.right = 7` (ya estaba así) y `7.parent = 5`.  \n",
    "   - Retornamos `(5, None?)` pero **ojo**: la parte derecha que retorna es `R = None`.  \n",
    "   - En realidad, queremos `(node=5, R=None)`.\n",
    "5. Volviendo a raíz =10:  \n",
    "   - Recibimos `(L=5, R_sub=None)`.  \n",
    "   - Asignamos `10.left = None` (se suelta el 5 original), `None.parent = 10` omitido.  \n",
    "   - Retornamos `(L=5, node=10)`.\n",
    "6. **Construcción de los treaps**:  \n",
    "   - `left_tree.root = 5` produce:\n",
    "     ```\n",
    "       5\n",
    "      / \\\n",
    "     2   7\n",
    "     ```\n",
    "   - `right_tree.root = 10` produce:\n",
    "     ```\n",
    "      10\n",
    "        \\\n",
    "        15\n",
    "          \\\n",
    "          20\n",
    "     ```\n",
    "\n",
    "Ambos cumplen BST y heap.\n",
    "\n",
    "**Casos extremos**\n",
    "\n",
    "- **Splitting en `key` menor que la mínima**:  \n",
    "  - Todo va a `right_tree`, `left_tree` queda vacío.  \n",
    "- **Splitting en `key` mayor que la máxima**:  \n",
    "  - Todo va a `left_tree`, `right_tree` queda vacío.  \n",
    "- **Duplicados de clave** (si permites duplicados):  \n",
    "  - Se define si `<= key` va a la izquierda. Puedes adaptar la comparación `node.key <= key` para decidir dónde cae cada igualdad.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059abf5a-c479-4ad4-b765-c581076651d7",
   "metadata": {},
   "source": [
    "#### **Pregunta 2**\n",
    "\n",
    "**(a) Complejidad $O(k)$ en inserción y consulta**  \n",
    "\n",
    "Un Bloom filter de tamaño $m$ bits y con $k$ funciones de hash inserta o consulta un elemento ejecutando exactamente $k$ pasos de lectura/escritura de bits, por lo que, en el modelo de costo de operaciones de bits constantes, ambas operaciones tienen complejidad  \n",
    "$$\n",
    "T_{\\text{insert}}(v)\\;=\\;\\sum_{i=1}^{k}O(1)\\;=\\;O(k),\n",
    "\\qquad\n",
    "T_{\\text{lookup}}(v)\\;=\\;\\sum_{i=1}^{k}O(1)\\;=\\;O(k).\n",
    "$$  \n",
    "\n",
    "**Modelado matemático** \n",
    "\n",
    "1. **Número de hashes, $k$.**  \n",
    "   - Definido como  \n",
    "     $$\n",
    "       k \\;=\\;\\left\\lceil -\\frac{\\ln p}{\\ln 2}\\right\\rceil,\n",
    "     $$  \n",
    "     donde $p$ es la probabilidad deseada de falso positivo.  \n",
    "   - $k$ depende solo de la tolerancia $p$, no de $n$ ni de $m$, y por diseño es constante durante la vida del filtro.\n",
    "\n",
    "2. **Operaciones por hash**  \n",
    "   - Cada función _hash_ (en tu implementación, dos hashes base y combinación cuadrática) produce un entero en $[0,m)$, lo cual modelamos como $O(1)$ bit‐ops.  \n",
    "   - Luego se calcula  \n",
    "     $$\n",
    "       \\text{pos}_i = (h_1 + i\\,h_2 + i^2)\\bmod m,\n",
    "     $$  \n",
    "     cada una también $O(1)$.  \n",
    "\n",
    "3. **Acceso a bits**  \n",
    "   - Leer o escribir un bit en una posición dada requiere:\n",
    "     - Cálculo de índice de byte y desplazamiento: $O(1)$.\n",
    "     - Enmascarar y desplazar: $O(1)$.\n",
    "   - En total, cada bit‐op es $O(1)$, y hacemos $k$ de ellas.\n",
    "\n",
    "Por tanto, en un modelo ideal donde:\n",
    "- El tiempo de hash, aritmética modular y acceso a memoria de un byte es constante.\n",
    "- La longitud de la clave serializada $\\|\\mathrm{key}\\|$ es acotada (o se considera parte de un coste aparte),\n",
    "\n",
    "la complejidad de inserción y consulta es **lineal en $k$**, es decir, $O(k)$.\n",
    "\n",
    "**Suposiciones del modelo $O(k)$**\n",
    "\n",
    "Para que la abstracción $O(k)$ sea válida, asumimos:\n",
    "\n",
    "- **Hashing de longitud acotada.** Si la clave tiene longitud $\\ell$, entonces computar $h_1$ y $h_2$ cuesta $O(\\ell)$. Con $\\ell=O(1)$ o amortiguado, el coste dominante es $O(k)$.  \n",
    "- **Acceso a memoria constante.** Suponemos que leer o escribir un byte en la RAM toma tiempo constante, sin penalizaciones por jerarquía de caché.  \n",
    "- **Operaciones aritméticas en palabra máquina.** Las operaciones (suma, multiplicación módulo $2^{32}$, desplazamientos) son $O(1)$ en arquitecturas comunes.\n",
    "\n",
    "Bajo estas hipótesis, cada inserción o consulta recorre un bucle de $k$ iteraciones con coste constante, de modo que $T\\in\\Theta(k)$.\n",
    "\n",
    "**Límites en implementaciones reales**\n",
    "\n",
    "En la práctica, varias limitaciones pueden alejar el rendimiento real de la idealización $O(k)$:\n",
    "\n",
    "1. **Caché y localidad de referencia**  \n",
    "   - Las posiciones de bit generadas por hashing suelen \"saltar\" por todo el arreglo de $m$ bits. Si $m\\gg\\text{tamaño de caché}$, cada acceso puede causar fallo de caché (cache miss), elevando el coste a decenas o cientos de ciclos.  \n",
    "   - Técnicas como _blocked hashing_ o usar varios sub‐arrays más pequeños pueden mejorar la localidad y reducir el coste real.\n",
    "\n",
    "2. **Vectorización y prefetching**  \n",
    "   - En arquitecturas modernas, procesar varios hashes en paralelo (SIMD) o prefetching manual de líneas de caché puede acercar el coste a un factor amortizado cercano a $O(k/|\\text{SIMD}|)$.\n",
    "\n",
    "3. **Compresión del bit‐array**  \n",
    "   - Si se aplica compresión al arreglo de bits (p. ej. RLE, Roaring bitmaps), cada lectura o escritura puede requerir decodificar un bloque comprimido, costando tiempo variable y no constante.  \n",
    "   - El coste pasa de $O(1)$ por bit a $O(\\log m)$ o peor, dependiendo del esquema de compresión.\n",
    "\n",
    "4. **Cálculo de hashes para claves largas**  \n",
    "   - Cuando las claves son objetos complejos (JSON, strings de gran tamaño), la serialización (`consistent_stringify`) y el hashing se vuelven $O(\\ell)$, por lo que la complejidad real es $O(\\ell + k)$.  \n",
    "   - En entornos donde $\\ell\\gg k$, el tiempo de hash domina.\n",
    "\n",
    "5. **Sincronización en entornos concurrentes**  \n",
    "   - Bajo accesos concurrentes, si el filtro está protegido por un _lock_ global, el coste de inserción/consulta puede incluir $O(1)$ operaciones de bloqueo/desbloqueo, pero con contención puede crecer a $O(\\#\\text{hilos})$ en peor caso.\n",
    "\n",
    "6. **Costes de límite de memoria**  \n",
    "   - Si $m$ es tan grande que excede la memoria principal y se aloja en memoria virtual, cada acceso puede implicar _page fault_, encareciendo dramáticamente el tiempo por operación.\n",
    "\n",
    "\n",
    "> **Límites reales**  \n",
    "> Mientras que teóricamente $T=O(k)$ bajo supuestos ideales, en implementaciones industriales el rendimiento puede verse afectado por jerarquías de caché, compresión de datos, longitud de claves y sincronización concurrente. Una cuidadosa ingeniería (bloqueo de datos, hashing eficiente, estructuras de compresión-friendly y paralelismo) es esencial para acercarse al comportamiento $\\Theta(k)$ en sistemas reales.\n",
    "\n",
    "\n",
    "\n",
    "**(b) Óptimo de $k$ y la fórmula $k = \\frac{m}{n}\\ln 2$**  \n",
    "\n",
    "Sea un Bloom filter con  \n",
    "- $m$ bits en el arreglo,  \n",
    "- $n$ elementos insertados,  \n",
    "- $k$ funciones de hash independientes (o su aproximación mediante double-hashing).  \n",
    "\n",
    "La probabilidad teórica de falso positivo tras $n$ inserciones viene dada por  \n",
    "$$\n",
    "P_{\\rm fp}\n",
    "\\;=\\;\\Bigl(1 - e^{-\\,\\tfrac{k\\,n}{m}}\\Bigr)^{k}.\n",
    "$$\n",
    "El objetivo es encontrar el valor de $k$ que minimiza esta expresión.\n",
    " \n",
    "Definimos  \n",
    "$$\n",
    "f(k) = P_{\\rm fp} \n",
    "         = \\bigl(1 - e^{-kn/m}\\bigr)^k\n",
    "\\quad\\Longrightarrow\\quad\n",
    "\\ln f(k) \n",
    "= k\\;\\ln\\!\\bigl(1 - e^{-kn/m}\\bigr).\n",
    "$$\n",
    "\n",
    "Tratamos $k$ como variable continua y exigimos  \n",
    "$$\n",
    "\\frac{d}{dk}\\ln f(k) \\;=\\; 0.\n",
    "$$\n",
    "Calculemos la derivada paso a paso:\n",
    "\n",
    "1.  \n",
    "$$\n",
    "\\frac{d}{dk}\\bigl[\\;k\\;\\ln(1 - e^{-kn/m})\\bigr]\n",
    "= \\ln(1 - e^{-kn/m})\n",
    "  \\;+\\; k\\;\\frac{d}{dk}\\ln(1 - e^{-kn/m}).\n",
    "$$\n",
    "\n",
    "2.  \n",
    "$$\n",
    "\\frac{d}{dk}\\ln\\bigl(1 - e^{-kn/m}\\bigr)\n",
    "= \\frac{1}{1 - e^{-kn/m}}\\;\\cdot\\;\\Bigl(-\\frac{d}{dk}e^{-kn/m}\\Bigr)\n",
    "= \\frac{1}{1 - e^{-kn/m}}\\;\\cdot\\;\\Bigl(-e^{-kn/m}\\,\\bigl(-\\tfrac{n}{m}\\bigr)\\Bigr)\n",
    "= \\frac{(n/m)\\,e^{-kn/m}}{1 - e^{-kn/m}}.\n",
    "$$\n",
    "\n",
    "Por lo tanto,\n",
    "$$\n",
    "\\frac{d}{dk}\\ln f(k)\n",
    "= \\ln\\bigl(1 - e^{-kn/m}\\bigr)\n",
    "  \\;+\\;\n",
    "  k\\;\\frac{(n/m)\\,e^{-kn/m}}{1 - e^{-kn/m}}\n",
    "  \\;\\stackrel{!}{=}\\;0.\n",
    "$$\n",
    " \n",
    "Definamos \n",
    "$$\n",
    "x = e^{-kn/m}, \n",
    "\\quad\\text{así que}\\quad\n",
    "1 - x = 1 - e^{-kn/m}.\n",
    "$$\n",
    "El término $\\ln(1 - e^{-kn/m})$ es $\\ln(1 - x)$, y\n",
    "$$\n",
    "\\frac{(n/m)\\,e^{-kn/m}}{1 - e^{-kn/m}}\n",
    "= \\frac{(n/m)\\,x}{1 - x}.\n",
    "$$\n",
    "\n",
    "La ecuación crítica es\n",
    "\n",
    "$$\n",
    "\\ln(1 - x) \\;+\\; k\\,\\frac{n}{m}\\,\\frac{x}{1 - x} \\;=\\; 0.\n",
    "$$\n",
    "Pero como $x = e^{-kn/m}$, tenemos también\n",
    "$$\n",
    "k\\,\\frac{n}{m}\n",
    "= -\\ln x.\n",
    "$$\n",
    "\n",
    "Reemplazando el segundo término:\n",
    "\n",
    "$$\n",
    "\\ln(1 - x) \\;-\\; \\bigl(\\ln x\\bigr)\\,\\frac{x}{1 - x} \\;=\\; 0.\n",
    "$$\n",
    "\n",
    "Sin resolver esta en general, observamos que **$x = 1/2$** (i.e.\\ $\\ln x = -\\ln2$) satisface exactamente esta igualdad:\n",
    "\n",
    "- $\\ln(1 - x)=\\ln(1/2)=-\\ln2.$  \n",
    "- $\\displaystyle -(\\ln x)\\,\\frac{x}{1 - x}\n",
    "  = -(-\\ln2)\\,\\frac{1/2}{1/2}\n",
    "  = \\ln2.$\n",
    "\n",
    "De modo que\n",
    "$$\n",
    "-\\ln2 \\;+\\;\\ln2 \\;=\\;0.\n",
    "$$\n",
    "Por lo tanto la solución estacionaria es  \n",
    "$$\n",
    "e^{-kn/m} \\;=\\;\\tfrac12\n",
    "\\;\\Longrightarrow\\;\n",
    "-\\frac{k\\,n}{m} \\;=\\;\\ln\\tfrac12 \\;=\\;-\\,\\ln2\n",
    "\\;\\Longrightarrow\\;\n",
    "\\boxed{k^* \\;=\\;\\frac{m}{n}\\,\\ln2.}\n",
    "$$\n",
    "\n",
    "**Interpretación: ¿más o menos de $k^*$?**\n",
    "\n",
    "- **Si $k<k^*$**:  \n",
    "  - Se usan muy pocas funciones de hash,  \n",
    "  - Los bits del filtro no se \"escogen\" de manera suficientemente diversa,  \n",
    "  - La fracción de bits a 1 tras $n$ inserciones es menor, pero cada consulta lee pocos bits -> **aumenta** la probabilidad de falso positivo global.\n",
    "\n",
    "- **Si $k>k^*$**:  \n",
    "  - Se prueban demasiados bits por elemento,  \n",
    "  - El filtro se llena muy rápido (mucha más densidad de 1s),  \n",
    "  - Cada inserción/consulta cuesta más trabajo y el balance bits probados vs. densidad de 1s se desequilibra -> también **aumenta** la probabilidad de falso positivo.\n",
    "\n",
    "En ambos casos nos alejamos del mínimo de  \n",
    "$\\displaystyle P_{\\rm fp}=(1-e^{-kn/m})^k$,  \n",
    "que ocurre precisamente en  \n",
    "$\\displaystyle k^*=\\tfrac{m}{n}\\ln2$.  \n",
    "\n",
    "\n",
    "> **Conclusión:** elegir  \n",
    "> $$\n",
    " k \\approx \\frac{m}{n}\\,\\ln 2\n",
    " $$\n",
    "> garantiza número de hashes óptimo ni demasiados (llenan el filtro y encarecen la operación), ni muy pocos (pocos bits distintos probados) y minimiza la tasa de falsos positivos.\n",
    "\n",
    "\n",
    "**(c) Counting Bloom filter y su sobrecosto de memoria**  \n",
    "  \n",
    "Un **Counting Bloom filter** (CBF) extiende el Bloom filter clásico reemplazando el arreglo de bits por un arreglo de **contadores** (normalmente pequeños enteros sin signo). Sea  \n",
    "- $m$ la cantidad de \"celdas\" (igual que en el filtro bit a bit),  \n",
    "- $\\{c_i\\}_{i=0}^{m-1}$ un arreglo de contadores de ancho $w$ bits cada uno,  \n",
    "- $k$ las funciones de hash (o double hashing) como en tu implementación.  \n",
    "\n",
    "Las operaciones se implementan así:\n",
    "\n",
    "1. **Inserción** `add(value)`:  \n",
    "   ```python\n",
    "   for pos in key_positions(value):\n",
    "       c[pos] += 1\n",
    "   ```  \n",
    "2. **Eliminación** `remove(value)`:  \n",
    "   ```python\n",
    "   for pos in key_positions(value):\n",
    "       # Se asume que nunca se decrementa por debajo de 0\n",
    "       if c[pos] > 0:\n",
    "           c[pos] -= 1\n",
    "   ```  \n",
    "3. **Consulta** `contains(value)`:  \n",
    "   ```python\n",
    "   return all(c[pos] > 0 for pos in key_positions(value))\n",
    "   ```  \n",
    "\n",
    "> **Nota:**  \n",
    "> - Cada contador $c_i$ debe tener suficiente rango para evitar **desbordamientos**: su valor máximo debe ser al menos el número máximo de inserciones que mapeen a la misma celda.  \n",
    "> - La eliminación no introduce **falsos negativos** mientras no se produzcan desbordamientos o borrados excesivos.\n",
    "\n",
    "**Sobrecosto de memoria**\n",
    "\n",
    "- En el Bloom filter clásico usamos **1 bit** por celda.  \n",
    "- En el CBF usamos **$w$ bits** por celda para representar contadores de $0$ a $2^w-1$.  \n",
    "\n",
    "Por tanto, el factor de sobrecosto de memoria es  \n",
    "$$\n",
    "\\frac{\\text{memoria CBF}}{\\text{memoria BF}} \n",
    "\\;=\\;\\frac{m\\cdot w\\text{ bits}}{m\\cdot 1\\text{ bit}}\n",
    "\\;=\\;w.\n",
    "$$  \n",
    "\n",
    "Más detallado:\n",
    "\n",
    "- Si elegimos $w = 4$ (contadores de hasta 15), ocupamos 4× más memoria que un bit-array.  \n",
    "- Para evitar desbordamientos, a menudo se dimensiona  \n",
    "  $$\n",
    "    w \\ge \\lceil \\log_2(C_{\\max}+1)\\rceil,\n",
    "  $$\n",
    "  donde $C_{\\max}$ es el número máximo esperado de inserciones que pueden colisionar en una misma celda (en el peor caso, $C_{\\max}=n$, aunque en promedio es mucho menor).\n",
    "\n",
    "Además del factor $w$, el CBF puede requerir cierta **sobrecapacidad** extra para bajar la probabilidad de desbordar contadores, lo que implica dimensionar un poco más $m$ en función del perfil de colisiones.\n",
    "\n",
    "\n",
    "Un CBF resulta crítico cuando la **colección es dinámica** y se requieren **eliminaciones**, por ejemplo:\n",
    "\n",
    "- **Ventanas deslizantes en streaming**  \n",
    "  - En sistemas de métricas en tiempo real (logs, eventos de usuario), a menudo se desea mantener sólo los últimos $W$ minutos de datos. Al expirar cada elemento antiguo, hay que quitarlo del filtro; un Bloom filter clásico no permite esto sin reconstruirlo completamente, mientras que un CBF puede decrementar contadores al expirar cada evento.\n",
    "\n",
    "- **Cachés con invalidación**  \n",
    "  - En un servidor de caché distribuido, al expulsar (`evict`) una clave, conviene eliminarla del filtro de presencia para evitar falsos positivos posteriores que impidan recargar la clave correcta.\n",
    "\n",
    "- **Tablas de flujo en redes**  \n",
    "  - Un router o **firewall** mantiene un Bloom filter de conexiones activas. Al cerrar una sesión TCP, debe eliminar dicha conexión del filtro para no seguir generando falsos positivos de paquetes \"viejos\".\n",
    "\n",
    "En todos estos casos, la capacidad de **borrar** (decrementar) sin reconstruir la estructura desde cero y con un coste amortizado $O(k)$ hace al Counting Bloom filter una solución práctica e indispensable.\n",
    "\n",
    "**(d) Estimación teórica vs. experimento práctico**  \n",
    "\n",
    "1. **Estimación teórica**  \n",
    "   Con $n=4000$, $m=48000$ y $k=7$, la probabilidad de falso positivo viene dada por  \n",
    "   $$\n",
    "     P_{\\rm fp}\n",
    "     \\;=\\;\\Bigl(1 - e^{-\\,\\tfrac{k\\,n}{m}}\\Bigr)^k\n",
    "     \\;=\\;\\Bigl(1 - e^{-\\,\\tfrac{7\\cdot4000}{48000}}\\Bigr)^{7}\n",
    "     \\;=\\;\\bigl(1 - e^{-0.5833\\dots}\\bigr)^{7}\n",
    "     \\;=\\;(0.4420)^{7}\n",
    "     \\;\\approx\\;3.3\\times10^{-3}\\;(\\!0.33\\%\\!)\\,.\n",
    "   $$\n",
    "\n",
    "2. **Diseño de un experimento para validar $P_{\\rm fp}$ con ±1 % de error**  \n",
    "\n",
    "   > *Objetivo:* medir empíricamente la tasa de falsos positivos $p_{\\rm emp}$ de manera que el intervalo de confianza al 95 % tenga un margen de error absoluto <= 0.01 (1 p.p.).\n",
    "\n",
    "   - **Paso 1. Preparar el filtro**  \n",
    "     ```python\n",
    "     from uuid import uuid4\n",
    "     filtro = BloomFilter(max_size=4000, max_tolerance=0.01, seed=42)\n",
    "     # Forzar m=48000, k=7:\n",
    "     filtro._num_bits = 48000\n",
    "     filtro._num_hashes = 7\n",
    "     ```\n",
    "   - **Paso 2. Insertar 4000 elementos únicos**  \n",
    "     ```python\n",
    "     inserciones = {str(uuid4()) for _ in range(4000)}\n",
    "     for x in inserciones:\n",
    "         filtro.add(x)\n",
    "     ```\n",
    "   - **Paso 3. Generar elementos \"ausentes\"**  \n",
    "     - Crear un conjunto de prueba `prueba = {str(uuid4()) for _ in range N}` con `N` suficientemente grande y que no intersecte con `inserciones`.  \n",
    "     - En la práctica, elegir **$N=10\\,000$** garantiza un margen de error al 95 % de  \n",
    "       $$\n",
    "         \\mathrm{ME}\n",
    "         = z_{0.975}\\,\\sqrt{\\frac{p(1-p)}{N}}\n",
    "         \\;\\approx\\;1.96\\,\\sqrt{\\frac{0.0033\\cdot0.9967}{10\\,000}}\n",
    "         \\;\\approx\\;0.0011\\;(0.11\\%\\!)<1\\%.\n",
    "       $$\n",
    "   - **Paso 4. Medir falsos positivos**  \n",
    "     ```python\n",
    "     falsos = sum(1 for x in prueba if filtro.contains(x))\n",
    "     p_emp = falsos / N\n",
    "     ```\n",
    "   - **Paso 5. Intervalo de confianza**  \n",
    "     Con distribución binomial aproximada:\n",
    "     $$\n",
    "       \\hat p \\pm z_{0.975}\\,\\sqrt{\\frac{\\hat p(1-\\hat p)}{N}}\n",
    "     $$\n",
    "     donde $\\hat p = p_{\\rm emp}$.  \n",
    "\n",
    "   > **Nota:** si en lugar de ±1 p.p. absoluto se quisiera ±1 % relativo, se recalcula $N$ usando  $\\mathrm{ME}=0.01\\,\\hat p$ en la fórmula anterior.\n",
    "\n",
    "\n",
    "**(e) Impacto de la dispersión de las funciones hash**  \n",
    "\n",
    "1. **¿Por qué causa más falsos positivos?**  \n",
    "   - Si dos (o más) de las $k$ funciones hash \"apuntan\" sistemáticamente a posiciones cercanas o a un mismo subconjunto de bits,  \n",
    "     - se **reduce la diversidad** de celdas explotadas,  \n",
    "     - aumenta la **densidad local de 1s**,  \n",
    "     - disparan las colisiones múltiples,  \n",
    "     - y el Bloom filter responde \"sí\" a muchas claves ausentes.  \n",
    "\n",
    "2. **Propiedades deseables en una función hash**  \n",
    "   - **Uniformidad**: cada bit-position de $[0,m)$ debe recibir aproximadamente igual número de hashes.  \n",
    "   - **Avalanche effect**: un sólo bit de la entrada altera aproximadamente la mitad de los bits de la salida.  \n",
    "   - **Independencia o _k_-independencia**: salidas de las distintas funciones deben comportarse como independientes (o al menos 2-o 4-independientes) para que la teoría del Bloom clásico se aplique.  \n",
    "   - **Bajas colisiones**: minimizar la probabilidad de que dos claves distintas produzcan el mismo hash.  \n",
    "   - **Eficiencia**: coste $O(1)$ por hash en tiempo real, con bajo overhead computacional.  \n",
    "\n",
    "3. **Buenas elecciones prácticas**  \n",
    "   - Algoritmos probados como MurmurHash3, xxHash, HighwayHash (o variantes de CityHash) que cumplen las propiedades anteriores.  \n",
    "   - Evitar funciones con sesgos conocidos (p. e. suma sencilla de bytes, CRC sin mezcla) o con patrón de baja entropía en bits altos o bajos.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
