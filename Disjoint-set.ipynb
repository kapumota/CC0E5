{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80365a2d-fd6f-4b09-8fbb-4d6f7c8c52a1",
   "metadata": {},
   "source": [
    "### **Disjoint-set/Union-Find**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea3c69e-6344-4d74-9365-b5955e90d4ae",
   "metadata": {},
   "source": [
    "La estructura de datos **Disjoint-Set**, también conocida como **Union-Find**, permite gestionar particiones de un conjunto de elementos de forma eficiente, ofreciendo operaciones de unión (`merge`) y búsqueda de representante (`find_partition`). Esta implementación en Python optimiza la complejidad amortizada mediante compresión de caminos y unión por rango, logrando costo casi constante en escenarios con numerosas operaciones. Es especialmente útil en algoritmos de grafos, detección de ciclos y construcciones de árboles de expansión mínima como Kruskal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f7adf-96c8-4b50-93d0-72abbcf66dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementación del TDA-Disjoint-Set / Union-Find con:\n",
    "\n",
    "*  Compresión de caminos en find_partition\n",
    "*  unión por rango en merge\n",
    "*  Manejo exhaustivo de errores (mensajes en español)\n",
    "*  Compatibilidad total con el juego de pruebas unitarias suministrado\n",
    "\n",
    "\"\"\"\n",
    "from collections.abc import Iterable, Mapping  # Mapping nos permite detectar dicts\n",
    "\n",
    "\n",
    "#  Validación utilitaria \n",
    "def is_defined(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "def is_undefined(val):\n",
    "    return val is None\n",
    "\n",
    "\n",
    "def is_iterable(val):\n",
    "    try:\n",
    "        iter(val)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "\n",
    "#  Mensajes de error \n",
    "def _error_union_find_constructor_illegal_argument(val):\n",
    "    return f\"Argumento ilegal para el constructor de DisjointSet: {val}\"\n",
    "\n",
    "\n",
    "def _error_union_find_constructor_duplicate_element(val):\n",
    "    return (\n",
    "        f\"Elemento duplicado en el conjunto inicial para el constructor de DisjointSet: {val}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _error_find_not_in_set(val):\n",
    "    return f\"El argumento {val} para el método find_partition no pertenece a este conjunto\"\n",
    "\n",
    "\n",
    "def _error_invalid_argument(method, param, val):\n",
    "    return f\"Argumento inválido para el método '{method}': el parámetro '{param}' tiene un valor inválido {val!r}\"\n",
    "\n",
    "\n",
    "# Clase auxiliar\n",
    "class Info:\n",
    "    \"\"\"Mantiene la raíz y el rango de un elemento.\"\"\"\n",
    "\n",
    "    def __init__(self, elem):\n",
    "        if not is_defined(elem):\n",
    "            raise TypeError(_error_invalid_argument(\"Info.__init__\", \"elem\", elem))\n",
    "        self._root = elem\n",
    "        self._rank = 1\n",
    "\n",
    "    # root\n",
    "    @property\n",
    "    def root(self):\n",
    "        return self._root\n",
    "\n",
    "    @root.setter\n",
    "    def root(self, new_root):\n",
    "        if not is_defined(new_root):\n",
    "            raise TypeError(\n",
    "                _error_invalid_argument(\"Info.root.setter\", \"new_root\", new_root)\n",
    "            )\n",
    "        self._root = new_root\n",
    "\n",
    "    # rank\n",
    "    @property\n",
    "    def rank(self):\n",
    "        return self._rank\n",
    "\n",
    "    @rank.setter\n",
    "    def rank(self, new_rank):\n",
    "        self._rank = new_rank\n",
    "\n",
    "\n",
    "#  Clase DisjointSet\n",
    "class DisjointSet:\n",
    "    \"\"\"\n",
    "    Estructura Conjuntos disjuntos (Union-Find) con:\n",
    "\n",
    "    * find con compresión de caminos\n",
    "    * unión por rango\n",
    "    * interface amigable y validación estricta\n",
    "    \"\"\"\n",
    "\n",
    "    # Constructor \n",
    "    def __init__(self, initial_set=None):\n",
    "        # 0. Normalización\n",
    "        if initial_set is None:\n",
    "            initial_set = []\n",
    "\n",
    "        # 1. Rechazar tipos explícitamente prohibidos:\n",
    "        #    - str y bytes se considerarían colecciones de caracteres/bytes,\n",
    "        #      pero el constructor debe tratarlos como argumento inválido.\n",
    "        #    - Mapping (dict, OrderedDict, defaultdict, …) se itera sobre sus\n",
    "        #      claves; tampoco se desea permitirlo.\n",
    "        if isinstance(initial_set, (str, bytes)) or isinstance(initial_set, Mapping):\n",
    "            raise TypeError(_error_union_find_constructor_illegal_argument(initial_set))\n",
    "\n",
    "        # 2. Asegurar que sea iterable (list, tuple, set, generator, etc.)\n",
    "        if not is_iterable(initial_set):\n",
    "            raise TypeError(_error_union_find_constructor_illegal_argument(initial_set))\n",
    "\n",
    "        # 3. Construir la tabla de elementos\n",
    "        self._elements: dict = {}\n",
    "        for elem in initial_set:\n",
    "            if not is_defined(elem):\n",
    "                raise TypeError(_error_union_find_constructor_illegal_argument(elem))\n",
    "            if elem in self._elements:\n",
    "                raise TypeError(_error_union_find_constructor_duplicate_element(elem))\n",
    "            self._elements[elem] = Info(elem)\n",
    "\n",
    "    # Propiedades de sólo lectura \n",
    "    @property\n",
    "    def size(self):\n",
    "        \"\"\"Número total de elementos (no de subconjuntos) almacenados.\"\"\"\n",
    "        return len(self._elements)\n",
    "\n",
    "    # Métodos públicos\n",
    "    def add(self, elem):\n",
    "        \"\"\"\n",
    "        Inserta `elem` como nuevo subconjunto singleton.\n",
    "\n",
    "        Devuelve:\n",
    "            True  - si el elemento se añadió.\n",
    "            False - si ya existía previamente.\n",
    "        \"\"\"\n",
    "        if not is_defined(elem):\n",
    "            raise TypeError(_error_invalid_argument(\"add\", \"elem\", elem))\n",
    "        if elem in self._elements:\n",
    "            return False\n",
    "        self._elements[elem] = Info(elem)\n",
    "        return True\n",
    "\n",
    "    def find_partition(self, elem):\n",
    "        \"\"\"\n",
    "        Devuelve el representante (raíz) del subconjunto que contiene a `elem`,\n",
    "        aplicando compresión de caminos para minimizar la profundidad.\n",
    "        \"\"\"\n",
    "        if is_undefined(elem):\n",
    "            raise TypeError(_error_invalid_argument(\"find_partition\", \"elem\", elem))\n",
    "        if elem not in self._elements:\n",
    "            raise TypeError(_error_find_not_in_set(elem))\n",
    "\n",
    "        info = self._elements[elem]\n",
    "        if info.root != elem:  # no es raíz ⇒ seguir recursivamente\n",
    "            info.root = self.find_partition(info.root)\n",
    "        return info.root\n",
    "\n",
    "    def merge(self, elem1, elem2):\n",
    "        \"\"\"\n",
    "        Une los subconjuntos que contienen elem1 y elem2.\n",
    "\n",
    "        Retorna:\n",
    "            True  - si los subconjuntos eran distintos y se fusionaron.\n",
    "            False - si ambos elementos ya pertenecían al mismo subconjunto.\n",
    "        \"\"\"\n",
    "        # Validación de argumentos se delega a find_partition\n",
    "        r1 = self.find_partition(elem1)\n",
    "        r2 = self.find_partition(elem2)\n",
    "        if r1 == r2:\n",
    "            return False  # ya estaban unidos\n",
    "\n",
    "        info1 = self._elements[r1]\n",
    "        info2 = self._elements[r2]\n",
    "\n",
    "        # Unión por rango: el de mayor rango se convierte en la nueva raíz\n",
    "        if info1.rank >= info2.rank:\n",
    "            info2.root = info1.root\n",
    "            info1.rank += info2.rank\n",
    "        else:\n",
    "            info1.root = info2.root\n",
    "            info2.rank += info1.rank\n",
    "\n",
    "        return True\n",
    "\n",
    "    def are_disjoint(self, elem1, elem2):\n",
    "        \"\"\"\n",
    "        Indica si elem1 y elem2 pertenecen a subconjuntos distintos.\n",
    "\n",
    "        Devuelve True si son disjuntos, False! si comparten representante.\n",
    "        \"\"\"\n",
    "        p1 = self.find_partition(elem1)\n",
    "        p2 = self.find_partition(elem2)\n",
    "        return p1 != p2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a9599-e8c7-44e4-bc00-43c6ee626dd8",
   "metadata": {},
   "source": [
    "#### **Explicación del código**\n",
    "El constructor de la clase `DisjointSet` acepta un iterable inicial de elementos y aplica validaciones estrictas para rechazar argumentos inválidos. Se prohíben tipos como `str`, `bytes` y `Mapping` (diccionarios), ya que su iteración original podría interpretarlos como colecciones de caracteres o claves. \n",
    "\n",
    "La función `is_iterable` verifica adaptativamente colecciones, mientras que `is_defined` e `is_undefined` controlan valores nulos. Cualquier error arroja mensajes detallados en español, por ejemplo, \"Argumento ilegal para el constructor de DisjointSet\" o \"Elemento duplicado en el conjunto inicial\", facilitando la depuración.\n",
    "\n",
    "La clase auxiliar `Info` encapsula la información de cada elemento: su raíz (`root`) y su rango (`rank`). Mediante propiedades con getters y setters, garantiza la integridad de los datos, validando que la raíz nunca sea `None` y gestionando el incremento de rango sin restricciones implícitas. Este diseño modular desacopla la lógica de almacenamiento de metadatos de la funcionalidad principal, simplificando el mantenimiento y las extensiones posteriores.\n",
    "\n",
    "El método `find_partition` aplica recursivamente compresión de caminos: comprueba si el elemento no es raíz y, en ese caso, reasigna su padre al representante final obtenido de la llamada recursiva. Este proceso minimiza la profundidad de los árboles resultantes, acelerando búsquedas subsecuentes. Además, controla argumentos indefinidos y valores no registrados, generando excepciones con mensajes claros como \"El argumento X para el método find_partition no pertenece a este conjunto\".\n",
    "\n",
    "La función `merge` ejecuta unión por rango: compara los rangos de las raíces de dos elementos y asigna la raíz de mayor rango como representante común, sumando el rango del árbol absorbido a la raíz dominante. Si ambos subárboles ya comparten representante, retorna `False`; de lo contrario, efectúa la unión y devuelve `True`. El método `are_disjoint` complementa estas operaciones, indicando si dos elementos residen en subconjuntos diferentes. Finalmente, el método `add` incorpora nuevos elementos singulares con validación, asegurando unicidad y generando errores tipo `TypeError` para entradas inválidas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d39766-39f5-471b-8b2c-d0f25f141fcc",
   "metadata": {},
   "source": [
    "Cómo usarlo: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1060c96-7d16-412d-b23f-70ca424c7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DisjointSet(['a', 'b', 'c'])\n",
    "print(ds.size)                # 3\n",
    "print(ds.are_disjoint('a','b'))  # True\n",
    "ds.merge('a','b')\n",
    "print(ds.are_disjoint('a','b'))  # False\n",
    "ds.add('d')                   # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7e59d-9c01-430d-9c4d-05ada8ddbc49",
   "metadata": {},
   "source": [
    "#### **Pruebas unitarias**\n",
    "\n",
    "Este archivo define una suite de pruebas unitarias con unittest para verificar el comportamiento de la clase `DisjointSet`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d27d1-8a58-4113-b72e-046358758619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "# Si tu clase vive en otro archivo distinta a este, importa así:\n",
    "# from disjointset import DisjointSet\n",
    "#\n",
    "# Como el enunciado indica que estamos en Jupyter ─o mismo espacio─\n",
    "# se puede hacer:\n",
    "from __main__ import DisjointSet   # noqa: E402\n",
    "\n",
    "\n",
    "# 1. Constructor \n",
    "class TestConstructor(unittest.TestCase):\n",
    "\n",
    "    def test_illegal_arg_not_iterable(self):\n",
    "        with self.assertRaises(TypeError) as cm:\n",
    "            DisjointSet('123')\n",
    "        self.assertIn(\n",
    "            \"Argumento ilegal para el constructor de DisjointSet: 123\",\n",
    "            str(cm.exception)\n",
    "        )\n",
    "\n",
    "        with self.assertRaises(TypeError) as cm2:\n",
    "            DisjointSet({'a': 1})\n",
    "        self.assertIn(\n",
    "            \"Argumento ilegal para el constructor de DisjointSet: {'a': 1}\",\n",
    "            str(cm2.exception)\n",
    "        )\n",
    "\n",
    "    def test_illegal_arg_none_elem(self):\n",
    "        with self.assertRaises(TypeError) as cm:\n",
    "            DisjointSet([None])\n",
    "        self.assertIn(\n",
    "            \"Argumento ilegal para el constructor de DisjointSet: None\",\n",
    "            str(cm.exception)\n",
    "        )\n",
    "\n",
    "    def test_duplicate_elements(self):\n",
    "        with self.assertRaises(TypeError) as cm:\n",
    "            DisjointSet(['1', '1'])\n",
    "        self.assertIn(\n",
    "            \"Elemento duplicado en el conjunto inicial para el constructor de DisjointSet: 1\",\n",
    "            str(cm.exception)\n",
    "        )\n",
    "\n",
    "    def test_constructor_iterables_ok(self):\n",
    "        DisjointSet([1, 2, 'a', (1, 2)])              # lista\n",
    "        DisjointSet({'x', 'y'})                       # set\n",
    "        DisjointSet({1: 'a', 2: 'b'}.items())         # dict.items()\n",
    "\n",
    "    def test_constructor_different_but_alike(self):\n",
    "        DisjointSet(['1', 1, '2', 2])\n",
    "        DisjointSet({'1', 1, '2', 2})\n",
    "        DisjointSet({('1', '2'), (1, 2)})\n",
    "\n",
    "\n",
    "# 2. find_partition\n",
    "class TestFindPartition(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.ds = DisjointSet(['1', '2', '3', 'a', 'abc'])\n",
    "\n",
    "    def test_invalid_argument(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.ds.find_partition(None)\n",
    "\n",
    "    def test_not_in_set(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.ds.find_partition('x')\n",
    "\n",
    "    def test_initial_root_is_itself(self):\n",
    "        for k in ['1', '2', '3', 'a', 'abc']:\n",
    "            self.assertEqual(self.ds.find_partition(k), k)\n",
    "\n",
    "\n",
    "# 3. merge\n",
    "class TestMerge(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.ds = DisjointSet(['1', '2', '3', '4', '5', '6'])\n",
    "\n",
    "    def test_invalid_arguments(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.ds.merge(None, None)\n",
    "\n",
    "    def test_not_in_set(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.ds.merge('x', 'y')\n",
    "\n",
    "    def test_basic_merge(self):\n",
    "        self.assertTrue(self.ds.merge('1', '2'))\n",
    "        self.assertEqual(\n",
    "            self.ds.find_partition('1'),\n",
    "            self.ds.find_partition('2')\n",
    "        )\n",
    "\n",
    "    def test_repeated_merge(self):\n",
    "        self.ds.merge('5', '6')\n",
    "        self.assertFalse(self.ds.merge('5', '6'))\n",
    "\n",
    "    def test_union_by_rank(self):\n",
    "        ds = DisjointSet(['1', '2', '3', '4', '5', '6'])\n",
    "        self.assertTrue(ds.merge('1', '2'))\n",
    "        root = ds.find_partition('1')\n",
    "\n",
    "        ds.merge('1', '3')\n",
    "        self.assertEqual(ds.find_partition('3'), root)\n",
    "\n",
    "        ds.merge('3', '4')\n",
    "        for x in ['1', '2', '3', '4']:\n",
    "            self.assertEqual(ds.find_partition(x), root)\n",
    "\n",
    "        ds.merge('5', '6')\n",
    "        ds.merge('3', '6')\n",
    "        for x in ['5', '6']:\n",
    "            self.assertEqual(ds.find_partition(x), root)\n",
    "\n",
    "\n",
    "# 4. are_disjoint \n",
    "class TestAreDisjoint(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.ds = DisjointSet(['1', '2', '3'])\n",
    "\n",
    "    def test_invalid_arguments(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.ds.are_disjoint(None, None)\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.ds.are_disjoint('x', 'y')\n",
    "\n",
    "    def test_true_before_merge(self):\n",
    "        self.assertTrue(self.ds.are_disjoint('1', '2'))\n",
    "\n",
    "    def test_false_after_merge(self):\n",
    "        self.ds.merge('3', '1')\n",
    "        self.assertFalse(self.ds.are_disjoint('1', '3'))\n",
    "\n",
    "    def test_commutativity(self):\n",
    "        self.assertEqual(\n",
    "            self.ds.are_disjoint('1', '3'),\n",
    "            self.ds.are_disjoint('3', '1')\n",
    "        )\n",
    "\n",
    "\n",
    "# 5. add \n",
    "class TestAdd(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.ds = DisjointSet(['1', '2', '3', 1])\n",
    "\n",
    "    def test_invalid_arguments(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.ds.add(None)\n",
    "\n",
    "    def test_add_existing(self):\n",
    "        for k in ['1', '2', '3', 1]:\n",
    "            self.assertFalse(self.ds.add(k))\n",
    "\n",
    "    def test_add_new(self):\n",
    "        ds = DisjointSet(['1', '2', '3'])\n",
    "        new_keys = ['new', (1, 2), frozenset({3}), 2]\n",
    "        for k in new_keys:\n",
    "            self.assertTrue(ds.add(k))\n",
    "            self.assertEqual(ds.find_partition(k), k)\n",
    "\n",
    "\n",
    "# 6. size\n",
    "class TestSize(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.ds = DisjointSet(['1', '2', '3'])\n",
    "\n",
    "    def test_size_consistent(self):\n",
    "        self.assertEqual(self.ds.size, 3)\n",
    "\n",
    "    def test_size_after_union(self):\n",
    "        self.ds.merge('1', '2')\n",
    "        self.assertEqual(self.ds.size, 3)\n",
    "        self.ds.merge('3', '2')\n",
    "        self.assertEqual(self.ds.size, 3)\n",
    "\n",
    "    def test_size_after_add(self):\n",
    "        old = self.ds.size\n",
    "        self.assertTrue(self.ds.add('new'))\n",
    "        self.assertEqual(self.ds.size, old + 1)\n",
    "        self.assertFalse(self.ds.add('new'))\n",
    "        self.assertEqual(self.ds.size, old + 1)\n",
    "\n",
    "\n",
    "# Ejecución directa\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c6cda-eb81-4be7-b68b-d78818873daa",
   "metadata": {},
   "source": [
    "#### **Implementación de Union-Find con listas de particiones**  \n",
    "\n",
    "Esta versión de **union-find** mantiene un diccionario que mapea cada elemento a un `set` mutable que agrupa su partición.  \n",
    "\n",
    "1. **Inicialización y validación**  \n",
    "   - El constructor recibe un iterable y rechaza explícitamente `str`, `bytes`, `Mapping` y `None` para evitar ambigüedades.  \n",
    "   - Cada elemento único se inicializa como un `set` singleton en `self._partitions`.  \n",
    "\n",
    "2. **Operaciones básicas**  \n",
    "   - `add(elem)`: añade un nuevo singleton si no existía, lanzando error en caso de `None`.  \n",
    "   - `find_partition(elem)`: devuelve la referencia al `set` que contiene a `elem`, con validación de existencia.  \n",
    "   - `merge(a, b)`: une dos particiones por **tamaño**, moviendo todos los elementos del conjunto más pequeño al más grande y actualizando sus referencias en O(min |A|, |B|).  \n",
    "   - `are_disjoint(a, b)`: comprueba si `a` y `b` residen en distintos `set`.  \n",
    "\n",
    "3. **API de conveniencia**  \n",
    "   - `__len__`, `__contains__`, `__iter__` permiten usar `len(uf)`, `elem in uf` y bucles `for`.  \n",
    "   - `groups()`: retorna la colección de particiones como `frozenset`, útil para inspección.\n",
    "\n",
    "**Relación con algoritmos de grafos y clustering**  \n",
    "- En **grafos**, Union-Find detecta componentes conectados: al iterar sobre aristas `(u, v)`, `merge(u, v)` agrupa nodos, y después `find_partition` identifica si dos vértices comparten componente, optimizando detección de ciclos y construcción de bosques de expansión mínima (Kruskal).  \n",
    "- En **clustering aglomerativo**, cada elemento inicia en su propio clúster (`singleton`). Al aplicar un criterio de similitud, se va haciendo `merge` de los clústeres más cercanos.  Los `set` mutantes mantienen en tiempo amortizado la asignación de cada punto a su clúster global, facilitando consultas de pertenencia y actualización de grupos en cada paso de la jerarquía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f79e4-0e7d-47c5-81ff-48f4f543d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Versión mejorada (Python 3.10+) de una estructura Disjoint-Set / Unión-Búsqueda\n",
    "implementada con listas de elementos agrupados en conjuntos.\n",
    "\n",
    "- Validación exhaustiva y mensajes de error claros  \n",
    "- Tipado estático con typing  \n",
    "- Métodos utilitarios (__contains__, __len__, __iter__, groups)  \n",
    "- Unión por tamaño O(min |A|, |B|)  \n",
    "- Cobertura de casos extremos que suelen olvidarse (str, bytes, Mapping, None)\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Iterable as ABCIterable, Mapping\n",
    "from typing import Dict, Iterator, MutableSet, Set, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\", bound=object)\n",
    "\n",
    "\n",
    "# Utilidades\n",
    "def _is_iterable(obj) -> bool:\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:  # pragma: no cover  (solo entra si *no* es iterable)\n",
    "        return False\n",
    "\n",
    "\n",
    "# Errores\n",
    "class UnionFindError(TypeError):\n",
    "    \"\"\"Señala un uso incorrecto de la API de Unión-Búsqueda.\"\"\"\n",
    "\n",
    "\n",
    "def _err_constructor_illegal(val):\n",
    "    return f\"Argumento ilegal para el constructor de UnionFindLists: {val!r}\"\n",
    "\n",
    "\n",
    "def _err_constructor_duplicate(val):\n",
    "    return f\"Elemento duplicado en el conjunto inicial del constructor de UnionFindLists: {val!r}\"\n",
    "\n",
    "\n",
    "def _err_find_not_in_set(val):\n",
    "    return f\"El argumento {val!r} para el método find_partition no está presente en esta estructura\"\n",
    "\n",
    "\n",
    "def _err_invalid_arg(method: str, param: str, val):\n",
    "    return (\n",
    "        f\"Argumento inválido en '{method}': el parámetro '{param}' recibió el valor inválido {val!r}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Clase principal\n",
    "class UnionFindLists:\n",
    "    \"\"\"\n",
    "    Unión-Búsqueda basado en conjuntos: cada partición se almacena como un conjunto mutable de sus elementos.\n",
    "\n",
    "    A diferencia de las versiones \"clásicas\" basadas en árboles, esta implementación es más sencilla\n",
    "    conceptualmente, pero merge cuesta O(min |A|, |B|) al trasladar todos los elementos del conjunto más pequeño al más grande.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    initial_set : Iterable[T] | None\n",
    "        Conjunto inicial de elementos (cada uno arranca en su propia partición). Se rechazan\n",
    "        explícitamente las cadenas de texto (str, bytes) y los mappings (dict, defaultdict, ...)\n",
    "        para evitar confusiones.\n",
    "    \"\"\"\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, initial_set: ABCIterable[T] | None = None) -> None:\n",
    "        if initial_set is None:\n",
    "            initial_set = []\n",
    "\n",
    "        # 1. Filtro de tipos prohibidos (iterables \"engañosos\")\n",
    "        if isinstance(initial_set, (str, bytes)) or isinstance(initial_set, Mapping):\n",
    "            raise UnionFindError(_err_constructor_illegal(initial_set))\n",
    "\n",
    "        # 2. Debe ser realmente iterable\n",
    "        if not _is_iterable(initial_set):\n",
    "            raise UnionFindError(_err_constructor_illegal(initial_set))\n",
    "\n",
    "        # 3. Diccionario elemento → referencia al conjunto-partición\n",
    "        self._partitions: Dict[T, MutableSet[T]] = {}\n",
    "\n",
    "        # 4. Cargar elementos (verificando duplicados / None)\n",
    "        for elem in initial_set:\n",
    "            if elem is None:\n",
    "                raise UnionFindError(_err_constructor_illegal(elem))\n",
    "            if elem in self._partitions:\n",
    "                raise UnionFindError(_err_constructor_duplicate(elem))\n",
    "            self._partitions[elem] = {elem}\n",
    "\n",
    "    # Propiedades de solo lectura\n",
    "    def __len__(self) -> int:  # len(uf)\n",
    "        return len(self._partitions)\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:  # alias explícito\n",
    "        return len(self)\n",
    "\n",
    "    # Iteración / consulta\n",
    "    def __contains__(self, elem: T) -> bool:  # elem está en uf\n",
    "        return elem in self._partitions\n",
    "\n",
    "    def __iter__(self) -> Iterator[T]:  # para x en uf\n",
    "        return iter(self._partitions)\n",
    "\n",
    "    # Devuelve una 'vista' de las particiones (conjuntos únicos)\n",
    "    def groups(self) -> Set[frozenset[T]]:\n",
    "        \"\"\"\n",
    "        Conjunto de las particiones actuales como frozenset.\n",
    "        Útil para depuración o para contar cuántos subconjuntos hay.\n",
    "        \"\"\"\n",
    "        return {frozenset(g) for g in {id(s): s for s in self._partitions.values()}.values()}\n",
    "\n",
    "    # Métodos principales\n",
    "    def add(self, elem: T, /) -> bool:\n",
    "        \"\"\"Añade `elem` como partición de un solo elemento. True => insertado; False => ya existía.\"\"\"\n",
    "        if elem is None:\n",
    "            raise UnionFindError(_err_invalid_arg(\"add\", \"elem\", elem))\n",
    "        if elem in self._partitions:\n",
    "            return False\n",
    "        self._partitions[elem] = {elem}\n",
    "        return True\n",
    "\n",
    "    def find_partition(self, elem: T, /) -> MutableSet[T]:\n",
    "        \"\"\"Devuelve un conjunto mutable que representa la partición de `elem`.\"\"\"\n",
    "        if elem is None:\n",
    "            raise UnionFindError(_err_invalid_arg(\"find_partition\", \"elem\", elem))\n",
    "        try:\n",
    "            return self._partitions[elem]\n",
    "        except KeyError as exc:\n",
    "            raise UnionFindError(_err_find_not_in_set(elem)) from exc\n",
    "\n",
    "    def merge(self, elem1: T, elem2: T, /) -> bool:\n",
    "        \"\"\"\n",
    "        Une (si es necesario) las particiones que contienen a `elem1` y `elem2`.\n",
    "\n",
    "        Retorna\n",
    "        -------\n",
    "        True  – si las particiones eran distintas y se fusionaron.  \n",
    "        False – si ambos elementos ya estaban en la misma partición.\n",
    "        \"\"\"\n",
    "        p1 = self.find_partition(elem1)\n",
    "        p2 = self.find_partition(elem2)\n",
    "        if p1 is p2:  # ya unidas\n",
    "            return False\n",
    "\n",
    "        # Unión por tamaño: mover el conjunto más pequeño dentro del más grande\n",
    "        if len(p1) < len(p2):\n",
    "            small, big = p1, p2\n",
    "        else:\n",
    "            small, big = p2, p1\n",
    "\n",
    "        big_update = big.update  # microoptimización\n",
    "        for x in small:\n",
    "            self._partitions[x] = big\n",
    "        big_update(small)  # añade todos los elementos del conjunto pequeño\n",
    "\n",
    "        return True\n",
    "\n",
    "    def are_disjoint(self, elem1: T, elem2: T, /) -> bool:\n",
    "        \"\"\"Devuelve `True` si `elem1` y `elem2` están en particiones distintas.\"\"\"\n",
    "        return self.find_partition(elem1) is not self.find_partition(elem2)\n",
    "\n",
    "    # Representación amigable\n",
    "    def __repr__(self) -> str:\n",
    "        groups = \", \".join(sorted(map(repr, self.groups())))\n",
    "        return f\"{self.__class__.__name__}({{{groups}}})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11405706-c9b5-4033-9508-7eb2fdf7da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf = UnionFindLists(['a', 'b', 'c'])\n",
    "uf\n",
    "uf.add('d')  \n",
    "uf.add('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfa599-fda3-4bfc-99a8-5641d76bef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf.find_partition('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f6b77-db11-44e7-a680-d19b8762de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementación optimizada de Union-Find (bosque de conjuntos disjuntos) con:\n",
    "\n",
    "- Compresión de caminos *in situ* (find => α(m, n))  \n",
    "- Unión por rango (heurística de rango, O(1))  \n",
    "- Tipado estático (Python 3.10+) y API \"pythónica\" (`len`, `in`, `iter`)  \n",
    "- Mensajes de error claros mediante una excepción propia  \n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Iterable as ABCIterable, Mapping\n",
    "from typing import Dict, Iterator, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\", bound=object)\n",
    "\n",
    "\n",
    "# Excepción propia\n",
    "class UnionFindError(TypeError):\n",
    "    \"\"\"Uso indebido de la API Union-Find (argumentos nulos, inexistentes, etc.).\"\"\"\n",
    "\n",
    "\n",
    "# Mensajes de error\n",
    "def _err_ctor_illegal(val):\n",
    "    return f\"Argumento ilegal para el constructor de UnionFindTrees: {val!r}\"\n",
    "\n",
    "\n",
    "def _err_ctor_duplicate(val):\n",
    "    return f\"Elemento duplicado en el conjunto inicial para el constructor de UnionFindTrees: {val!r}\"\n",
    "\n",
    "\n",
    "def _err_find_not_in_set(val):\n",
    "    return f\"El argumento {val!r} para el método find_partition no está presente en esta estructura\"\n",
    "\n",
    "\n",
    "def _err_invalid_arg(method: str, param: str, val):\n",
    "    return (\n",
    "        f\"Argumento inválido en '{method}': el parámetro '{param}' recibió el valor inválido {val!r}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Clase principal\n",
    "class UnionFindTrees:\n",
    "    \"\"\"\n",
    "    Bosque de conjuntos disjuntos con punteros a padres, compresión de caminos y unión por rango.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    initial_set : Iterable[T] | None\n",
    "        Elementos iniciales; cada uno comienza como singleton.\n",
    "        Se rechazan explícitamente `str`, `bytes` y `Mapping`\n",
    "        para evitar confusiones con iterables \"engañosos\".\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"_parent\", \"_rank\")\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, initial_set: ABCIterable[T] | None = None) -> None:\n",
    "        if initial_set is None:\n",
    "            initial_set = []\n",
    "\n",
    "        # Rechazar textuales y mappings engañosos\n",
    "        if isinstance(initial_set, (str, bytes)) or isinstance(initial_set, Mapping):\n",
    "            raise UnionFindError(_err_ctor_illegal(initial_set))\n",
    "\n",
    "        # Validar que sea iterable\n",
    "        try:\n",
    "            iterator = iter(initial_set)\n",
    "        except TypeError:  # pragma: no cover\n",
    "            raise UnionFindError(_err_ctor_illegal(initial_set)) from None\n",
    "\n",
    "        # Inicializar estructuras\n",
    "        self._parent: Dict[T, T] = {}\n",
    "        self._rank: Dict[T, int] = {}\n",
    "\n",
    "        # Cargar elementos de forma segura\n",
    "        for elem in iterator:\n",
    "            if elem is None:\n",
    "                raise UnionFindError(_err_ctor_illegal(elem))\n",
    "            if elem in self._parent:\n",
    "                raise UnionFindError(_err_ctor_duplicate(elem))\n",
    "            self._parent[elem] = elem  # se apunta a sí mismo\n",
    "            self._rank[elem] = 1       # rango inicial\n",
    "\n",
    "    # Metaprotocolos útiles\n",
    "    def __len__(self) -> int:          # len(uf)\n",
    "        return len(self._parent)\n",
    "\n",
    "    def __contains__(self, elem: T) -> bool:  # elem in uf\n",
    "        return elem in self._parent\n",
    "\n",
    "    def __iter__(self) -> Iterator[T]:  # for x in uf\n",
    "        return iter(self._parent)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        roots = {r for r in self._parent.values() if r == self._parent[r]}\n",
    "        return f\"{self.__class__.__name__}(n={len(self)}, conjuntos={len(roots)})\"\n",
    "\n",
    "    # Alias explícito\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Alias para obtener el tamaño (número de elementos).\"\"\"\n",
    "        return len(self)\n",
    "\n",
    "    # Función interna para validar elementos\n",
    "    def _validate_elem(self, method: str, param: str, elem: T) -> None:\n",
    "        if elem is None:\n",
    "            raise UnionFindError(_err_invalid_arg(method, param, elem))\n",
    "        if elem not in self._parent:\n",
    "            raise UnionFindError(_err_find_not_in_set(elem))\n",
    "\n",
    "    # API pública\n",
    "    def add(self, elem: T, /) -> bool:\n",
    "        \"\"\"Inserta `elem` como singleton. True ⇒ añadido; False ⇒ ya existía.\"\"\"\n",
    "        if elem is None:\n",
    "            raise UnionFindError(_err_invalid_arg(\"add\", \"elem\", elem))\n",
    "        if elem in self._parent:\n",
    "            return False\n",
    "        self._parent[elem] = elem\n",
    "        self._rank[elem] = 1\n",
    "        return True\n",
    "\n",
    "    def find_partition(self, elem: T, /) -> T:\n",
    "        \"\"\"Devuelve la raíz (representante) de la partición que contiene `elem`.\"\"\"\n",
    "        self._validate_elem(\"find_partition\", \"elem\", elem)\n",
    "\n",
    "        # Compresión de caminos iterativa\n",
    "        root = elem\n",
    "        while root != self._parent[root]:\n",
    "            root = self._parent[root]\n",
    "\n",
    "        # Pasada para comprimir rutas\n",
    "        while elem != root:\n",
    "            parent = self._parent[elem]\n",
    "            self._parent[elem] = root\n",
    "            elem = parent\n",
    "\n",
    "        return root\n",
    "\n",
    "    def merge(self, elem1: T, elem2: T, /) -> bool:\n",
    "        \"\"\"\n",
    "        Une las particiones que contienen `elem1` y `elem2`.\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        True  - si las particiones eran distintas y se fusionaron.  \n",
    "        False - si ya pertenecían a la misma partición.\n",
    "        \"\"\"\n",
    "        r1 = self.find_partition(elem1)\n",
    "        r2 = self.find_partition(elem2)\n",
    "        if r1 == r2:\n",
    "            return False\n",
    "\n",
    "        # Unión por rango: el árbol de menor rango apunta al de mayor\n",
    "        if self._rank[r1] < self._rank[r2]:\n",
    "            r1, r2 = r2, r1\n",
    "\n",
    "        self._parent[r2] = r1\n",
    "        self._rank[r1] += self._rank[r2]\n",
    "        return True\n",
    "\n",
    "    def are_disjoint(self, elem1: T, elem2: T, /) -> bool:\n",
    "        \"\"\"True si `elem1` y `elem2` están en particiones distintas.\"\"\"\n",
    "        return self.find_partition(elem1) != self.find_partition(elem2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ac1ec-84ac-44ec-9ee3-11e4175f47a2",
   "metadata": {},
   "source": [
    "Esta implementación de **Union-Find** (o Disjoint‐Set Forest) ofrece una estructura eficiente para gestionar particiones dinámicas de un conjunto de elementos mediante dos heurísticas clásicas: compresión de caminos e unión por rango.  \n",
    "\n",
    "1. **Definición de la excepción y mensajes de error**  \n",
    "   - Se crea una excepción propia `UnionFindError`, que hereda de `TypeError` para señalizar usos inválidos de la API (parámetros nulos, elementos ausentes, duplicados, tipos no permitidos).  \n",
    "   - Cuatro funciones auxiliares (`_err_ctor_illegal`, `_err_ctor_duplicate`, `_err_find_not_in_set`, `_err_invalid_arg`) generan mensajes claros en tiempo de ejecución, usando `!r` para representar con comillas literales los valores problemáticos.\n",
    "\n",
    "2. **Almacenamiento interno**  \n",
    "   - Se emplean dos diccionarios:  \n",
    "     - `_parent: Dict[T, T]`, que para cada elemento almacena su puntero al padre (o a sí mismo si es raíz).  \n",
    "     - `_rank: Dict[T, int]`, que mantiene un valor heurístico de \"rango\" (aproximación al tamaño del subárbol) para decidir la raíz en las uniones.  \n",
    "   - El constructor valida exhaustivamente el `initial_set`:  \n",
    "     - Rechaza strings, bytes y cualquier `Mapping`.  \n",
    "     - Asegura que el argumento sea iterable (captura `TypeError` al llamar `iter`).  \n",
    "     - Parcela `None` y duplicados, lanzando `UnionFindError` con mensaje apropiado.  \n",
    "     - Inicializa cada elemento como su propia raíz (`_parent[elem] = elem`) con rango 1.\n",
    "\n",
    "3. **Metaprotocolos de Python**  \n",
    "   - `__len__` devuelve el número total de elementos registrados.  \n",
    "   - `__contains__` y `__iter__` permiten usar `elem in uf` y `for x in uf`.  \n",
    "   - `__repr__` sintetiza el estado mostrando cuántos conjuntos hay (`sets=…`) y cuántos elementos (`n=…`).\n",
    "\n",
    "4. **Validación interna de parámetros**  \n",
    "   - `_validate_elem` centraliza la comprobación de que un elemento no sea `None` y exista en `_parent`, lanzando la excepción con mensaje personalizado.\n",
    "\n",
    "5. **Operaciones clave**  \n",
    "   - `add(elem)`: inserta un nuevo singleton, devolviendo `True` si fue añadido y `False` si ya existía. Valida `None`.  \n",
    "   - `find_partition(elem)`:  \n",
    "     - Primera fase: recorre punteros padre hasta hallar la raíz (condición `root != parent[root]`).  \n",
    "     - Segunda fase: vuelve al elemento original y redirige cada puntero intermedio directamente a la raíz, comprimiendo caminos.  \n",
    "     - Ambos bucles son lineales en la profundidad original, pero la compresión de caminos amortiza la complejidad a prácticamente constante inversa de la función de Ackermann, α(m,n).  \n",
    "   - `merge(elem1, elem2)`:  \n",
    "     - Obtiene las raíces `r1`, `r2` con `find_partition`.  \n",
    "     - Si son iguales, retorna `False` (ya unidos).  \n",
    "     - Si no, compara rangos y hace la raíz de mayor rango el padre de la otra, actualizando `_parent[r2] = r1` y sumando rangos: `_rank[r1] += _rank[r2]`.  \n",
    "     - Esta heurística garantiza altura logarítmica en el peor caso y tiempo constante amortizado.  \n",
    "   - `are_disjoint(a,b)`: compara raíces para saber si viven en conjuntos distintos.\n",
    "\n",
    "Cada método arroja `UnionFindError` con mensajes claros cuando se violan las precondiciones, haciendo que la depuración sea sencilla y el uso de la estructura robusto en escenarios reales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9dabd-265d-448f-9389-701ec3882d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf = UnionFindTrees(['a', 'b', 'c'])\n",
    "uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbe79d-860f-4bf3-8582-e5c160cba537",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf.add('d')      # nuevo ⇒ True\n",
    "uf.add('a')      # 'a' ya existe ⇒ False\n",
    "len(uf)          # alias de uf.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd50c3-846d-462d-b8e2-1b0fbc797e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a y b estaban en sets distintos\n",
    "uf.merge('a', 'b')\n",
    "uf.merge('a', 'b')   # ya unidas → False\n",
    "\n",
    "# estado rápido\n",
    "print(uf)     # __repr__ muestra elementos y nº de conjuntos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22a362-9f5f-4352-9cf3-4eb76a7d934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uf.find_partition('a')      # raíz representante (compresión de caminos)\n",
    "uf.are_disjoint('a', 'b') # 'a' y 'b' comparten raíz\n",
    "uf.are_disjoint('a', 'c')      # aún separados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cacfeb-4d42-4e9e-934c-9526ea03166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'c' in uf\n",
    "for x in uf:          # iterar elementos\n",
    "    print(x, uf.find_partition(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3c21d-e81a-422e-bcad-946c72ade2df",
   "metadata": {},
   "source": [
    "**Uso en Kruskal’s Minimum Spanning Tree**  \n",
    "\n",
    "Para construir un **árbol de expansión mínima** en un grafo no dirigido, el algoritmo de Kruskal sigue estos pasos:  \n",
    "\n",
    "1. **Inicialización**: Crea un `UnionFindTrees` con todos los vértices del grafo. Cada vértice empieza en su propio conjunto.  \n",
    "2. **Ordenación de aristas**: Lista todas las aristas `(u,v,w)` y ordenarlas por peso `w` ascendente.  \n",
    "3. **Iteración sobre aristas**:  \n",
    "   - Para cada arista `(u,v,w)` en orden, llama a `find_partition(u)` y `find_partition(v)`.  \n",
    "   - Si las raíces difieren (uso de `are_disjoint(u,v)`), incluye la arista en el árbol resultante y ejecute `merge(u,v)`.  \n",
    "   - Si las raíces coinciden, omite la arista para evitar ciclos.  \n",
    "4. **Finalización**: Al procesar todas las aristas o alcanzar `n-1` aristas unidas, el conjunto de aristas acumuladas forma el MST.  \n",
    "\n",
    "La eficiencia global es $O(E\\log E)$ por la ordenación, mientras que las operaciones de unión y búsqueda cuestan aproximadamente $O(\\alpha(n))$, esencialmente constante. Donde $\\alpha$ hace referencia a la **función inversa de Ackermann**. \n",
    "\n",
    ">Nota:\n",
    ">1. **Ackermann** es una función recursiva extremadamente creciente (más rápida que cualquier función exponencial o factorial).\n",
    ">2. 2. **Su inversa**, $\\alpha(n)$, crece tan lentamente que para cualquier valor práctico de `n` (incluso `n` del tamaño de átomos en el universo), $\\alpha(n)\\leq 4$ o $5$.  \n",
    "\n",
    "Algunos puntos clave:\n",
    "\n",
    "- Cuando decimos que cada operación de **find** o **union** cuesta $O(\\alpha(n))$, estamos diciendo que, en el peor caso amortizado, su coste **crece aún más despacio** que cualquier logaritmo.  \n",
    "- En la práctica, puedes considerarlo **\"casi constante\"**, puesto que $\\alpha(n)$ apenas aumenta al crecer `n` por ejemplo:\n",
    "  \n",
    "  - Si $n=10^3$, $\\alpha(n)=3$  \n",
    "  - Si $n=10^8$, $\\alpha(n)=4$  \n",
    "  - Si $n\\approx 10^{10}$, $\\alpha(n)$ apenas llega a 5.  \n",
    "\n",
    "Por eso, aunque teóricamente no sea **O(1)**, en la práctica el sobrecoste por cada llamada es insignificante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053b22a-db05-4d65-b16d-2d89c87cf31a",
   "metadata": {},
   "source": [
    "**Uso en clustering aglomerativo jerárquico**\n",
    "\n",
    "En **clustering aglomerativo**, deseamos fusionar iterativamente los clústeres más similares hasta formar una jerarquía:  \n",
    "\n",
    "1. **Inicialización**: Cada punto de datos `x[i]` se añade a `UnionFindTrees` como clúster singleton.  \n",
    "2. **Matriz de distancias**: Calcula la similitud o distancia entre todos los pares de puntos.  \n",
    "3. **Selección de clústeres a fusionar**:  \n",
    "   - Encuentra el par de clústeres `(C_a, C_b)` con la menor distancia según el criterio elegido (enlace simple, completo, promedio, Ward, etc.).  \n",
    "   - Extrae un representante cualquiera de `C_a` y `C_b` (por ejemplo, un punto de cada conjunto). Use `find_partition` para identificar su raíz y comprobar si ya comparten clúster.  \n",
    "   - Si son disjuntos, registra la fusión en el dendrograma y ejecuta `merge(elem_a, elem_b)`.  \n",
    "4. **Actualización de distancias**:  \n",
    "   - Después de fusionar, actualiza las distancias entre el nuevo clúster unido y el resto, según la estrategia de enlace.  \n",
    "   - Repite la selección y fusión hasta que quede un solo clúster o se alcance el número deseado.  \n",
    "\n",
    "El uso de **Union-Find** aquí evita reconstruir conjuntos desde cero: cada `merge` actualiza punteros en tiempo amortizado casi constante, mientras que `find_partition` identifica rápidamente a qué clúster pertenece cada punto. Esto permite llevar un registro eficiente de la partición de los datos en cada paso de la jerarquía, y facilita operaciones de consulta de pertenencia de puntos a clústeres sin tareas de búsqueda costosas en estructuras de datos explícitas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfe2c2-c349-428a-a581-ce50d95673b5",
   "metadata": {},
   "source": [
    "### **Aplicaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16598e55-7ab1-4e86-a87b-e6936cd8169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections.abc import Iterable as ABCIterable, Mapping\n",
    "from typing import Dict, TypeVar, Generic, List, Tuple\n",
    "\n",
    "T = TypeVar(\"T\", bound=object)\n",
    "\n",
    "class UnionFindError(TypeError):\n",
    "    \"\"\"Excepción personalizada para errores en UnionFind.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def _err_ctor_illegal(val):\n",
    "    return f\"Argumento ilegal para el constructor: {val!r}\"\n",
    "\n",
    "def _err_ctor_duplicate(val):\n",
    "    return f\"Elemento duplicado en el conjunto inicial: {val!r}\"\n",
    "\n",
    "def _err_find_not_in_set(val):\n",
    "    return f\"El argumento {val!r} no está presente en la estructura UnionFind\"\n",
    "\n",
    "def _err_invalid_arg(method: str, param: str, val):\n",
    "    return f\"Argumento inválido en '{method}': parámetro '{param}' recibió valor {val!r}\"\n",
    "\n",
    "class UnionFindTrees(Generic[T]):\n",
    "    \"\"\"\n",
    "    Estructura Disjoint-Set con compresión de ruta y unión por rango.\n",
    "    \"\"\"\n",
    "    __slots__ = (\"_parent\", \"_rank\")\n",
    "\n",
    "    def __init__(self, initial_set: ABCIterable[T] = None) -> None:\n",
    "        if initial_set is None:\n",
    "            initial_set = []\n",
    "        if isinstance(initial_set, (str, bytes, Mapping)):\n",
    "            raise UnionFindError(_err_ctor_illegal(initial_set))\n",
    "        try:\n",
    "            iterator = iter(initial_set)\n",
    "        except TypeError:\n",
    "            raise UnionFindError(_err_ctor_illegal(initial_set))\n",
    "\n",
    "        self._parent: Dict[T, T] = {}\n",
    "        self._rank: Dict[T, int] = {}\n",
    "        for e in iterator:\n",
    "            if e is None:\n",
    "                raise UnionFindError(_err_ctor_illegal(e))\n",
    "            if e in self._parent:\n",
    "                raise UnionFindError(_err_ctor_duplicate(e))\n",
    "            self._parent[e] = e\n",
    "            self._rank[e] = 1\n",
    "\n",
    "    def find_partition(self, elem: T) -> T:\n",
    "        \"\"\"\n",
    "        Encuentra el representante (raíz) del conjunto al que pertenece elem,\n",
    "        aplicando compresión de ruta.\n",
    "        \"\"\"\n",
    "        if elem is None or elem not in self._parent:\n",
    "            raise UnionFindError(_err_find_not_in_set(elem))\n",
    "        root = elem\n",
    "        while root != self._parent[root]:\n",
    "            root = self._parent[root]\n",
    "        while elem != root:\n",
    "            parent = self._parent[elem]\n",
    "            self._parent[elem] = root\n",
    "            elem = parent\n",
    "        return root\n",
    "\n",
    "    def merge(self, a: T, b: T) -> bool:\n",
    "        \"\"\"\n",
    "        Une los conjuntos que contienen a y b. Devuelve True si se unieron,\n",
    "        False si ya estaban en el mismo conjunto.\n",
    "        \"\"\"\n",
    "        r1 = self.find_partition(a)\n",
    "        r2 = self.find_partition(b)\n",
    "        if r1 == r2:\n",
    "            return False\n",
    "        if self._rank[r1] < self._rank[r2]:\n",
    "            r1, r2 = r2, r1\n",
    "        self._parent[r2] = r1\n",
    "        self._rank[r1] += self._rank[r2]\n",
    "        return True\n",
    "\n",
    "class Graph(Generic[T]):\n",
    "    \"\"\"\n",
    "    Grafo no dirigido con pesos opcionales en las aristas.\n",
    "    \"\"\"\n",
    "    def __init__(self, vertices: ABCIterable[T] = None) -> None:\n",
    "        self.adj: Dict[T, List[Tuple[T, float]]] = {}\n",
    "        self.edges: List[Tuple[float, T, T]] = []\n",
    "        if vertices:\n",
    "            for v in vertices:\n",
    "                self.add_vertex(v)\n",
    "\n",
    "    def add_vertex(self, v: T) -> None:\n",
    "        if v not in self.adj:\n",
    "            self.adj[v] = []\n",
    "\n",
    "    def add_edge(self, u: T, v: T, weight: float = 1.0) -> None:\n",
    "        self.add_vertex(u)\n",
    "        self.add_vertex(v)\n",
    "        self.adj[u].append((v, weight))\n",
    "        self.adj[v].append((u, weight))\n",
    "        self.edges.append((weight, u, v))\n",
    "\n",
    "    def vertices(self) -> List[T]:\n",
    "        return list(self.adj.keys())\n",
    "\n",
    "    def connected_components_dfs(self) -> List[List[T]]:\n",
    "        visited = set()\n",
    "        components: List[List[T]] = []\n",
    "        def dfs(u: T, comp: List[T]):\n",
    "            visited.add(u)\n",
    "            comp.append(u)\n",
    "            for v, _ in self.adj[u]:\n",
    "                if v not in visited:\n",
    "                    dfs(v, comp)\n",
    "        for u in self.adj:\n",
    "            if u not in visited:\n",
    "                comp: List[T] = []\n",
    "                dfs(u, comp)\n",
    "                components.append(comp)\n",
    "        return components\n",
    "\n",
    "    def connected_components_unionfind(self) -> List[List[T]]:\n",
    "        uf = UnionFindTrees(self.vertices())\n",
    "        for _, u, v in self.edges:\n",
    "            uf.merge(u, v)\n",
    "        comps: Dict[T, List[T]] = {}\n",
    "        for v in self.vertices():\n",
    "            root = uf.find_partition(v)\n",
    "            comps.setdefault(root, []).append(v)\n",
    "        return list(comps.values())\n",
    "\n",
    "    def kruskal_mst(self) -> List[Tuple[T, T, float]]:\n",
    "        mst: List[Tuple[T, T, float]] = []\n",
    "        uf = UnionFindTrees(self.vertices())\n",
    "        for weight, u, v in sorted(self.edges, key=lambda x: x[0]):\n",
    "            if uf.find_partition(u) != uf.find_partition(v):\n",
    "                uf.merge(u, v)\n",
    "                mst.append((u, v, weight))\n",
    "        return mst\n",
    "\n",
    "    def cluster_by_kruskal(self, k: int) -> List[List[T]]:\n",
    "        uf = UnionFindTrees(self.vertices())\n",
    "        edges_desc = sorted(self.edges, key=lambda x: x[0], reverse=True)\n",
    "        removed = 0\n",
    "        for weight, u, v in edges_desc:\n",
    "            if uf.find_partition(u) != uf.find_partition(v):\n",
    "                uf.merge(u, v)\n",
    "                removed += 1\n",
    "                if removed == len(self.vertices()) - k:\n",
    "                    break\n",
    "        comps: Dict[T, List[T]] = {}\n",
    "        for v in self.vertices():\n",
    "            root = uf.find_partition(v)\n",
    "            comps.setdefault(root, []).append(v)\n",
    "        return list(comps.values())\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Graph(V={len(self.adj)}, E={len(self.edges)})\"\n",
    "\n",
    "#Funciones de visualización\n",
    "def to_networkx(g: Graph[T]) -> nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(g.vertices())\n",
    "    for weight, u, v in g.edges:\n",
    "        G.add_edge(u, v, weight=weight)\n",
    "    return G\n",
    "\n",
    "def draw_components(g: Graph[T], method: str = 'dfs') -> None:\n",
    "    G = to_networkx(g)\n",
    "    comps = (g.connected_components_unionfind() if method == 'unionfind'\n",
    "             else g.connected_components_dfs())\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    plt.figure()\n",
    "    for comp in comps:\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=comp, node_size=300)\n",
    "    nx.draw_networkx_edges(G, pos)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    plt.title(f\"Componentes conexas ({method})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def draw_mst(g: Graph[T]) -> None:\n",
    "    G = to_networkx(g)\n",
    "    mst_edges = [(u, v) for u, v, _ in g.kruskal_mst()]\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    plt.figure()\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=300)\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=mst_edges, width=2)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    plt.title(\"Árbol de recubrimiento mínimo\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def draw_clusters(g: Graph[T], k: int) -> None:\n",
    "    G = to_networkx(g)\n",
    "    clusters = g.cluster_by_kruskal(k)\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    plt.figure()\n",
    "    for cluster in clusters:\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=cluster, node_size=300)\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    plt.title(f\"Clustering por Kruskal (k={k})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Ejemplos de uso más complejos\n",
    "\n",
    "# Ejemplo 1: Grafo numérico pequeño\n",
    "print(\"\\nEjemplo 1: Grafo numérico\")\n",
    "g1 = Graph([1, 2, 3, 4, 5, 6])\n",
    "edges1 = [(1,2,1.0),(2,3,2.5),(4,5,1.2),(5,6,3.0),(3,4,2.0)]\n",
    "for u,v,w in edges1:\n",
    "    g1.add_edge(u, v, w)\n",
    "print(g1)\n",
    "print(\"Componentes (DFS):\", g1.connected_components_dfs())\n",
    "print(\"Componentes (UF):\", g1.connected_components_unionfind())\n",
    "print(\"MST:\", g1.kruskal_mst())\n",
    "print(\"Clusters k=2:\", g1.cluster_by_kruskal(2))\n",
    "draw_components(g1, method='dfs')\n",
    "draw_mst(g1)\n",
    "\n",
    "# Ejemplo 2: Grafo de cadenas y clustering k=3\n",
    "print(\"\\nEjemplo 2: Grafo con vértices tipo str\")\n",
    "vertices2 = ['A','B','C','D','E','F','G','H']\n",
    "g2 = Graph(vertices2)\n",
    "for (u,v),w in {('A','B'):2,('B','C'):1,('C','D'):3,('A','E'):2.5,('E','F'):0.5,('G','H'):4}.items():\n",
    "    g2.add_edge(u, v, w)\n",
    "print(g2)\n",
    "print(\"Componentes (DFS):\", g2.connected_components_dfs())\n",
    "print(\"MST:\", g2.kruskal_mst())\n",
    "draw_clusters(g2, k=3)\n",
    "\n",
    "# Ejemplo 3: Manejo de errores en UnionFind\n",
    "print(\"\\nEjemplo 3: Errores UnionFind\")\n",
    "uf = UnionFindTrees([1,2,3])\n",
    "try:\n",
    "    uf.find_partition(4)\n",
    "except UnionFindError as err:\n",
    "    print(\"Error detectado:\", err)\n",
    "# Unión válida vs redundante\n",
    "print(\"Merge 1-2:\", uf.merge(1,2))\n",
    "print(\"Merge 1-2 de nuevo (debería ser False):\", uf.merge(1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12594d97-1f5e-4591-961a-d15615fc3f02",
   "metadata": {},
   "source": [
    "### **Ejercicios** \n",
    "\n",
    "#### 1. Kruskal \"industrial-grade\" con *UnionFindTrees*  \n",
    "Una empresa de telecomunicaciones va a desplegar fibra óptica en 20 000 ciudades conectadas por 300 000 posibles enlaces. Cada enlace tiene un coste de instalación y un \"tiempo de vida\" previsto. Necesitan un MST (Minimum Spanning Tree) que minimice coste y, a igualdad de coste, maximice longevidad. La decisión debe tomarse cada noche con los datos del día.  \n",
    "\n",
    "**Tareas.**  \n",
    "\n",
    "* Añade a `UnionFindTrees` un método `bulk_add(iterable)` que inserte masivamente nodos nuevos en **O(n)** amortizado sin invalidar rangos previos.  \n",
    "* Implementa `kruskal_mst(edges, *, tie_break='max_life') -> list[Edge]`, donde los empates en coste se resuelven con un comparador secundario (p. ej. mayor longevidad).  \n",
    "* Diseña pruebas unitarias parametrizadas (`pytest.mark.parametrize`) que verifiquen:  \n",
    "  1. Correctitud del peso total.  \n",
    "  2. Invariante de aciclicidad.  \n",
    "  3. Uso estable del comparador secundario.  \n",
    "* Crea un *benchmark* con `pytest-benchmark` que compare la versión clásica frente a tu versión con `bulk_add` en grafos Erdős-Rényi de 10 K-40 K vértices.  \n",
    "\n",
    "#### 2. **k-Clustering** jerárquico con *UnionFindLists*  \n",
    "En un sistema de recomendación de música se representan 150 000 canciones como puntos en $R^2$ (t-SNE). Quieren agruparlas con *single-linkage* hasta obtener exactamente *k* clústeres para experimentos A/B.  \n",
    "**Tareas.**  \n",
    "\n",
    "* Implementa `single_linkage(points, k)` reutilizando `UnionFindLists.merge`; detén el algoritmo cuando queden *k* particiones.  \n",
    "* Añade un método `groups()` que devuelva las particiones ordenadas por tamaño descendente.  \n",
    "* Integra un visualizador opcional que coloree cada clúster (usa *matplotlib*; **no** se evalúa en CI, pero documenta cómo activarlo).  \n",
    "* Analiza teóricamente la complejidad O(min |A|, |B|) de cada fusión y discute cuándo *UnionFindTrees* sería preferible.  \n",
    "\n",
    "\n",
    "#### 3. **MST dinámico** con operaciones *undo* (DSU-Rollback)  \n",
    " Para simulaciones de resiliencia de redes eléctricas se necesitan consultas *offline* del MST bajo inserción y eliminación temporal de aristas. Se conocen de antemano *q* consultas tipo \"añadir arista\" / \"deshacer última\"/\"preguntar peso MST\".  \n",
    "\n",
    "**Tareas.**  \n",
    "\n",
    "* Extiende `UnionFindTrees` con una pila de operaciones que guarde pares *(hijo, padre, rango_prev)*.  \n",
    "* Implementa `rollback()` en **O(1)** que revierte la última `merge`.  \n",
    "* Desarrolla `offline_mst(queries)` (divide-y-vencerás sobre el intervalo de consultas) y demuestra que responde en $O((n + m) \\log n)$.  \n",
    "* Redacta pruebas que cubran la secuencia de *rollback* hasta el estado inicial y verifiquen integridad de rangos.  \n",
    "\n",
    "\n",
    "#### 4. **Borůvka paralelo** con *UnionFindTrees* thread-safe  \n",
    "Un *render-farm* genera diariamente mallas 3D con hasta 50 M aristas. El pipeline se ejecuta en un clúster con 64 hilos y necesita el MST para simplificar mallas antes de la transmisión de vídeo.  \n",
    "\n",
    "**Tareas.**  \n",
    "\n",
    "* Haz `UnionFindTrees` seguro para concurrencia con *lock striping* (por bucket hash).  \n",
    "* Implementa Borůvka multi-hilo: cada hilo busca la arista mínima saliente de su componente; sincroniza fusiones con CAS o `threading.Lock`.  \n",
    "* Mide *speed-up* y *scaling efficiency* (8, 16, 32, 64 hilos) frente a Kruskal secuencial.  \n",
    "* Entrega informe de 1 000 palabras sobre bottlenecks y afinamiento de granularidad de locks.  \n",
    "\n",
    "#### 5. **Segmentación de imágenes** por componentes conexas (CCA)  \n",
    "Para un proyecto de visión computacional se deben etiquetar todas las regiones blancas en un mapa binario de 4 096 × 4 096 píxeles.  \n",
    "**Tareas.**  \n",
    "\n",
    "* Escribe `label_components(bitmap)` que recorra la imagen en *raster-scan* y use `DisjointSet.merge` para unir píxeles vecinos 4-conexos.  \n",
    "* Tras el primer pase, haz un segundo barrido que re-mapee cada componente a un entero consecutivo.  \n",
    "* Calcula memoria máxima usada y demuestra que el algoritmo es $O(N \\alpha(N))$.  \n",
    "\n",
    "#### 6. **Algoritmo de *k*-clique-percolation** en grafos sociales  \n",
    "Para analizar comunidades en un grafo de 2 M vértices se busca el método de *clique percolation*: dos k-cliques se unen si comparten k-1 vértices.  \n",
    "**Tareas.**  \n",
    "\n",
    "* Genera todas las 4-cliques con *pivot-branching*; asigna un id incremental a cada una.  \n",
    "* Usa `UnionFindTrees.merge` para fusionar ids de cliques que percolan.  \n",
    "* Devuelve el conteo y la distribución de tamaños de comunidades.  \n",
    "* Optimiza para memoria restringida guardando solo ids de vértices ordenados y usando hashing incremental.  \n",
    "\n",
    "\n",
    "#### 7. **Detección de *percolación* en redes hexagonales**  \n",
    "En física estadística se estudia si existe un camino de sitios ocupados que conecte de arriba hacia abajo en una malla hexagonal $L\\times L$.  \n",
    "**Tareas.**  \n",
    "\n",
    "* Modela la malla como un conjunto de sitios con índices (q, r).  \n",
    "* Inserta un sitio ocupado │-> `add` + conexiones a sus seis vecinos.  \n",
    "* Tras cada inserción responde en $O(\\alpha(N))$ si \"percola\" (las particiones de la fila superior e inferior comparten raíz).  \n",
    "* Simula 10 000 corridas Monte-Carlo y estima $p_n^{*}$ (probabilidad crítica) para L = 128.  \n",
    "\n",
    "\n",
    "#### 8. **Persistencia distribuida de particiones** con *hash-ring*  \n",
    "Un sistema de *microservicios* mantiene su estado de conectividad en 256 shards. Cada shard aloja un sub-DSU que debe sincronizarse cada minuto con sus vecinos inmediatos en el hash-ring.  \n",
    "**Tareas.**  \n",
    "\n",
    "* Serializa cada sub-DSU (`pickle` o JSON propio) y publícalo en Kafka.  \n",
    "* Implementa reconciliación incremental: solo se envían pares *(elem, nueva_raíz)* si la raíz cambió.  \n",
    "* Exhibe pruebas de consistencia eventual en presencia de particiones de red (usa `tox` + Docker Compose).  \n",
    "\n",
    "**Recomendaciones de entrega**\n",
    "\n",
    "* **Estructura** tu repositorio con `src/`, `tests/`, `benchmarks/` y `docs/`.  \n",
    "* Configura **CI/CD** en GitHub Actions que ejecute pytest, linters y, si procede, *stress tests* con límites de tiempo.  \n",
    "* Incluye *type hints* (`mypy --strict`) y asegura $\\geq$ 95 % de cobertura.  \n",
    "* Documenta en un `README.md` cada ejercicio con instrucciones para reproducir resultados y scripts de generación de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3afa1d-dcdb-4c36-bbfe-e55fcb2fb7fa",
   "metadata": {},
   "source": [
    "Presenta tus respuestas en tu repositorio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
