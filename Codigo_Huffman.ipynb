{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bbc90a7-01fe-4972-86aa-47a3d1e4e87f",
   "metadata": {},
   "source": [
    "### Teoría sobre la codificación de Huffman\n",
    "\n",
    "El **algoritmo de Huffman** es uno de los métodos más conocidos para la compresión de datos sin pérdidas. \n",
    "A grandes rasgos, se basa en:\n",
    "\n",
    "1. **Calcular la frecuencia** de aparición de cada carácter en el texto de entrada.\n",
    "2. **Crear nodos hoja** para cada carácter, etiquetados con su frecuencia.\n",
    "3. **Usar una cola de prioridad (min-heap)** para ir combinando de abajo hacia arriba los nodos de menor frecuencia:\n",
    "   - Extraemos los dos nodos de menor frecuencia.\n",
    "   - Creamos un nodo padre que los agrupe, con frecuencia igual a la suma de ambos.\n",
    "   - Insertamos de nuevo este nodo padre en la cola de prioridad.\n",
    "4. Al finalizar, **queda un solo nodo** en la cola, que es la raíz de nuestro árbol de Huffman.\n",
    "5. Para **codificar** cada carácter, se recorre el árbol desde la raíz hasta la hoja correspondiente:\n",
    "   - Se asigna `0` al ir por la rama izquierda.\n",
    "   - Se asigna `1` al ir por la rama derecha.\n",
    "   - La concatenación de esos bits es el **código Huffman** para dicho carácter.\n",
    "\n",
    "Este método produce **códigos más cortos** para los caracteres más frecuentes y **códigos más largos** para los menos frecuentes, logrando una compresión eficiente en muchos casos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e2007-ed2b-4c87-9bb9-4539b3a3a4b0",
   "metadata": {},
   "source": [
    "#### Pseudocódigo del algoritmo de Huffman\n",
    "\n",
    "Un código de Huffman es un árbol, construido de abajo hacia arriba, comenzando con la lista de diferentes caracteres que aparecen en un texto y su frecuencia. El algoritmo itera de la siguiente manera: \n",
    "\n",
    "- Selecciona y remueve de la lista los dos elementos con la frecuencia más baja.\n",
    "- Luego crea un nuevo nodo combinándolos (sumando las dos frecuencias).\n",
    "- Y finalmente agrega de nuevo el nuevo nodo a la lista. \n",
    "\n",
    "Aunque el árbol en sí no es un heap, un paso clave del algoritmo se basa en recuperar de forma eficiente los elementos más pequeños de la lista, así como en agregar nuevos elementos a la lista de manera eficiente.\n",
    "\n",
    "\n",
    "```\n",
    "function huffman(text) \n",
    "  charFrequenciesMap ← ComputeFrequencies(text) \n",
    "  priorityQueue ← MinHeap() \n",
    "  for (char, frequency) in charFrequenciesMap do \n",
    "    priorityQueue.insert(TreeNode([char], frequency)) \n",
    "  while priorityQueue.size > 1 do \n",
    "    left ← priorityQueue.top() \n",
    "    right ← priorityQueue.top() \n",
    "    parent ← TreeNode(left.chars + right.chars, \n",
    "                       left.frequency + right.frequency) \n",
    "    parent.left ← left \n",
    "    parent.right ← right \n",
    "    priorityQueue.insert(parent) \n",
    "  return buildTable(priorityQueue.top(), [], Map()) \n",
    "```\n",
    "\n",
    "> Cada `TreeNode`, de hecho, contiene dos campos (además de los punteros a sus hijos):  \n",
    "> - un **conjunto de caracteres**, y  \n",
    "> - la **frecuencia** de esos caracteres en el texto, calculada como la suma de las frecuencias de los caracteres individuales.\n",
    "\n",
    "**Construyendo una tabla a partir del árbol**\n",
    "\n",
    "```\n",
    "function buildTable(node, sequence, charactersToSequenceMap) \n",
    "  if node.characters.size == 1 then \n",
    "    charactersToSequenceMap[node.characters[0]] ← sequence  \n",
    "  else \n",
    "    if node.left <> null then \n",
    "      buildTable(node.left, 0 + sequence, charactersToSequenceMap)  \n",
    "    if node.right <> null then \n",
    "      buildTable(node.right, 1 + sequence, charactersToSequenceMap)  \n",
    "  return charactersToSequenceMap \n",
    "```\n",
    "\n",
    "> Estos pasos se repiten hasta que quede un solo elemento en la cola  y ese último elemento será el `TreeNode` que representa la **raíz del árbol final**.\n",
    "\n",
    "> Escribimos el método `buildTable` en forma **recursiva**.  Esto nos permite ofrecer un código más **limpio y fácil de entender**,  pero en algunos lenguajes las implementaciones concretas pueden ser más eficientes  si se implementan usando **iteraciones explícitas**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccee7b9-803c-4e84-92d5-81c7c1133e79",
   "metadata": {},
   "source": [
    "### Implementaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60648a-54ed-46b4-b05a-c6569565b708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "\n",
    "class DWayHeap(object):\n",
    "    def __init__(self, elements: List[Any] = [], priorities: List[float] = [], branching_factor: int = 2) -> None:\n",
    "        \"\"\"Constructor\n",
    "\n",
    "        Args:\n",
    "            elements: Los elementos para inicializar el heap.\n",
    "            priorities: Las prioridades de los elementos anteriores. Deben tener la misma longitud que `elements`.\n",
    "            branching_factor: El número (máximo) de hijos por nodo en el heap. Debe ser al menos 2.\n",
    "        \"\"\"\n",
    "        if len(elements) != len(priorities):\n",
    "            raise ValueError(f'La longitud de la lista de elementos ({len(elements)})'\n",
    "                             f' debe coincidir con la longitud de la lista de prioridades ({len(priorities)}).')\n",
    "        if branching_factor < 2:\n",
    "            raise ValueError(f'El factor de ramificación ({branching_factor}) debe ser mayor que 1.')\n",
    "        self._pairs: List[Tuple[float, Any]] = []\n",
    "        self.D = branching_factor\n",
    "\n",
    "        if len(elements) > 0:\n",
    "            self._heapify(elements, priorities)\n",
    "\n",
    "    def __sizeof__(self) -> int:\n",
    "        \"\"\"Tamaño del heap.\n",
    "\n",
    "        Returns: El número de elementos en el heap.\n",
    "        \"\"\"\n",
    "        return len(self)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Tamaño del heap.\n",
    "\n",
    "        Returns: El número de elementos en el heap.\n",
    "        \"\"\"\n",
    "        return len(self._pairs)\n",
    "\n",
    "    def _validate(self) -> bool:\n",
    "        \"\"\"Verifica que se cumplan las tres invariantes del heap:\n",
    "        1. Cada nodo tiene como máximo `D` hijos. (Garantizado por la construcción)\n",
    "        2. El árbol del heap es completo y alineado a la izquierda. (También garantizado por la construcción)\n",
    "        3. Cada nodo contiene la mayor prioridad en el subárbol con raíz en ese nodo.\n",
    "\n",
    "        Returns: True si se cumplen todas las invariantes del heap.\n",
    "        \"\"\"\n",
    "        current_index = 0\n",
    "        first_leaf = self.first_leaf_index()\n",
    "        while current_index < first_leaf:\n",
    "            current_priority: float = self._pairs[current_index][0]\n",
    "            first_child = self._first_child_index(current_index)\n",
    "            last_child_guard = min(first_child + self.D, len(self))\n",
    "            for child_index in range(first_child, last_child_guard):\n",
    "                if current_priority < self._pairs[child_index][0]:\n",
    "                    return False\n",
    "            current_index += 1\n",
    "        return True\n",
    "\n",
    "    def _push_down(self, index: int) -> None:\n",
    "        \"\"\"Empuja hacia abajo la raíz de un sub-heap hacia sus hojas para restablecer las invariantes del heap.\n",
    "        Si alguno de los hijos del elemento tiene mayor prioridad, se intercambia el elemento actual\n",
    "        con su hijo de mayor prioridad C, y se verifica recursivamente el sub-heap que estaba previamente\n",
    "        enraizado en ese C.\n",
    "\n",
    "        Args:\n",
    "            index: El índice de la raíz del sub-heap.\n",
    "        \"\"\"\n",
    "        assert (0 <= index < len(self._pairs))\n",
    "        input_pair = self._pairs[index]\n",
    "        input_priority = input_pair[0]\n",
    "        current_index = index\n",
    "        first_leaf = self.first_leaf_index()\n",
    "        while current_index < first_leaf:\n",
    "            child_index = self._highest_priority_child_index(current_index)\n",
    "            assert (child_index is not None)\n",
    "            if self._pairs[child_index][0] > input_priority:\n",
    "                self._pairs[current_index] = self._pairs[child_index]\n",
    "                current_index = child_index\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        self._pairs[current_index] = input_pair\n",
    "\n",
    "    def _bubble_up(self, index: int) -> None:\n",
    "        \"\"\"Eleva un elemento hacia la raíz para restablecer las invariantes del heap.\n",
    "        Si el padre P de un elemento tiene menor prioridad, se intercambian el elemento actual y su padre,\n",
    "        y se verifica recursivamente la posición que tenía P anteriormente.\n",
    "\n",
    "        Args:\n",
    "            index: El índice del elemento a elevar.\n",
    "        \"\"\"\n",
    "        assert (0 <= index < len(self._pairs))\n",
    "        input_pair = self._pairs[index]\n",
    "        input_priority = input_pair[0]\n",
    "        while index > 0:\n",
    "            parent_index = self._parent_index(index)\n",
    "            parent = self._pairs[parent_index]\n",
    "\n",
    "            if input_priority > parent[0]:\n",
    "                self._pairs[index] = parent\n",
    "                index = parent_index\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        self._pairs[index] = input_pair\n",
    "\n",
    "    def _first_child_index(self, index) -> int:\n",
    "        \"\"\"Calcula el índice del primer hijo de un nodo en el heap.\n",
    "\n",
    "        Args:\n",
    "            index: El índice del nodo actual, del cual se buscan los índices de sus hijos.\n",
    "\n",
    "        Returns: El índice del hijo más a la izquierda del nodo actual del heap.\n",
    "        \"\"\"\n",
    "        return index * self.D + 1\n",
    "\n",
    "    def _parent_index(self, index) -> int:\n",
    "        \"\"\"Calcula el índice del padre de un nodo en el heap.\n",
    "\n",
    "        Args:\n",
    "            index: El índice del nodo actual, del cual se busca el índice de su padre.\n",
    "\n",
    "        Returns: El índice del padre del nodo actual del heap.\n",
    "        \"\"\"\n",
    "        return (index - 1) // self.D\n",
    "\n",
    "    def _highest_priority_child_index(self, index) -> Optional[int]:\n",
    "        \"\"\"Encuentra, entre los hijos de un nodo del heap, el hijo con la mayor prioridad.\n",
    "        En caso de que varios hijos tengan la misma prioridad, se devuelve el más a la izquierda.\n",
    "\n",
    "        Args:\n",
    "            index: El índice del nodo del heap cuyos hijos se examinan.\n",
    "\n",
    "        Returns: El índice del hijo con mayor prioridad del nodo actual del heap, o None si\n",
    "                 el nodo actual no tiene hijos.\n",
    "        \"\"\"\n",
    "        first_index = self._first_child_index(index)\n",
    "        size = len(self)\n",
    "        last_index = min(first_index + self.D, size)\n",
    "\n",
    "        if first_index >= size:\n",
    "            return None\n",
    "\n",
    "        highest_priority = -float('inf')\n",
    "        index = first_index\n",
    "        for i in range(first_index, last_index):\n",
    "            if self._pairs[i][0] > highest_priority:\n",
    "                highest_priority = self._pairs[i][0]\n",
    "                index = i\n",
    "\n",
    "        return index\n",
    "\n",
    "    def first_leaf_index(self):\n",
    "        return (len(self) - 2) // self.D + 1\n",
    "\n",
    "    def _heapify(self, elements: List[Any], priorities: List[float]) -> None:\n",
    "        \"\"\"Inicializa el heap con una lista de elementos y prioridades.\n",
    "\n",
    "        Args:\n",
    "            elements: La lista de elementos a agregar al heap.\n",
    "            priorities: Las prioridades correspondientes a esos elementos (en el mismo orden).\n",
    "        \"\"\"\n",
    "        assert (len(elements) == len(priorities))\n",
    "        self._pairs = list(zip(priorities, elements))\n",
    "        last_inner_node_index = self.first_leaf_index() - 1\n",
    "        for index in range(last_inner_node_index, -1, -1):\n",
    "            self._push_down(index)\n",
    "\n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\"Verifica si el heap está vacío.\n",
    "\n",
    "        Returns: True si el heap está vacío.\n",
    "        \"\"\"\n",
    "        return len(self) == 0\n",
    "\n",
    "    def top(self) -> Any:\n",
    "        \"\"\"Elimina y devuelve el elemento con mayor prioridad en el heap.\n",
    "        Si el heap está vacío, lanza una `RuntimeError`.\n",
    "\n",
    "        Returns: El elemento con mayor prioridad en el heap.\n",
    "        \"\"\"\n",
    "        if self.is_empty():\n",
    "            raise RuntimeError('Se llamó al método top en un heap vacío.')\n",
    "        if len(self) == 1:\n",
    "            element = self._pairs.pop()[1]\n",
    "        else:\n",
    "            element = self._pairs[0][1]\n",
    "            self._pairs[0] = self._pairs.pop()\n",
    "            self._push_down(0)\n",
    "\n",
    "        return element\n",
    "\n",
    "    def peek(self) -> Any:\n",
    "        \"\"\"Devuelve, SIN eliminarlo, el elemento con mayor prioridad en el heap.\n",
    "        Si el heap está vacío, lanza una `RuntimeError`.\n",
    "\n",
    "        Returns: El elemento con mayor prioridad en el heap.\n",
    "        \"\"\"\n",
    "        if self.is_empty():\n",
    "            raise RuntimeError('Se llamó al método peek en un heap vacío.')\n",
    "        return self._pairs[0][1]\n",
    "\n",
    "    def insert(self, element: Any, priority: float) -> None:\n",
    "        \"\"\"Agrega un nuevo par elemento/prioridad al heap\n",
    "\n",
    "        Args:\n",
    "            element: El nuevo elemento a agregar.\n",
    "            priority: La prioridad asociada al nuevo elemento.\n",
    "        \"\"\"\n",
    "        self._pairs.append((priority, element))\n",
    "        self._bubble_up(len(self._pairs) - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39544e7-6a93-4726-8ae5-a4a687dfe6b6",
   "metadata": {},
   "source": [
    "####  HuffmanNode y funciones asociadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516442f7-ecc7-4c81-8027-1e54b4378007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class HuffmanNode(object):\n",
    "    def __init__(self, symbols: List[str], priority: float, left: Optional['HuffmanNode'] = None,\n",
    "                 right: Optional['HuffmanNode'] = None) -> None:\n",
    "        \"\"\"Constructor de un nodo para el árbol de Huffman.\n",
    "        \n",
    "        Args:\n",
    "            symbols: Lista de símbolos (caracteres) contenidos en el nodo.\n",
    "            priority: Valor de prioridad (frecuencia) asociado al nodo.\n",
    "            left: Nodo hijo izquierdo (opcional).\n",
    "            right: Nodo hijo derecho (opcional).\n",
    "        \"\"\"\n",
    "        self._symbols = symbols\n",
    "        self._priority = priority\n",
    "        self._left = left\n",
    "        self._right = right\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Representación oficial del nodo.\"\"\"\n",
    "        return f'({self._symbols}, {self._priority})'\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Representación en cadena del nodo, mostrando sus hijos.\"\"\"\n",
    "        return f'{repr(self)} -> ({self._left} | {self._right})'\n",
    "\n",
    "    def symbols(self) -> List[str]:\n",
    "        \"\"\"Devuelve la lista de símbolos contenidos en el nodo.\n",
    "        \n",
    "        Returns:\n",
    "            Lista de símbolos.\n",
    "        \"\"\"\n",
    "        return self._symbols\n",
    "\n",
    "    def priority(self) -> float:\n",
    "        \"\"\"Devuelve la prioridad (frecuencia) del nodo.\n",
    "        \n",
    "        Returns:\n",
    "            Valor de prioridad.\n",
    "        \"\"\"\n",
    "        return self._priority\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_left_path(inner_path: str) -> str:\n",
    "        \"\"\"Codifica la ruta agregando un 0 al inicio (para la rama izquierda).\n",
    "        \n",
    "        Args:\n",
    "            inner_path: La codificación interna.\n",
    "        \n",
    "        Returns:\n",
    "            La ruta codificada para la rama izquierda.\n",
    "        \"\"\"\n",
    "        return f'0{inner_path}'\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_right_path(inner_path: str) -> str:\n",
    "        \"\"\"Codifica la ruta agregando un 1 al inicio (para la rama derecha).\n",
    "        \n",
    "        Args:\n",
    "            inner_path: La codificación interna.\n",
    "        \n",
    "        Returns:\n",
    "            La ruta codificada para la rama derecha.\n",
    "        \"\"\"\n",
    "        return f'1{inner_path}'\n",
    "\n",
    "    def _validate(self) -> bool:\n",
    "        \"\"\"Valida la consistencia del nodo verificando que:\n",
    "           - La lista de símbolos sea la concatenación de la de sus hijos.\n",
    "           - La prioridad sea la suma de las prioridades de sus hijos.\n",
    "        \n",
    "        Returns:\n",
    "            True si el nodo es válido, False en caso contrario.\n",
    "        \"\"\"\n",
    "        left_symbols = self._left.symbols() if self._left else []\n",
    "        right_symbols = self._right.symbols() if self._right else []\n",
    "\n",
    "        left_priority = self._left.priority() if self._left else 0.\n",
    "        right_priority = self._right.priority() if self._right else 0.\n",
    "\n",
    "        if self.symbols() != left_symbols + right_symbols:\n",
    "            return False\n",
    "\n",
    "        if self.priority() != left_priority + right_priority:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def tree_encoding(self) -> Dict[str, str]:\n",
    "        \"\"\"Genera la codificación del árbol de Huffman.\n",
    "        \n",
    "        Returns:\n",
    "            Un diccionario que asocia cada símbolo a su cadena de codificación.\n",
    "        \"\"\"\n",
    "        left_encoding_table = {} if self._left is None else self._left.tree_encoding()\n",
    "        right_encoding_table = {} if self._right is None else self._right.tree_encoding()\n",
    "\n",
    "        encoding_table = {}\n",
    "\n",
    "        for key, path in left_encoding_table.items():\n",
    "            encoding_table[key] = HuffmanNode.encode_left_path(path)\n",
    "\n",
    "        for key, path in right_encoding_table.items():\n",
    "            encoding_table[key] = HuffmanNode.encode_right_path(path)\n",
    "\n",
    "        if len(self._symbols) == 1:\n",
    "            encoding_table[self.symbols()[0]] = \"\"\n",
    "\n",
    "        return encoding_table\n",
    "\n",
    "def _create_frequency_table(text: str) -> collections.Counter:\n",
    "    \"\"\"Dado un texto, crea una tabla de frecuencias que asocia cada caracter a su número de ocurrencias.\n",
    "    \n",
    "    Args:\n",
    "        text: Texto de entrada.\n",
    "    \n",
    "    Returns:\n",
    "        Un objeto Counter con la frecuencia de cada caracter.\n",
    "    \"\"\"\n",
    "    return collections.Counter(text)\n",
    "\n",
    "def _frequency_table_to_heap(ft: collections.Counter, branching_factor: int = 2) -> DWayHeap:\n",
    "    \"\"\"Convierte una tabla de frecuencias en un heap cuyos elementos son nodos del árbol de Huffman.\n",
    "    \n",
    "    Args:\n",
    "        ft: Tabla de frecuencias (caracter: número de ocurrencias).\n",
    "        branching_factor: Factor de ramificación para el heap d-ario.\n",
    "    \n",
    "    Returns:\n",
    "        Un heap d-ario que contiene un nodo por cada carácter único en el texto.\n",
    "    \"\"\"\n",
    "    characters, priorities = list(zip(*ft.items()))\n",
    "    # Crea un nodo para cada carácter; se utiliza el inverso de la frecuencia ya que DWayHeap es un heap máximo\n",
    "    priorities = list(map(lambda p: -p, priorities))\n",
    "    elements = list(map(lambda c: HuffmanNode([c], -ft[c]), characters))\n",
    "    return DWayHeap(elements=elements, priorities=priorities, branching_factor=branching_factor)\n",
    "\n",
    "def _heap_to_tree(heap: DWayHeap) -> HuffmanNode:\n",
    "    \"\"\"Construye el árbol de codificación de Huffman a partir de un heap.\n",
    "    \n",
    "    Args:\n",
    "        heap: Un heap d-ario que contiene nodos de Huffman.\n",
    "    \n",
    "    Returns:\n",
    "        El nodo raíz del árbol de codificación de Huffman.\n",
    "    \"\"\"\n",
    "    while len(heap) > 1:\n",
    "        # Obtiene los dos nodos con mayor prioridad\n",
    "        right: HuffmanNode = heap.top()\n",
    "        left: HuffmanNode = heap.top()\n",
    "\n",
    "        # Combina los símbolos y las prioridades de los nodos extraídos\n",
    "        symbols: List[str] = left.symbols() + right.symbols()\n",
    "        priority: float = left.priority() + right.priority()\n",
    "\n",
    "        heap.insert(HuffmanNode(symbols, priority, left, right), priority)\n",
    "\n",
    "    return heap.top()\n",
    "\n",
    "def create_encoding(text: str, branching_factor: int) -> Dict[str, str]:\n",
    "    \"\"\"Crea la codificación de Huffman para un texto.\n",
    "    \n",
    "    Args:\n",
    "        text: Texto de entrada a comprimir.\n",
    "        branching_factor: Factor de ramificación para el heap d-ario.\n",
    "    \n",
    "    Returns:\n",
    "        Un diccionario que asocia cada carácter único del texto con su codificación binaria.\n",
    "        Por ejemplo, si ('a', '101') está en el diccionario, para comprimir el texto se reemplaza 'a' por '101'.\n",
    "    \"\"\"\n",
    "    return _heap_to_tree(_frequency_table_to_heap(_create_frequency_table(text), branching_factor)).tree_encoding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b751b-ff64-4287-83ec-abc7bfd9c7ea",
   "metadata": {},
   "source": [
    "#### Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafcf484-7e20-4e7a-bc35-8198c8c9ba91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class HuffmanTest(unittest.TestCase):\n",
    "    Text = \"fffeeeeeddddddcccccccbbbbbbbbbbbbbbbbbbbbbbaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
    "\n",
    "    def test_huffman(self):\n",
    "        self.assertEqual({'a': '0', 'b': '10', 'c': '1100', 'd': '1101', 'e': '1110', 'f': '1111'},\n",
    "                         create_encoding(HuffmanTest.Text, 2))\n",
    "\n",
    "    def test_create_frequency_table(self):\n",
    "        self.assertEqual({'a': 57, 'b': 22, 'c': 7, 'd': 6, 'e': 5, 'f': 3},\n",
    "                         _create_frequency_table(HuffmanTest.Text))\n",
    "\n",
    "    def test_frequency_table_to_heap(self):\n",
    "        heap = _frequency_table_to_heap(_create_frequency_table(HuffmanTest.Text))\n",
    "        self.assertTrue(heap._validate())\n",
    "\n",
    "    def test_heap_to_tree(self):\n",
    "        heap = _frequency_table_to_heap(_create_frequency_table(HuffmanTest.Text))\n",
    "        tree = _heap_to_tree(heap)\n",
    "        self.assertTrue(tree._validate())\n",
    "        print(tree)\n",
    "\n",
    "# Ejecuta las pruebas\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HuffmanTest)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee429e-6cf3-4d38-a20e-6e71d0d115a1",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a66fd-1b35-4377-a887-850dc3d2d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import cProfile\n",
    "import pstats\n",
    "import unittest\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def read_text(file_name: str) -> str:\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        texto = f.read()\n",
    "    return texto\n",
    "\n",
    "\n",
    "def read_image(file_name: str) -> str:\n",
    "    with open(file_name, 'rb') as f:\n",
    "        # Lee los bytes de una imagen y los codifica en base64 para tratarlos como texto\n",
    "        texto = str(base64.b64encode(f.read()))\n",
    "    return texto\n",
    "\n",
    "\n",
    "# Clase para realizar el perfilado de la codificación de Huffman\n",
    "class HuffmanProfile(unittest.TestCase):\n",
    "    TestCases = {\n",
    "        'texto': (['data/alice.txt', 'data/candide.txt',\n",
    "                   'data/gullivers_travels.txt'], read_text, 1000),\n",
    "        'image': (['data/best_advice.jpg'], read_image, 200)\n",
    "    }\n",
    "    BranchingFactors = range(2, 24)\n",
    "    OutputFileName = 'data/stats_huffman.csv'\n",
    "\n",
    "    @staticmethod\n",
    "    def write_header(f) -> None:\n",
    "        f.write('test_case,branching_factor,method_name,total_time,cumulative_time,per_call_time\\n')\n",
    "\n",
    "    @staticmethod\n",
    "    def write_row(f, test_case: str, branching_factor: int, method_name: str, total_time: float,\n",
    "                  cumulative_time: float, per_call_time: float) -> None:\n",
    "        f.write(f'{test_case},{branching_factor},{method_name},{total_time},{cumulative_time},{per_call_time}\\n')\n",
    "\n",
    "    @staticmethod\n",
    "    def get_running_times(st: pstats.Stats) -> List[Tuple[str, float, float, float]]:\n",
    "        ps = st.strip_dirs().stats\n",
    "        def is_heap_method(k):\n",
    "            return 'heap' in k[2] or 'create_encoding' in k[2] or \\\n",
    "                   ('dway_heap.py' in k and ('top' in k[2] or 'insert' in k[2] or\n",
    "                                             '_push_down' in k[2] or '_bubble_up' in k[2] or\n",
    "                                             '_highest_priority_child_index' in k[2]))\n",
    "        keys = list(filter(is_heap_method, ps.keys()))\n",
    "        return [(key[2], ps[key][2], ps[key][3], ps[key][3] / ps[key][1]) for key in keys]\n",
    "\n",
    "    def test_profile_huffman(self) -> None:\n",
    "        with open(HuffmanProfile.OutputFileName, 'w') as f:\n",
    "            HuffmanProfile.write_header(f)\n",
    "            for test_case, (file_names, read_func, runs) in HuffmanProfile.TestCases.items():\n",
    "                file_contents = [read_func(file_name) for file_name in file_names]\n",
    "                for _ in range(runs):\n",
    "                    for b in HuffmanProfile.BranchingFactors:\n",
    "                        pro = cProfile.Profile()\n",
    "                        for file_content in file_contents:\n",
    "                            pro.runcall(create_encoding, file_content, b)\n",
    "                        st = pstats.Stats(pro)\n",
    "                        for method_name, total_time, cumulative_time, per_call_time in HuffmanProfile.get_running_times(st):\n",
    "                            HuffmanProfile.write_row(f, test_case, b, method_name, total_time, cumulative_time, per_call_time)\n",
    "\n",
    "# Ejecuta las pruebas de perfilado\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HuffmanProfile)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5ef5e-9bd1-459a-a486-911284730c0a",
   "metadata": {},
   "source": [
    "#### Ejercicios\n",
    "\n",
    "1 . Dado el siguiente conjunto de caracteres y sus frecuencias:\n",
    "- A: 0.4\n",
    "- B: 0.3\n",
    "- C: 0.2\n",
    "- D: 0.1\n",
    "\n",
    "Calcula manualmente el árbol de Huffman siguiendo el procedimiento:\n",
    "\n",
    "- Ordena los caracteres por frecuencia.\n",
    "- Combina los dos nodos de menor frecuencia para formar un nodo padre.\n",
    "- Repite el proceso hasta que quede un único nodo.\n",
    "\n",
    "Dibuja el árbol resultante y escribe el código binario asignado a cada carácter (recuerda: 0 para rama izquierda y 1 para derecha).\n",
    "\n",
    "2 . Analiza la complejidad temporal del algoritmo de Huffman, considerando:\n",
    "\n",
    "- La construcción del mapa de frecuencias.\n",
    "- La inserción y extracción en el heap.\n",
    "- La construcción de la tabla de códigos mediante la función recursiva.\n",
    "\n",
    "Compara la complejidad teórica con la práctica, discutiendo posibles cuellos de botella y cómo podría optimizarse el algoritmo para textos muy largos o con un gran número de caracteres únicos.\n",
    "\n",
    "3 . Explica el proceso de generación del árbol de Huffman a partir de una tabla de frecuencias, detallando el rol de las funciones `_create_frequency_table`, `_frequency_table_to_heap` y `_heap_to_tree`.  Discute la importancia de invertir las frecuencias (utilizando valores negativos) al trabajar con un heap máximo y cómo se combinan los nodos para formar el árbol final.\n",
    "\n",
    "4 . Investiga cómo varía el rendimiento (en tiempo de ejecución y consumo de memoria) del algoritmo de Huffman al modificar el factor de ramificación del heap d-ario.  \n",
    "- **Tareas:**  \n",
    "  - Utilizar el código base para generar codificaciones Huffman con diferentes valores de _branching_factor_ (por ejemplo, desde 2 hasta 23).  \n",
    "  - Realizar pruebas de rendimiento y comparar los resultados obtenidos mediante perfilado.  \n",
    "  - Interpretar y explicar cómo y por qué el factor de ramificación afecta el número de comparaciones, la profundidad del heap y la eficiencia global del algoritmo.\n",
    "\n",
    "5 . Amplia la implementación actual para incluir funciones de compresión y descompresión de textos (y, opcionalmente, de imágenes).  \n",
    "- **Tareas:**  \n",
    "  - Diseñar e integrar funciones que permitan convertir un texto en su representación comprimida utilizando la codificación generada por Huffman.  \n",
    "  - Implementar el proceso inverso para recuperar el texto original a partir del código comprimido.  \n",
    "  - Diseñar pruebas unitarias adicionales que verifiquen la integridad de la compresión/descompresión en distintos escenarios y tamaños de entrada.\n",
    "\n",
    "\n",
    "6 . Identifica posibles cuellos de botella en la función que construye el árbol de Huffman y proponer mejoras.  \n",
    "- **Tareas:**  \n",
    "  - Analizar el rendimiento de las funciones `_push_down`, `_bubble_up` y `_highest_priority_child_index` en el contexto del heap d-ario.  \n",
    "  - Utilizar herramientas de perfilado para determinar qué métodos consumen más tiempo y optimizarlos sin alterar la semántica del algoritmo.  \n",
    "  - Justificar las modificaciones realizadas y evaluar el impacto de las optimizaciones en diferentes casos de prueba.\n",
    "\n",
    "7 . Profundiza en la verificación de la consistencia y la correcta construcción del árbol de Huffman.  \n",
    "- **Tareas:**  \n",
    "  - Implementar casos de prueba adicionales que verifiquen las invariantes del heap y la validez del árbol (por ejemplo, asegurando que cada nodo interno cumpla la suma correcta de prioridades y que los símbolos se concatenen adecuadamente).  \n",
    "  - Diseñar escenarios de prueba con datos sintéticos y reales (textos de distinta longitud y complejidad) para evaluar la robustez de las funciones de validación (`_validate` en ambos contextos).  \n",
    "  - Documentar posibles fallos y proponer estrategias para mejorar la detección temprana de errores en la construcción del árbol.\n",
    "\n",
    "8 . Consolida los resultados obtenidos a partir del perfilado en un reporte analítico detallado.  \n",
    "- **Tareas:**  \n",
    "  - Modificar y ampliar el script de perfilado para capturar métricas más detalladas (por ejemplo, tiempos de llamada, número de invocaciones y consumo de CPU) para las funciones clave del algoritmo.  \n",
    "  - Exportar los datos a un archivo CSV y generar visualizaciones (gráficos) que ilustren el comportamiento de cada función en función del factor de ramificación y el tipo de dato comprimido.  \n",
    "  - Elaborar un informe que incluya análisis comparativos, gráficos y conclusiones sobre el desempeño y las posibles mejoras del algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccffeb-c26b-4c61-b00e-7bc7b46c24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db816a0e-2734-4348-b0df-38b0d1f0d588",
   "metadata": {},
   "source": [
    "#### Visualización y análisis de estadísticas de rendimiento para algoritmos de Huffman y Heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99523a-a0dc-4544-9ab2-75c4766840d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Rutas de los archivos de estadísticas\n",
    "HUFFMAN_STATS = '/data/stats_huffman.csv'\n",
    "HEAP_STATS = '/data/stats_heap.csv'\n",
    "HEAP_MIXED_STATS = '/data/stats_heap_mixed.csv'\n",
    "HEAPIFY_STATS = '/data/stats_heapify.csv'\n",
    "\n",
    "def plot_test_case_stats(df: pd.DataFrame, test_case: str, time_field: str = 'cumulative_time'):\n",
    "    \"\"\"\n",
    "    Grafica los datos de un caso de prueba específico, generando gráficos para cada método.\n",
    "    \n",
    "    Parámetros:\n",
    "        df: DataFrame con los datos de estadísticas.\n",
    "        test_case: Nombre del caso de prueba a graficar.\n",
    "        time_field: Campo de tiempo a utilizar (por defecto 'cumulative_time').\n",
    "    \"\"\"\n",
    "    # Filtra el DataFrame para obtener solo los datos del caso de prueba indicado\n",
    "    df_test_case = df[df['test_case'] == test_case]\n",
    "    # Obtiene los nombres únicos de métodos en el caso de prueba\n",
    "    method_names = df_test_case['method_name'].unique()\n",
    "    \n",
    "    # Genera un gráfico para cada método\n",
    "    for method_name in method_names:\n",
    "        plot_method_stats(df_test_case, method_name, time_field)\n",
    "\n",
    "def plot_method_stats(df: pd.DataFrame, method_name: str, time_field: str):\n",
    "    \"\"\"\n",
    "    Genera un gráfico de caja (boxplot) para visualizar la distribución de tiempos de ejecución\n",
    "    de un método específico, según distintos factores de ramificación.\n",
    "    \n",
    "    Parámetros:\n",
    "        df: DataFrame filtrado para el caso de prueba.\n",
    "        method_name: Nombre del método a graficar.\n",
    "        time_field: Campo de tiempo a utilizar.\n",
    "    \"\"\"\n",
    "    # Filtra el DataFrame para obtener solo los datos del método especificado\n",
    "    df_method: pd.DataFrame = df[df['method_name'] == method_name]\n",
    "    \n",
    "    # Obtiene los factores de ramificación únicos\n",
    "    branching_factors = df_method['branching_factor'].unique()\n",
    "    # Agrupa los datos por cada factor de ramificación\n",
    "    data = [df_method[df_method['branching_factor'] == b][time_field] for b in branching_factors]\n",
    "    \n",
    "    # Crea la figura y el eje para el gráfico\n",
    "    fig, axe = plt.subplots()\n",
    "\n",
    "    axe.set_title(method_name, fontsize=16)\n",
    "    axe.set_xlabel('Factor de ramificación')\n",
    "    axe.set_ylabel('Tiempo de ejecución')\n",
    "\n",
    "    # Genera el gráfico de caja sin mostrar valores atípicos\n",
    "    plt.boxplot(x=data, labels=branching_factors, showfliers=False)\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_case_means(df: pd.DataFrame, test_case: str, time_field: str = 'cumulative_time'):\n",
    "    \"\"\"\n",
    "    Grafica las medias de tiempo de ejecución para cada método en un caso de prueba,\n",
    "    según el factor de ramificación.\n",
    "    \n",
    "    Parámetros:\n",
    "        df: DataFrame con los datos de estadísticas.\n",
    "        test_case: Nombre del caso de prueba a graficar.\n",
    "        time_field: Campo de tiempo a utilizar (por defecto 'cumulative_time').\n",
    "    \"\"\"\n",
    "    # Filtra el DataFrame para obtener solo los datos del caso de prueba indicado\n",
    "    df_test_case = df[df['test_case'] == test_case]\n",
    "    # Obtiene los nombres únicos de métodos en el caso de prueba\n",
    "    method_names = df_test_case['method_name'].unique()\n",
    "    \n",
    "    # Genera un gráfico para cada método mostrando la media\n",
    "    for method_name in method_names:\n",
    "        plot_method_mean(df_test_case, method_name, time_field)\n",
    "\n",
    "def plot_method_mean(df: pd.DataFrame, method_name: str, time_field: str):\n",
    "    \"\"\"\n",
    "    Genera un gráfico de líneas que muestra la media de tiempos de ejecución de un método\n",
    "    específico, agrupados por factor de ramificación.\n",
    "    \n",
    "    Parámetros:\n",
    "        df: DataFrame filtrado para el caso de prueba.\n",
    "        method_name: Nombre del método a graficar.\n",
    "        time_field: Campo de tiempo a utilizar.\n",
    "    \"\"\"\n",
    "    # Filtra el DataFrame para obtener solo los datos del método especificado\n",
    "    df_method: pd.DataFrame = df[df['method_name'] == method_name]\n",
    "    \n",
    "    # Obtiene los factores de ramificación únicos\n",
    "    branching_factors = df_method['branching_factor'].unique()\n",
    "    # Agrupa los datos por factor de ramificación y calcula la media\n",
    "    data = df_method.groupby('branching_factor').mean().reset_index()\n",
    "    \n",
    "    # Crea la figura y el eje para el gráfico\n",
    "    fig, axe = plt.subplots()\n",
    "\n",
    "    axe.set_title(method_name, fontsize=16)\n",
    "    axe.set_xlabel('Factor de ramificación')\n",
    "    axe.set_ylabel('Tiempo de ejecución')\n",
    "\n",
    "    # Genera el gráfico de líneas con la media de tiempo de ejecución\n",
    "    plt.plot(branching_factors, data[time_field])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980a1f1-ef0b-40ca-abf3-a2f38f76ce39",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "\n",
    "1. **Carga y exploración de datos**  \n",
    "   - Crea un DataFrame a partir del archivo CSV de estadísticas (por ejemplo, el archivo de Huffman).  \n",
    "   - Utiliza funciones propias de pandas para inspeccionar la estructura del DataFrame (por ejemplo, revisa la información de columnas y tipos de datos).  \n",
    "   - Extrae y lista todos los casos de prueba presentes en el DataFrame.  \n",
    "   - Reflexiona sobre la importancia de conocer la estructura y el contenido de los datos antes de analizarlos.\n",
    "\n",
    "2. **Visualización de estadísticas para casos de prueba de texto**  \n",
    "   - Emplea las funciones de visualización para generar gráficos de caja que muestren la distribución de tiempos de ejecución para el caso de prueba relacionado a texto, utilizando distintos campos como el tiempo por llamada y el tiempo acumulado.  \n",
    "   - Crea gráficos de líneas que representen la media de los tiempos de ejecución para el mismo caso de prueba, variando entre campos como tiempo acumulado, por llamada y tiempo total.  \n",
    "   - Analiza qué información adicional aporta cada tipo de gráfico y cómo pueden ayudar a identificar tendencias o anomalías en el rendimiento.\n",
    "\n",
    "3. **Visualización de estadísticas para casos de prueba de imágenes**  \n",
    "   - Utiliza las funciones de visualización para generar gráficos que muestren los tiempos de ejecución para el caso de prueba de imágenes, centrándote en los tiempos por llamada y los tiempos acumulados.  \n",
    "   - Compara los resultados obtenidos con los del caso de prueba de texto y comenta posibles diferencias en el rendimiento y la variabilidad.\n",
    "\n",
    "4. **Análisis de estadísticas relacionadas con el heap**  \n",
    "   - Crea DataFrames a partir de los archivos CSV correspondientes a las estadísticas del heap, las estadísticas mixtas del heap y las estadísticas de heapify.  \n",
    "   - Genera gráficos que muestren los tiempos de ejecución para el caso de prueba \"heap\", utilizando las funciones de visualización disponibles.  \n",
    "   - Discute las diferencias en la presentación de datos entre los distintos archivos y qué información relevante se puede extraer sobre el comportamiento del heap.\n",
    "\n",
    "5. **Cálculo y análisis del número de swaps en heapify**  \n",
    "   - Estudia la función encargada de calcular el número de swaps durante la operación heapify.  \n",
    "   - Analiza cómo varía el número de swaps en función del tamaño del heap (por ejemplo, para `n` igual a 100, 1000, 10000 y 100000) y el factor de ramificación.  \n",
    "   - Reflexiona sobre el impacto del factor de ramificación en la eficiencia de la operación, teniendo en cuenta que el gráfico generado utiliza una escala logarítmica en el eje de los swaps.\n",
    "\n",
    "6.   A partir de los gráficos y análisis previos, elabora un informe en el que se discuta la relación entre el factor de ramificación y el rendimiento en las operaciones del heap y la construcción del árbol de Huffman.  Considera aspectos como la variabilidad de los tiempos de ejecución, la media de los mismos y la influencia del tamaño del conjunto de datos en el número de swaps durante la operación heapify. Finalmente, reflexiona sobre cómo estos análisis pueden orientar futuras optimizaciones o ajustes en la implementación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d6d2e-2611-4831-abf8-0e5f2bcd524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
