{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd22dbd-4170-45bb-adda-e36ddc2bf0cb",
   "metadata": {},
   "source": [
    "### **Pregunta 1 (detallada)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b635f-39e1-413a-911c-3e4a87622b05",
   "metadata": {},
   "source": [
    "**1. Problema 0–1 Knapsack con $n \\le 10^5$ y capacidad $W$**\n",
    "\n",
    "**a) Dos estructuras de datos para la DP**\n",
    "\n",
    "1. **Matriz densa**\n",
    "\n",
    "   * Una matriz bidimensional $dp[i][w]$ de tamaño $(n+1)\\times(W+1)$, donde\n",
    "\n",
    "     $$\n",
    "       dp[i][w] = \\max\\bigl(\\,dp[i-1][w],\\;dp[i-1][w - weight_i] + value_i\\bigr)\n",
    "     $$\n",
    "\n",
    "     si $weight_i \\le w$, y $dp[i][w] = dp[i-1][w]$ en caso contrario.\n",
    "\n",
    "2. **Bitset por capas**\n",
    "\n",
    "   * Representar cada capa de la DP como un bitset de longitud $W+1$, donde el bit $w$ está a 1 si existe alguna selección de los primeros $i$ ítems que logra peso exactamente $w$.\n",
    "   * Para añadir el ítem $i$, desplazamos (shift) el bitset actual a la izquierda por $weight_i$ y lo OReamos con el original.\n",
    "   * Para recuperar el valor máximo, habría que llevar una estructura paralela o empaquetar valores en bits múltiples.\n",
    "\n",
    "3. **Tabla hash dispersa (sparse DP)**\n",
    "\n",
    "   * Mantener para cada capa un diccionario/hash map que mapea pesos alcanzables a su máximo valor:\n",
    "\n",
    "     $$\n",
    "       dp_i = \\{\\,w \\mapsto v\\mid \\exists\\text{ selección de ítems }1\\ldots i\\text{ con peso }w\\text{ y valor }v\\}.\n",
    "     $$\n",
    "   * Al procesar el ítem $i$, iteramos las entradas $(w,v)$ en $dp_{i-1}$ y actualizamos/inser­tamos en $dp_i$ las dos posibilidades: sin $i$ (copiar entrada) y con $i$ (peso $w+w_i$, valor $v+v_i$).\n",
    "\n",
    "\n",
    "**b) Complejidades temporal y espacial**\n",
    "Aquí tienes la tabla con todas las ecuaciones en LaTeX:\n",
    "\n",
    "| Estructura              | Tiempo                                                                                                                        | Espacio                                                                                              |\n",
    "| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "| **Matriz densa**        | $\\displaystyle O(nW)$                                                                                                         | $\\displaystyle O(nW)$                                                                                |\n",
    "| **Bitset por capas**    | $\\displaystyle O\\bigl(n \\cdot \\lceil W/B\\rceil\\bigr)$ con $B$ el tamaño de palabra (p.,ej.\\ 64) $\\;\\longrightarrow\\;O(nW/64)$ | $\\displaystyle O\\bigl(W/B\\bigr)$ (por capa; si solo guardamos la capa actual: $\\,O(W/64)$)           |\n",
    "| **Tabla hash dispersa** | $\\displaystyle O\\!\\Bigl(\\sum_{i=1}^{n}\\lvert dp_{i-1}\\rvert\\Bigr)$; en el peor caso $\\tilde{O}(nW)$                           | $\\displaystyle O\\bigl(\\lvert dp_i\\rvert\\bigr)$ por capa; en el peor caso $\\,O\\bigl(\\min(W,nW)\\bigr)$ |\n",
    "\n",
    "* **Matriz densa** es conceptualmente simple y garantiza tiempo estricto $O(nW)$, pero su uso de memoria es prohibitivo para $W\\approx10^6$ y $n\\approx10^5$.\n",
    "* **Bitset por capas** reduce el espacio por un factor de palabra y aprovecha operaciones de CPU vectorizadas (shift, OR).\n",
    "* **Tabla hash dispersa** puede ahorrar tiempo y espacio cuando muy pocos pesos son alcanzables, pero incurre en overhead de hashing y presenta baja localidad de memoria.\n",
    "\n",
    "\n",
    "**c) Caso $W \\ll n$, $W \\approx 10^6$, jerarquía de caché crítica**\n",
    "\n",
    "* **Elección:** **Bitset por capas** (con solo dos `filas` de bitsets, rotando entre capa actual y anterior).\n",
    "\n",
    "**Razones:**\n",
    "\n",
    "1. **Localidad y contigüidad:** los bitsets se almacenan contiguamente en memoria, optimizando las lecturas/escrituras lineales y beneficiándose de prefetching en caché.\n",
    "2. **Operaciones vectorizadas:** desplazamientos y OR a nivel de palabra (64 bits o más) se ejecutan en hardware en unos pocos ciclos, amortizando el coste sobre 64 elementos de la DP a la vez.\n",
    "3. **Espacio reducido:** usa $O(W/64)\\approx1.6\\times10^4$ palabras de 8 bytes -> ≈128 KB por capa, caben cómodamente en L2/L3 cache.\n",
    "4. **Salto mínimo de puntero:** no hay punteros dispersos ni estructuras encadenadas; cada acceso a palabra sólo depende de su índice, lo cual maximiza hits en caché.\n",
    "\n",
    "En cambio, la matriz densa usaría ≈8 bytes×$10^6$×2 filas $\\approx$ 16 MB, muy por encima de la mayoría de cachés, y la tabla hash sufriría saltos aleatorios de memoria por bucket y colisiones, mermando dramáticamente la localidad de referencia.\n",
    "\n",
    "**2. Complejidades en un $D$-ary heap**\n",
    "Un *D*-ary heap es una generalización del heap binario en la que cada nodo puede tener hasta $D$ hijos. Denotemos por $n$ el número de elementos en el heap.\n",
    "\n",
    "* **insert(x)**\n",
    "\n",
    "  1. Añadimos $x$ al final del arreglo que representa el heap.\n",
    "  2. Aplicamos *sift‑up*: mientras el nuevo elemento sea menor que su padre, los intercambiamos y seguimos subiendo.\n",
    "  3. Cada subida de nivel recorre un puntero \"hijo->padre\". La altura del heap es\n",
    "\n",
    "     $$\n",
    "       H = O(\\log_D n) \\quad\\bigl(=O(\\tfrac{\\ln n}{\\ln D})\\bigr).\n",
    "     $$\n",
    "  4. Cada comparación o intercambio es $O(1)$.\n",
    "\n",
    "  **Complejidad:**\n",
    "\n",
    "  $$\n",
    "    T_{\\text{insert}} = O(\\log_D n).\n",
    "  $$\n",
    "\n",
    "* **extract‑min()**\n",
    "\n",
    "  1. Intercambiamos la raíz (mínimo) con el último elemento y lo eliminamos.\n",
    "  2. Aplicamos *sift‑down* desde la nueva raíz: en cada nivel, entre sus hasta $D$ hijos elegimos el más pequeño (requiere $O(D)$ comparaciones) y lo intercambiamos con el padre.\n",
    "  3. Bajamos nivel a nivel hasta que el elemento quede en posición de heap. Hay $H = O(\\log_D n)$ niveles.\n",
    "\n",
    "  **Complejidad:**\n",
    "\n",
    "  $$\n",
    "    T_{\\text{extract-min}} = O\\bigl(D \\cdot \\log_D n\\bigr)\n",
    "      = O\\!\\bigl(D\\,\\tfrac{\\ln n}{\\ln D}\\bigr).\n",
    "  $$\n",
    "\n",
    "* **decrease‑key(x, $\\Delta$)**\n",
    "\n",
    "  1. Reducimos la clave de $x$ en $\\Delta$.\n",
    "  2. Si el nuevo valor es menor que el de su padre, aplicamos *sift‑up* exactamente como en la inserción.\n",
    "\n",
    "  **Complejidad:**\n",
    "\n",
    "  $$\n",
    "    T_{\\text{decrease-key}} = O(\\log_D n).\n",
    "  $$\n",
    "\n",
    "\n",
    "**Observación:** Elegir $D$ grande reduce la altura ($\\log_D n$ pequeño) pero incrementa el trabajo por nivel en extract-min ($O(D)$ comparaciones), lo que crea un trade‑off óptimo típicamente alrededor de $D\\approx4$ o $8$ en práctica.\n",
    "\n",
    "**3. Altura esperada $O(\\log n)$ de un Treap aleatorizado**\n",
    "Un **Treap** combina las propiedades de un BST (orden por clave) con un heap (prioridades aleatorias). Cada nodo tiene:\n",
    "\n",
    "* **clave**: impone el in‐order.\n",
    "* **prioridad**: valor aleatorio único, que convierte el árbol en un heap mínimo.\n",
    "\n",
    "**Idea de la prueba en esperanza (esquema):**\n",
    "\n",
    "1. Las prioridades son una permutación aleatoria de $\\{1,\\dots,n\\}$.\n",
    "2. El Treap resultante es isomorfo al **árbol de búsqueda** construido insertando las claves en el orden de sus prioridades (los más pequeños primeros).\n",
    "3. Es conocido que, si insertamos $n$ claves en un BST en orden **aleatorio uniforme**, la altura esperada es $H_n=O(\\log n)$.\n",
    "4. Con ello, la altura del Treap (que coincide con la altura de ese BST aleatorio) también satisface\n",
    "\n",
    "   $$\n",
    "     \\mathbb{E}[\\text{altura}] = O(\\log n).\n",
    "   $$\n",
    "\n",
    "\n",
    "**4. Fórmula del falso positivo en un Bloom Filter clásico**\n",
    "\n",
    "* **Filtro:** un array de $m$ bits, inicializados a 0; $k$ funciones de hash independientes $h_1,\\dots,h_k: U\\to\\{0,\\dots,m-1\\}$.\n",
    "* **Inserción** de un elemento $x$: para cada $i=1\\ldots k$, poner a 1 el bit en $\\text{pos}=h_i(x)$.\n",
    "* **Consulta** de $y$: comprobamos si **todos** los $k$ bits $\\{h_i(y)\\}$ están a 1. Si alguno es 0, decimos \"no está\"; si todos 1, \"sí\" (pero puede ser falso positivo).\n",
    "\n",
    "**Derivación bajo independencia ideal:**\n",
    "\n",
    "1. Tras insertar $n$ elementos, la probabilidad de que un bit concreto **no** haya sido seteado por una función de hash en una inserción es\n",
    "\n",
    "   $$\n",
    "     1 - \\frac1m.\n",
    "   $$\n",
    "2. Como hay $kn$ \"hash\" independientes, la probabilidad de que ese bit **siga 0** es\n",
    "\n",
    "   $$\n",
    "     \\Bigl(1 - \\tfrac1m\\Bigr)^{kn}.\n",
    "   $$\n",
    "3. Por tanto, la probabilidad de que el bit **esté a 1** es\n",
    "\n",
    "   $$\n",
    "     1 - \\Bigl(1 - \\tfrac1m\\Bigr)^{kn}.\n",
    "   $$\n",
    "4. Para un elemento **no insertado** (independiente), las $k$ posiciones de hash deben estar todas a 1 para FP. Suponiendo independencia entre bits consultados:\n",
    "\n",
    "   $$\n",
    "     p_{\\mathrm{fp}}\n",
    "     = \\Bigl[1 - (1 - \\tfrac1m)^{kn}\\Bigr]^{k}.\n",
    "   $$\n",
    "5. Aproximación para $m$ grande y $kn$ razonable:\n",
    "\n",
    "   $$\n",
    "     (1 - \\tfrac1m)^{kn} \\approx e^{-kn/m}\n",
    "     \\quad\\Longrightarrow\\quad\n",
    "     p_{\\mathrm{fp}}\n",
    "     \\approx \\bigl(1 - e^{-kn/m}\\bigr)^k.\n",
    "   $$\n",
    "\n",
    "**Supuestos clave:** funciones de hash verdaderamente independientes; bits se comportan de forma independiente — en la práctica, esto es sólo aproximado, pero guía el dimensionamiento óptimo de $k\\approx(m/n)\\ln2$.\n",
    "\n",
    "\n",
    "**5. Unión–Find con path compression + union by rank: análisis amortizado $O(\\alpha(n))$**\n",
    "\n",
    "En la estructura **Union–Find** (o Disjoint Set Union, DSU), queremos soportar dos operaciones sobre un universo de $n$ elementos:\n",
    "\n",
    "* **find(x):** devuelve el representante (raíz) del conjunto que contiene $x$.\n",
    "* **union(x,y):** une los conjuntos que contienen $x$ y $y$.\n",
    "\n",
    "La implementación más eficiente combina **union by rank** (o por tamaño) con **path compression**. El reto es demostrar que, aunque una operación individual pueda costar hasta $\\Theta(\\log n)$ o más, el **coste amortizado** de una secuencia de $m$ operaciones es $O\\bigl(m\\,\\alpha(n)\\bigr)$, donde $\\alpha(n)$ es la inversa de la función de Ackermann. \n",
    "\n",
    "A continuación se expone un desarrollo detallado:\n",
    "\n",
    "**A. Unión por rango (rank or size)**\n",
    "\n",
    "* Cada nodo $x$ guarda un **parent** $\\;p[x]$, apuntando a su padre en el árbol de conjuntos. Inicialmente $p[x]=x$.\n",
    "* Además, guardamos un campo **rank** (o aproximación de la altura) $r[x]$.\n",
    "* Al **unir** dos raíces $r_1$ y $r_2$, hacemos que la raíz de **menor rank** apunte a la de mayor rank.\n",
    "\n",
    "  * Si $r[r_1] < r[r_2]$, entonces $p[r_1] \\gets r_2$.\n",
    "  * Si $r[r_1] > r[r_2]$, entonces $p[r_2] \\gets r_1$.\n",
    "  * Si igual, unimos arbitrariamente y aumentamos el rank de la nueva raíz en 1.\n",
    "\n",
    "**Propiedad:** el rank de un nodo sólo crece cuando se unen dos árboles del mismo rank, y la altura de un árbol de tamaño $s$ es $O(\\log s)$. Sin path compression, esto ya garantiza que **cada** operación find(x) en el peor caso recorre $O(\\log n)$ punteros.\n",
    "\n",
    "**B. Path compression (compresión de camino)**\n",
    "\n",
    "Durante una llamada **find(x)**, recorremos punteros hasta la raíz $r$. Con path compression, hacemos que cada nodo en el camino apunte directamente a $r$. Así, la próxima vez que hagamos find sobre cualquiera de ellos, irá \"directo a casa\".\n",
    "\n",
    "**Pseudocódigo básico:**\n",
    "\n",
    "```plaintext\n",
    "function find(x):\n",
    "    if p[x] != x:\n",
    "        p[x] = find(p[x])\n",
    "    return p[x]\n",
    "```\n",
    "\n",
    "Cada invocación \"aplasta\" el camino desde $x$ hasta la raíz.\n",
    "\n",
    "**C. Análisis amortizado: esquema de la prueba**\n",
    "\n",
    "1. **Función potencial:** para un análisis amortizado, asignamos un **potencial** $\\Phi$ a la estructura, que refleje \"lo lejos\" que están los nodos de sus raíces, de modo que la path compression reduzca sustancialmente ese potencial.\n",
    "\n",
    "2. **Medida de complejidad:** Sea $\\alpha(n)$ la inversa de la función de Ackermann (muy, muy lenta). A pesar de que Ackermann crece extremadamente rápido, su inversa crece **tan** despacio que para todo propósito práctico $\\alpha(n) \\le 4$ si $n$ es menor que el número de átomos del universo.\n",
    "\n",
    "3. **Cota de Tarjan (1975):** Robert Tarjan demostró que, en una secuencia de $m$ operaciones union o find arbitrarias sobre $n$ elementos, el coste total es\n",
    "\n",
    "   $$\n",
    "     O\\bigl(m\\,\\alpha(n)\\bigr).\n",
    "   $$\n",
    "\n",
    "   Por lo tanto, el coste amortizado **por operación** es $O(\\alpha(n))$.\n",
    "\n",
    "**D. Intuición de por qué $\\alpha(n)$**\n",
    "\n",
    "* La combinación de union by rank y path compression produce árboles casi \"planos\": la mayoría de los nodos quedarán muy cerca de la raíz después de pocas finds.\n",
    "* El análisis usa una descomposición de nodos según su rank y define clases de nodos (niveles). Cada vez que comprimimos un camino, movemos nodos a clases \"más bajas\" (más cercanas a la raíz), reduciendo la \"distancia efectiva\" del camino.\n",
    "* El número de veces que un nodo puede \"saltar\" entre clases está acotado por $\\alpha(n)$, porque la función de Ackermann crece tan rápido que $\\alpha(n)$ describe cuántas veces podemos aplicar recíprocamente operaciones que reduzcan el tamaño de los subárboles antes de llegar a un base trivial.\n",
    "\n",
    "Los detalles formales combinan técnicas de **potencial** y una cuidadosa partición de los operaciones en \"carácter ligero\" vs. \"pesado\", clasificando los enlaces de parent según su rank, y mostrando que cada operación que no sea ligera ocurre muy pocas veces (a lo sumo $O(\\alpha(n))$) a lo largo de toda la secuencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f94a92-dc7a-486d-b63e-249703829678",
   "metadata": {},
   "source": [
    "### **Pregunta 2 (detallada)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79aaec-efdf-4e07-8b19-b1277bcc6f67",
   "metadata": {},
   "source": [
    "**B1. Bloom Filter (m = $10^5$, n = $2*10^4$)**\n",
    "\n",
    "1. **Probabilidad teórica $p_{fp}$ para $k=6$:**\n",
    "\n",
    "   $$\n",
    "     p_0 = \\Bigl(1 - \\tfrac{1}{m}\\Bigr)^{kn}\n",
    "     = \\Bigl(1 - 10^{-5}\\Bigr)^{6\\cdot2\\cdot10^{4}}\n",
    "     \\approx e^{-1.2}\n",
    "     \\approx 0.301  \n",
    "     \\quad\\Longrightarrow\\quad\n",
    "     p_{fp} = (1 - p_0)^{k} \\approx (1 - 0.301)^{6}\\approx 0.1179.\n",
    "   $$\n",
    "\n",
    "2. **Probabilidad empírica:**\n",
    "   Insertando 20 000 claves y testeando otras 20 000, se obtuvo\n",
    "\n",
    "   $$\n",
    "     \\hat p_{fp}\\approx 0.1163.\n",
    "   $$\n",
    "\n",
    "3. **Gráfica $\\quad k=1\\ldots10$**\n",
    "  \n",
    "\n",
    "4. **Discusión:**\n",
    "   La probabilidad empírica se ajusta muy bien a la teórica; las ligeras diferencias (<1 %) se deben a la varianza estadística de la muestra y a la dependencia imperfecta entre bits y hashes (MD5 no es totalmente independiente). Observamos que el valor óptimo de $k$ (mínimo $p_{fp}$) está alrededor de 3-4, en concordancia con la fórmula $k_{\\mathrm{opt}}=(m/n)\\ln2\\approx(10^5/2\\cdot10^4)\\ln2\\approx3.47$. Para $k<k_{\\mathrm{opt}}$ el filtro queda demasiado denso; para $k>k_{\\mathrm{opt}}$ el coste de múltiples hashes domina, incrementando $p_{fp}$.\n",
    "\n",
    "\n",
    "**B2. KD‑Tree vs SS+-Tree (10 000 puntos en $\\mathbb{R}^5$)**\n",
    "\n",
    "> Se ha utilizado las implementaciones del curso\n",
    "\n",
    "A continuación se muestran los resultados de medir **build**, **query** (tiempo medio por consulta) y **recall** (porcentaje de vecinos exactos) para un **Kd‑Tree** sobre **10 000** puntos en $\\mathbb R^5$ (mezcla de Gaussiana) y para una **SS+-Tree** construida sobre un **subconjunto de 2 000** puntos (la implementación en Python de SS+-Tree es muy costosa a gran escala; para 10 000 puntos su construcción tarda varios minutos, por lo que hemos usado 2 000 para obtener tiempos manejables y extrapolables):\n",
    "\n",
    "| Estructura   | Build (ms) | Query (ms) | Recall (%) |\n",
    "| ------------ | ---------: | ---------: | ---------: |\n",
    "| **Kd‑Tree**  |        8.0 |       0.01 |          - |\n",
    "| **SS⁺-Tree** | $1.13 × 10^5$ |       54.8 |       84.9 |\n",
    "\n",
    "* **Build Kd‑Tree (10 000 pts):** \\~8 ms\n",
    "* **Build SS⁺-Tree (2 000 pts):** \\~113 000 ms -> Escalar a 10 000 pts: $\\approx 565 000$ ms\n",
    "* **Query Kd‑Tree:** \\~0.01 ms por nearest‑neighbour\n",
    "* **Query SS+-Tree:** \\~54.8 ms por consulta\n",
    "* **Recall SS+-Tree ($\\varepsilon=0.1$):** \\~85 %\n",
    "\n",
    "**Análisis:**\n",
    "\n",
    "* El **Kd‑Tree** brilla en dimensiones moderadas ($d=5$): **construcción ultrarrápida** y consultas casi instantáneas, con exactitud garantizada.\n",
    "* La **SS⁺-Tree**, por su diseño de centros y radios, **explora menos nodos** pero paga un coste enorme en la **construcción** (actualización de centroides y splits) y en consultas individuales. El recall \\~85 % indica que a menudo falla en encontrar el vecino exacto.\n",
    "* **Casos**:\n",
    "\n",
    "  * Si el requisito es **latencia muy baja** y **exactitud total**, elige **Kd‑Tree**.\n",
    "  * Si se dispone de **índices preconstruidos** (offline) y se tolera un 10-15 % de error a cambio de **acelerar ligeramente** búsquedas en un sistema distribuido (p. ej., filtros previos en base de datos), la **SS+-Tree** puede tener sentido.\n",
    "  * En la práctica, para 10 000-100 000 puntos en $d\\le10$, el **Kd‑Tree** suele ser la opción más eficiente y fiable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2056a00-66cc-4e90-84d2-bfb922fa735a",
   "metadata": {},
   "source": [
    "### **Pregunta 3 (detallada)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747d658-b44e-4534-a91e-049ae3ab9e2c",
   "metadata": {},
   "source": [
    "> Se ha utilizado las implementaciones del curso y se ha ejecutado los métodos de clustering sobre el dataset de mezcla de Gaussianas con ruido y se realizó la comparación del rendimiento de la heap binaria estándar (`heapq`) frente a una heap de grado 4.\n",
    "> \n",
    "\n",
    "**C1. Comparación de métodos**\n",
    "\n",
    "| Método                           | Silhouette Score |\n",
    "| -------------------------------- | ---------------- |\n",
    "| KMeans (k=4)                     | 0.502            |\n",
    "| DBSCAN ($\\epsilon=0.8$, min\\_samples=10)  | 0.271            |\n",
    "| OPTICS (min\\_samples=10, $\\varepsilon=0.05)$ | 0.312            |\n",
    "\n",
    "<p><strong>Justificación:</strong>  \n",
    "K‑Means, con k=4, recupera claramente los cuatro grupos gaussianos y separa eficazmente el ruido, alcanzando el mayor valor de silhouette ($\\approx 0.50$). DBSCAN identifica bien densidades pero fusiona clústeres cercanos y etiqueta parte del ruido como clústeres pequeños, resultando en un silhouette bajo ($\\approx0.27$). OPTICS, al adaptar dinámicamente el vecindario, maneja mejor las densidades variables que DBSCAN y capta la estructura de los clusters, aunque su puntuación ($\\approx 0.31$) es inferior a K‑Means. \n",
    "\n",
    "Por simplicidad, interpretabilidad y eficiencia computacional, **K‑Means** es el método más adecuado para este dataset, siempre que el número de clústeres sea conocido de antemano.\n",
    "\n",
    "**C2. OPTICS con D-ary heap (D=4)**\n",
    "\n",
    "| Implementación   | Tiempo (s) |\n",
    "| ---------------- | ---------- |\n",
    "| heapq (binaria)  | 1.45       |\n",
    "| D‑ary heap (d=4) | 1.17       |\n",
    "\n",
    "**Impacto de aumentar D:**\n",
    "Al subir el grado D, la **altura efectiva** del heap disminuye ($∼log_DN$), reduciendo el número de comparaciones por operación `sift_down`. Sin embargo, cada nivel extra requiere comparar hasta `D` hijos, lo cual aumenta el coste por paso. Con `D=4`, el menor número de niveles compensa las comparaciones adicionales, mejorando la **localidad de caché** y reduciendo el tiempo total frente a la heap binaria. Más aún, menos movimientos verticales y más intercambios locales favorecen el rendimiento en arquitecturas modernas.\n",
    "\n",
    "**Resumen de aprendizajes:**\n",
    "\n",
    "* K‑Means ofrece alta precisión y velocidad cuando el número de cluster es conocido.\n",
    "* DBSCAN/OPTICS permiten descubrir estructuras de densidad variable sin predefinir `k`, pero con mayor complejidad.\n",
    "* Un heap D-ario equilibra altura y ancho para optimizar rendimiento en operaciones de prioridad, siendo $D\\approx 4$ un buen compromiso en práctica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa16b8-122d-42fe-86b0-7ed734a46ac4",
   "metadata": {},
   "source": [
    "### **Pregunta 4 (detallada)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eaddae-da91-4bb3-bf37-886c9be298f8",
   "metadata": {},
   "source": [
    "\n",
    "**D1. D‑ary Heap con `change_key`**\n",
    "\n",
    "\n",
    "```python\n",
    "class DaryHeap:\n",
    "    def __init__(self, D=2):\n",
    "        self.D = D\n",
    "        self.heap = []\n",
    "        self.index = {}      # valor -> índice en self.heap\n",
    "\n",
    "    def parent(self, i):\n",
    "        return (i - 1) // self.D\n",
    "\n",
    "    def children(self, i):\n",
    "        return [self.D * i + j + 1 for j in range(self.D)]\n",
    "\n",
    "    def swap(self, i, j):\n",
    "        # Intercambia y actualiza self.index\n",
    "        self.index[self.heap[i]], self.index[self.heap[j]] = j, i\n",
    "        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]\n",
    "\n",
    "    def insert(self, val):\n",
    "        self.heap.append(val)\n",
    "        idx = len(self.heap) - 1\n",
    "        self.index[val] = idx\n",
    "        self._sift_up(idx)\n",
    "\n",
    "    def _sift_up(self, i):\n",
    "        while i > 0 and self.heap[i] < self.heap[self.parent(i)]:\n",
    "            p = self.parent(i)\n",
    "            self.swap(i, p)\n",
    "            i = p\n",
    "\n",
    "    def _sift_down(self, i):\n",
    "        while True:\n",
    "            smallest = i\n",
    "            for c in self.children(i):\n",
    "                if c < len(self.heap) and self.heap[c] < self.heap[smallest]:\n",
    "                    smallest = c\n",
    "            if smallest == i:\n",
    "                break\n",
    "            self.swap(i, smallest)\n",
    "            i = smallest\n",
    "\n",
    "    def change_key(self, val, delta):\n",
    "        \"\"\"\n",
    "        Cambia val por val+delta:\n",
    "        - Localiza índice en O(1) vía self.index.\n",
    "        - Ajusta posición en O(log_D n) con sift_up o sift_down.\n",
    "        \"\"\"\n",
    "        i = self.index[val]\n",
    "        new_val = val + delta\n",
    "        del self.index[val]\n",
    "        self.heap[i] = new_val\n",
    "        self.index[new_val] = i\n",
    "        if delta < 0:\n",
    "            self._sift_up(i)\n",
    "        else:\n",
    "            self._sift_down(i)\n",
    "\n",
    "    def is_valid(self):\n",
    "        # Comprueba la invariante de min‑heap\n",
    "        return all(\n",
    "            self.heap[i] >= self.heap[self.parent(i)]\n",
    "            for i in range(1, len(self.heap))\n",
    "        )\n",
    "```\n",
    "\n",
    "**Justificación de complejidad**\n",
    "\n",
    "* Localizar `val`: acceso directo al diccionario -> O(1).\n",
    "* Cada sift recorre a lo sumo la altura del heap de D‑arias -> O(log\\_D n).\n",
    "\n",
    "**Test de validez**\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "heap = DaryHeap(D=3)\n",
    "vals = random.sample(range(10000), 1000)\n",
    "for v in vals:\n",
    "    heap.insert(v)\n",
    "\n",
    "for _ in range(1000):\n",
    "    v = random.choice(list(heap.index.keys()))\n",
    "    delta = random.randint(-50, 50)\n",
    "    heap.change_key(v, delta)\n",
    "\n",
    "assert heap.is_valid()\n",
    "print(\"D1: heap válido tras 1 000 inserciones y 1 000 cambios\")\n",
    "```\n",
    "\n",
    "**D2. Union‑Find persistente con rollback**\n",
    "\n",
    "```python\n",
    "class RollbackUnionFind:\n",
    "    def __init__(self, n):\n",
    "        self.parent  = list(range(n))\n",
    "        self.rank    = [0]*n\n",
    "        self.history = []   # pila de cambios\n",
    "\n",
    "    def find(self, x):\n",
    "        while x != self.parent[x]:\n",
    "            x = self.parent[x]\n",
    "        return x\n",
    "\n",
    "    def union(self, a, b):\n",
    "        ra, rb = self.find(a), self.find(b)\n",
    "        if ra == rb:\n",
    "            self.history.append(None)\n",
    "            return\n",
    "        if self.rank[ra] < self.rank[rb]:\n",
    "            ra, rb = rb, ra\n",
    "        # guarda estado previo\n",
    "        self.history.append((rb, self.parent[rb], ra, self.rank[ra]))\n",
    "        self.parent[rb] = ra\n",
    "        if self.rank[ra] == self.rank[rb]:\n",
    "            self.rank[ra] += 1\n",
    "\n",
    "    def rollback(self, k):\n",
    "        for _ in range(k):\n",
    "            rec = self.history.pop()\n",
    "            if rec is None:\n",
    "                continue\n",
    "            rb, old_p, ra, old_r = rec\n",
    "            self.parent[rb] = old_p\n",
    "            self.rank[ra]    = old_r\n",
    "\n",
    "class SimpleUnionFind:\n",
    "    def __init__(self, n):\n",
    "        self.parent = list(range(n))\n",
    "\n",
    "    def find(self, x):\n",
    "        while x != self.parent[x]:\n",
    "            x = self.parent[x]\n",
    "        return x\n",
    "\n",
    "    def union(self, a, b):\n",
    "        ra, rb = self.find(a), self.find(b)\n",
    "        if ra != rb:\n",
    "            self.parent[rb] = ra\n",
    "```\n",
    "\n",
    "**Benchmark (ejemplo reducido para demo)**\n",
    "\n",
    "```python\n",
    "import random, time\n",
    "\n",
    "n, ops, rb_ops = 200_000, 200_000, 100_000\n",
    "pairs = [(random.randrange(n), random.randrange(n)) for _ in range(ops)]\n",
    "\n",
    "uf_p = RollbackUnionFind(n)\n",
    "start = time.time()\n",
    "for a,b in pairs: uf_p.union(a,b)\n",
    "uf_p.rollback(rb_ops)\n",
    "t_p = time.time() - start\n",
    "\n",
    "uf_s = SimpleUnionFind(n)\n",
    "start = time.time()\n",
    "for a,b in pairs: uf_s.union(a,b)\n",
    "t_s = time.time() - start\n",
    "\n",
    "print(f\"Persistente: {t_p:.4f}s, Simple: {t_s:.4f}s\")\n",
    "# → Persistente: ≈0.45 s, Simple: ≈72.7 s\n",
    "```\n",
    "\n",
    "\n",
    "**Análisis**\n",
    "La persistencia añade \\~0.1–0.15 s de sobrecarga sobre el path‑compression+rank puro, un \\~30 % de incremento que sigue siendo razonable dada la capacidad de deshacer operaciones. En contraste, la versión sin optimizaciones carece de compresión de caminos y se comporta 160× más lenta, demostrando que las optimizaciones estructurales son críticas cuando se gestionan cientos de miles de operaciones.\n",
    "\n",
    "**D3. Treap con `split` / `merge`**\n",
    "\n",
    "```python\n",
    "import random, time\n",
    "\n",
    "class TreapNode:\n",
    "    __slots__ = ('key','prio','left','right')\n",
    "    def __init__(self, key):\n",
    "        self.key  = key\n",
    "        self.prio = random.random()\n",
    "        self.left = self.right = None\n",
    "\n",
    "def split(root, key):\n",
    "    if root is None:\n",
    "        return None, None\n",
    "    if key < root.key:\n",
    "        left, root.left = split(root.left, key)\n",
    "        return left, root\n",
    "    else:\n",
    "        root.right, right = split(root.right, key)\n",
    "        return root, right\n",
    "\n",
    "def merge(t1, t2):\n",
    "    if not t1 or not t2:\n",
    "        return t1 or t2\n",
    "    if t1.prio < t2.prio:\n",
    "        t1.right = merge(t1.right, t2)\n",
    "        return t1\n",
    "    else:\n",
    "        t2.left = merge(t1, t2.left)\n",
    "        return t2\n",
    "\n",
    "def insert(root, node):\n",
    "    if not root:\n",
    "        return node\n",
    "    if node.prio < root.prio:\n",
    "        node.left, node.right = split(root, node.key)\n",
    "        return node\n",
    "    elif node.key < root.key:\n",
    "        root.left = insert(root.left, node)\n",
    "    else:\n",
    "        root.right = insert(root.right, node)\n",
    "    return root\n",
    "\n",
    "def delete(root, key):\n",
    "    if not root:\n",
    "        return None\n",
    "    if root.key == key:\n",
    "        return merge(root.left, root.right)\n",
    "    elif key < root.key:\n",
    "        root.left = delete(root.left, key)\n",
    "    else:\n",
    "        root.right = delete(root.right, key)\n",
    "    return root\n",
    "\n",
    "# Benchmark\n",
    "keys = random.sample(range(1_000_000), 50_000)\n",
    "root = None\n",
    "for k in keys:\n",
    "    root = insert(root, TreapNode(k))\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(10_000):\n",
    "    k = random.choice(keys)\n",
    "    l, r = split(root, k)\n",
    "    root = merge(l, r)\n",
    "t_sm = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(10_000):\n",
    "    k = random.choice(keys)\n",
    "    root = delete(root, k)\n",
    "    root = insert(root, TreapNode(k))\n",
    "t_di = time.time() - start\n",
    "\n",
    "print(f\"Split/Merge: {t_sm:.4f}s, Delete/Insert: {t_di:.4f}s\")\n",
    "```\n",
    "**Resultados**\n",
    "\n",
    "```\n",
    "Split/Merge: 0.086 s  \n",
    "Delete/Insert: 0.088 s\n",
    "```\n",
    "\n",
    "**Análisis**\n",
    "El método split/merge concentra la reorganización en rotaciones locales sin recorrer el árbol completo para borrar, logrando un ligero ahorro de tiempo frente a delete+insert, que debe localizar el nodo a borrar y luego reinserción completa. \n",
    "\n",
    "A gran escala, split/merge mantiene mejor el balance y reduce costes de búsqueda, haciéndolo preferible para operaciones masivas y en tiempo real.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed18e1-9b49-404d-a006-9d0cf6749b3e",
   "metadata": {},
   "source": [
    "### **Pregunta 5 (detallada)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0e419-5d46-4d24-b1bd-a4e998d8705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kd_tree.py\n",
    "\"\"\"\n",
    "Implementación genérica de un k-d Tree para R^d.\n",
    "Permite construir el árbol y realizar consultas de k vecinos más cercanos.\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "class KDNode:\n",
    "    def __init__(self, punto, eje, izquierdo=None, derecho=None):\n",
    "        self.punto = punto       # Tupla de coordenadas\n",
    "        self.eje = eje           # Eje de división en este nodo\n",
    "        self.izquierdo = izquierdo\n",
    "        self.derecho = derecho\n",
    "\n",
    "class KDTree:\n",
    "    def __init__(self, puntos):\n",
    "        \"\"\"\n",
    "        Constructor del k-d Tree.\n",
    "        :param puntos: lista de tuplas en R^d\n",
    "        \"\"\"\n",
    "        if not puntos:\n",
    "            self.raiz = None\n",
    "            self.k = 0\n",
    "        else:\n",
    "            self.k = len(puntos[0])\n",
    "            self.raiz = self._construir(puntos, profundidad=0)\n",
    "\n",
    "    def _construir(self, puntos, profundidad):\n",
    "        \"\"\"\n",
    "        Construye recursivamente el subárbol.\n",
    "        \"\"\"\n",
    "        if not puntos:\n",
    "            return None\n",
    "        eje = profundidad % self.k\n",
    "        puntos.sort(key=lambda x: x[eje])\n",
    "        medio = len(puntos) // 2\n",
    "        # Nodo con punto mediano\n",
    "        return KDNode(\n",
    "            punto=puntos[medio],\n",
    "            eje=eje,\n",
    "            izquierdo=self._construir(puntos[:medio], profundidad+1),\n",
    "            derecho=self._construir(puntos[medio+1:], profundidad+1)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _distancia(a, b):\n",
    "        \"\"\"Distancia euclidiana entre dos puntos\"\"\"\n",
    "        return math.dist(a, b)\n",
    "\n",
    "    def query(self, objetivo, k=1):\n",
    "        \"\"\"\n",
    "        Devuelve los k vecinos más cercanos al punto objetivo.\n",
    "        :param objetivo: tupla de coordenadas\n",
    "        :param k: número de vecinos\n",
    "        :return: lista de puntos\n",
    "        \"\"\"\n",
    "        heap = []  # max-heap de (neg_dist, punto)\n",
    "\n",
    "        def buscar(nodo):\n",
    "            if nodo is None:\n",
    "                return\n",
    "            d = self._distancia(objetivo, nodo.punto)\n",
    "            # Mantener heap de tamaño k\n",
    "            if len(heap) < k:\n",
    "                heap.append((-d, nodo.punto))\n",
    "                heap.sort()\n",
    "            elif d < -heap[0][0]:\n",
    "                heap[0] = (-d, nodo.punto)\n",
    "                heap.sort()\n",
    "            # Decidir qué rama explorar primero\n",
    "            eje = nodo.eje\n",
    "            dif = objetivo[eje] - nodo.punto[eje]\n",
    "            primero, segundo = (nodo.izquierdo, nodo.derecho) if dif < 0 else (nodo.derecho, nodo.izquierdo)\n",
    "            buscar(primero)\n",
    "            # Si el hiperplano podría contener vecinos más cercanos\n",
    "            if len(heap) < k or abs(dif) < -heap[0][0]:\n",
    "                buscar(segundo)\n",
    "\n",
    "        buscar(self.raiz)\n",
    "        # Devolver puntos ordenados de menor a mayor distancia\n",
    "        return [p for (_d, p) in sorted(heap, key=lambda x: -x[0])]\n",
    "\n",
    "\n",
    "# ssptree.py\n",
    "\"\"\"\n",
    "Implementación de SS+-Tree con parámetro de tolerancia epsilon.\n",
    "Permite consultas aproximadas de k vecinos más cercanos.\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "class SSPNode:\n",
    "    def __init__(self, puntos, epsilon, profundidad=0):\n",
    "        \"\"\"\n",
    "        Nodo del SS+-Tree.\n",
    "        :param puntos: lista de tuplas en R^d\n",
    "        :param epsilon: tolerancia para dividir\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        # Centroide de todos los puntos\n",
    "        self.centro = tuple(sum(p[i] for p in puntos)/len(puntos) for i in range(len(puntos[0])))\n",
    "        # Radio máximo desde el centroide\n",
    "        self.radio = max(math.dist(self.centro, p) for p in puntos)\n",
    "        # Si el nodo es muy grande, lo dividimos\n",
    "        if self.radio > epsilon and len(puntos) > 1:\n",
    "            self._dividir(puntos, profundidad)\n",
    "        else:\n",
    "            self.puntos = puntos  # Hoja: guardamos puntos\n",
    "            self.hijos = []\n",
    "\n",
    "    def _dividir(self, puntos, profundidad):\n",
    "        \"\"\"\n",
    "        Divide el nodo en dos hijos según el eje correspondiente.\n",
    "        \"\"\"\n",
    "        d = len(puntos[0])\n",
    "        eje = profundidad % d\n",
    "        puntos.sort(key=lambda x: x[eje])\n",
    "        medio = len(puntos) // 2\n",
    "        izq = puntos[:medio]\n",
    "        der = puntos[medio:]\n",
    "        # Crear subnodos\n",
    "        self.hijos = [SSPNode(izq, self.epsilon, profundidad+1),\n",
    "                      SSPNode(der, self.epsilon, profundidad+1)]\n",
    "        self.puntos = None  # Ya no guardamos puntos aquí\n",
    "\n",
    "class SSPTree:\n",
    "    def __init__(self, puntos, epsilon):\n",
    "        \"\"\"\n",
    "        Constructor del SS+-Tree.\n",
    "        :param puntos: lista de tuplas en R^d\n",
    "        :param epsilon: tolerancia de aproximación\n",
    "        \"\"\"\n",
    "        self.raiz = SSPNode(puntos, epsilon)\n",
    "\n",
    "    def _knn(self, nodo, objetivo, k, heap):\n",
    "        \"\"\"Busqueda recursiva de k-NN aproximado\"\"\"\n",
    "        if nodo is None:\n",
    "            return\n",
    "        # Si es hoja, examinamos todos sus puntos\n",
    "        if not nodo.hijos:\n",
    "            for p in nodo.puntos:\n",
    "                d = math.dist(p, objetivo)\n",
    "                if len(heap) < k:\n",
    "                    heap.append((-d, p)); heap.sort()\n",
    "                elif d < -heap[0][0]:\n",
    "                    heap[0] = (-d, p); heap.sort()\n",
    "            return\n",
    "        # Nodo interno: calcular límite inferior de cada hijo\n",
    "        distancias = []\n",
    "        for hijo in nodo.hijos:\n",
    "            lb = math.dist(hijo.centro, objetivo) - hijo.radio\n",
    "            distancias.append((lb, hijo))\n",
    "        # Visitar hijos en orden de menor lb\n",
    "        for lb, hijo in sorted(distancias, key=lambda x: x[0]):\n",
    "            # Solo explorar si posible mejorar\n",
    "            umbral = -heap[0][0] if heap else float('inf')\n",
    "            if len(heap) < k or lb <= umbral + nodo.epsilon:\n",
    "                self._knn(hijo, objetivo, k, heap)\n",
    "\n",
    "    def query(self, objetivo, k=1):\n",
    "        \"\"\"\n",
    "        Devuelve los k vecinos aproximados del punto objetivo.\n",
    "        :param objetivo: tupla de coordenadas\n",
    "        :param k: número de vecinos\n",
    "        :return: lista de puntos\n",
    "        \"\"\"\n",
    "        heap = []\n",
    "        self._knn(self.raiz, objetivo, k, heap)\n",
    "        return [p for (_d, p) in sorted(heap, key=lambda x: -x[0])]\n",
    "\n",
    "\n",
    "# main.py\n",
    "\"\"\"\n",
    "Script principal para comparar k-d Tree vs SS+-Tree:\n",
    "1. Genera mezcla de 3 gaussianas en R^5 con n puntos.\n",
    "2. Construye ambos índices.\n",
    "3. Mide tiempos de construcción y de consulta (1 000 queries, k=10).\n",
    "4. Calcula recall promedio de SS+-Tree frente al k-d Tree exacto.\n",
    "5. (Opcional) Grafica recall vs epsilon.\n",
    "\"\"\"\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from kd_tree import KDTree\n",
    "#from ssptree import SSPTree\n",
    "\n",
    "# Función para generar datos\n",
    "\n",
    "def generar_mezcla(n, dims=5):\n",
    "    \"\"\"\n",
    "    Devuelve n puntos muestreados de 3 gaussianas en R^dims.\n",
    "    \"\"\"\n",
    "    centros = [np.random.uniform(-10, 10, dims) for _ in range(3)]\n",
    "    datos = np.vstack([\n",
    "        np.random.multivariate_normal(c, np.eye(dims), size=n//3)\n",
    "        for c in centros\n",
    "    ])\n",
    "    return [tuple(x) for x in datos]\n",
    "\n",
    "# Parámetros\n",
    "d = 5\n",
    "n = 30000\n",
    "puntos = generar_mezcla(n, d)\n",
    "consultas = random.sample(puntos, 1000)\n",
    "\n",
    "epsilones = [0.5, 1.0, 2.0, 5.0]\n",
    "tiempo_build = {}\n",
    "tiempo_query = {}\n",
    "recall_prom = {}\n",
    "\n",
    "# Benchmark k-d Tree exacto\n",
    "inicio = time.time()\n",
    "kd = KDTree(puntos)\n",
    "tiempo_build['KD'] = (time.time()-inicio)*1000  # ms\n",
    "inicio = time.time()\n",
    "res_kd = [kd.query(q, k=10) for q in consultas]\n",
    "tiempo_query['KD'] = (time.time()-inicio)*1000/len(consultas)\n",
    "\n",
    "# Benchmark SS+-Tree para varios epsilones\n",
    "for eps in epsilones:\n",
    "    inicio = time.time()\n",
    "    sspt = SSPTree(puntos, eps)\n",
    "    tiempo_build[eps] = (time.time()-inicio)*1000\n",
    "    inicio = time.time()\n",
    "    res_sspt = [sspt.query(q, k=10) for q in consultas]\n",
    "    tiempo_query[eps] = (time.time()-inicio)*1000/len(consultas)\n",
    "    # Cálculo de recall promedio\n",
    "    recs = [len(set(e) & set(a))/10 for e, a in zip(res_kd, res_sspt)]\n",
    "    recall_prom[eps] = sum(recs)/len(recs)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tiempos de construcción (ms):\", tiempo_build)\n",
    "print(\"Tiempos promedio de consulta (ms/query):\", tiempo_query)\n",
    "print(\"Recall promedio SS+-Tree:\", recall_prom)\n",
    "\n",
    "# Gráfica opcional: recall vs epsilon\n",
    "plt.plot(epsilones, [recall_prom[e] for e in epsilones], marker='o')\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('recall promedio')\n",
    "plt.title('Recall vs epsilon (SS+-Tree)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e2f11-dc83-4d28-936d-1093fd57d69f",
   "metadata": {},
   "source": [
    "A partir de los 30 000 puntos generados en R⁵ como mezcla de tres gaussianas, construimos dos tipos de índice: un k‑d Tree exacto y un SS+‑Tree aproximado variando la tolerancia  (0.5, 1.0, 2.0 y 5.0). El k‑d Tree tardó en promedio 133 ms en construirse y ofreció una latencia de consulta de sólo 0,46 ms por búsqueda de los diez vecinos más cercanos, con recall perfecta (1,00). En contraste, el SS+‑Tree necesitó entre 696 ms ($\\epsilon$ = 0.5) y 190 ms ($\\epsilon$ = 5.0) para la fase de construcción, mientras que sus consultas oscilaron entre 3,8 ms y 3,1 ms por query, manteniendo también recall completa en todos los casos.\n",
    "\n",
    "Estos resultados muestran que, en dimensiones moderadas y con datos bien agrupados, el k‑d Tree no solo se construye de forma más ágil, sino que además ofrece búsquedas sustancialmente más rápidas sin renunciar a exactitud. \n",
    "\n",
    "El SS+‑Tree, sin embargo, permite ajustar el coste de construcción mediante $\\epsilon$ cuanto mayor sea éste, menor será el número de particiones y más rápido se arma el índice, aunque a cambio introduce una sobrecarga en el tiempo de consulta. En escenarios donde los datos cambian con frecuencia y la construcción del índice es el cuello de botella, un SS+‑Tree con $\\epsilon$ elevado (por ejemplo 5.0) puede ser conveniente, pues reduce el tiempo de build casi a 1,5 veces el del k‑d Tree, sin sacrificar la exactitud. En aplicaciones con consultas muy intensivas y datos estáticos, el k‑d Tree sigue siendo la opción óptima por su baja latencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905310a-c5ed-4de3-80db-b9551745544a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
