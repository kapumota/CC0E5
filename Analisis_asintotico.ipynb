{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6c4035-5534-4e30-922f-202bda0c6b42",
   "metadata": {},
   "source": [
    "### Notación asintótica\n",
    "\n",
    "Dadas las expresiones para mejor, promedio y peor caso, necesitamos representar formalmente las **cotas superior** y **cotas inferior**. Para ello, usamos cierta notación especial, que es el tema del siguiente cuaderno. Asumamos que el algoritmo se expresa como una función $f(n)$.\n",
    "\n",
    "\n",
    "#### Notación big-O\n",
    "\n",
    "Esta notación proporciona la **cota superior ajustada** (tight upper bound) de la función dada. Normalmente se representa como $f(n) = O(g(n))$. Esto significa que, para valores grandes de $n$, la tasa de crecimiento de $f(n)$ es **como máximo** $g(n)$.  \n",
    "Por ejemplo, si $f(n) = n^4 + 100n^2 + 10n + 50$, entonces $g(n)$ es $O(n^4)$.\n",
    "\n",
    "La definición formal es:  \n",
    "$$\n",
    "O(g(n)) = \\{\\,f(n): \\exists \\, c, n_0 > 0 \\;\\text{tal que}\\; 0 \\le f(n) \\le c\\,g(n) \\;\\;\\text{para todo}\\; n \\ge n_0\\}.\n",
    "$$\n",
    "\n",
    "En términos sencillos, queremos encontrar la **tasa de crecimiento más grande** que **domina** a $f(n)$ cuando $n$ tiende a infinito. Ignoramos las constantes y los términos de menor orden.\n",
    "\n",
    "Hay varios **ejemplos** sencillos:\n",
    "\n",
    "- $3n + 8$ es $O(n)$.  \n",
    "- $n^2 + 1$ es $O(n^2)$.  \n",
    "- $n^4 + 100n^2 + 50$ es $O(n^4)$.  \n",
    "- $2n^3 - 2n^2$ es $O(n^3)$.  \n",
    "- $4^{10}$ (constante) es $O(1)$.\n",
    "\n",
    "Generalmente descartamos valores más bajos de $n$. Esto significa que la tasa de crecimiento en valores más bajos de $n$ no es importante. por ejemplo $n_0$  es el punto a partir del cual necesitamos considerar la tasa de crecimiento para un algoritmo dado Por debajo de $n_0$, la tasa de crecimiento podría ser diferente. $n_0$ se llama umbral para la función dada.\n",
    "\n",
    "\n",
    "$O(g(n))$ es el conjunto de funciones con un orden de crecimiento menor o igual al de $g(n)$. Por ejemplo, $O(n^2)$ incluye $O(1)$, $O(n)$, $O(n \\log n)$, etc.\n",
    "\n",
    "#### ¿No hay unicidad?\n",
    "\n",
    "No hay un conjunto único de valores para $n_0$ y $c$ al probar los límites asintóticos. Consideremos, por ejemplo, $100n + 5 = O(n)$. Para esta función, hay múltiples valores posibles de $n_0$ y $c$.\n",
    "\n",
    "- **Solución 1:**   $100n + 5 \\leq 100n + n = 101n \\leq 101n$, para todo $n \\geq 5$, $n_0 = 5$ y $c = 101$ es una solución.\n",
    "\n",
    "- **Solución 2:**   $100n + 5 \\leq 100n + 5n = 105n \\leq 105n$, para todo $n \\geq 1$, $n_0 = 1$ y $c = 105$ también es una solución.\n",
    "\n",
    "\n",
    "#### Notación big omega ($\\Omega$)\n",
    "\n",
    "Similar a big-O, esta notación proporciona la **cota inferior ajustada** (tight lower bound) de la función, y se representa como $f(n) = \\Omega(g(n))$. Esto significa que, para valores grandes de $n$, la tasa de crecimiento de $f(n)$ es **como mínimo** $g(n)$.  \n",
    "La definición formal es:  \n",
    "\n",
    "$$\n",
    "\\Omega(g(n)) = \\{\\,f(n): \\exists \\, c, n_0 > 0 \\;\\text{tal que}\\; 0 \\le c\\,g(n) \\le f(n) \\;\\;\\text{para todo}\\; n \\ge n_0\\}.\n",
    "$$\n",
    "\n",
    "Por ejemplo, si $f(n) = 100n^2 + 10n + 50$, su cota inferior ajustada es $\\Omega(n^2)$.\n",
    "\n",
    "**Ejemplos:**\n",
    "\n",
    "**Ejemplo 1:** Encontrar la cota inferior para $f(n) = 5n^2$.\n",
    "\n",
    "**Solución:**  \n",
    "$\\exists c, n_0$ tal que:  \n",
    "$0 \\leq cn^2 \\leq 5n^2 \\Rightarrow c = 1$ y $n_0 = 1$.  \n",
    "Por lo tanto, $5n^2 = \\Omega(n^2)$ con $c = 1$ y $n_0 = 1$.\n",
    "\n",
    "\n",
    "**Ejemplo 2:** Probar que $f(n) = 100n + 5 \\neq \\Omega(n^2)$.\n",
    "\n",
    "**Solución:**  \n",
    "$\\exists c, n_0$ tal que:  \n",
    "$0 \\leq cn^2 \\leq 100n + 5$.  \n",
    "$100n + 5 \\leq 100n + 5n \\ (\\forall n \\geq 1)\\ = 105n$.  \n",
    "$cn^2 \\leq 105n \\Rightarrow n(cn - 105) \\leq 0$.  \n",
    "\n",
    "Dado que $n$ es positivo $\\Rightarrow cn - 105 \\leq 0$.  \n",
    "$\\Rightarrow$ Contradicción: $n$ no puede ser menor que una constante.\n",
    "\n",
    "\n",
    "**Ejemplo 3:** :$2n = \\Omega(n), \\quad n^3 = \\Omega(n^3), \\quad \\log n = \\Omega(\\log n)$.\n",
    "\n",
    "\n",
    "#### 1.4 Notación big-theta ($\\Theta$)\n",
    "\n",
    "Esta notación decide si las cotas superior (**O**) e inferior (**$\\Omega$**) de una función (algoritmo) son la **misma**. Es decir, si tanto la cota superior como la inferior tienen el **mismo orden** de crecimiento, entonces decimos que la función se encuentra en $\\Theta(g(n))$.  \n",
    "\n",
    "La definición formal:  \n",
    "\n",
    "$$\n",
    "\\Theta(g(n)) = \\{\\,f(n) : \\exists\\, c_1, c_2, n_0 > 0 \\;\\text{tal que}\\; 0 \\le c_1 \\, g(n) \\le f(n) \\le c_2 \\, g(n) \\;\\;\\text{para todo}\\; n \\ge n_0\\}.\n",
    "$$\n",
    "$g(n)$ es una cota asintótica ajustada para $f(n)$. $\\Theta(g(n))$ es el conjunto de funciones con el mismo orden de crecimiento que $g(n)$.\n",
    "\n",
    "Por ejemplo, si $f(n) = 10n + n$, es $O(n)$ y también $\\Omega(n)$. Por lo tanto, $f(n) = \\Theta(n)$.\n",
    "\n",
    "\n",
    "En este caso, las tasas de crecimiento en el mejor caso y en el peor caso son las mismas. Como resultado, el caso promedio también será el mismo. Para una función dada (algoritmo), si las tasas de crecimiento (cotas) para los casos $O$ y $\\Omega$ no son las mismas, entonces la tasa de crecimiento para el caso $\\Theta$ puede no ser la misma. En este caso, necesitamos considerar todos los posibles tiempos de ejecución y tomar el promedio de estos.\n",
    "\n",
    "\n",
    "#### **Ejemplos**\n",
    "\n",
    "**Ejemplo 1:** Encontrar la cota $\\Theta$ para $f(n) = \\frac{n^2}{2} - \\frac{n}{2}$.  \n",
    "\n",
    "**Solución:**  \n",
    "\n",
    "$$\n",
    "\\frac{n^2}{5} \\leq \\frac{n^2}{2} - \\frac{n}{2} \\leq n^2, \\quad \\text{para todo } n \\geq 1\n",
    "$$  \n",
    "\n",
    "Por lo tanto:  \n",
    "\n",
    "$$\n",
    "\\frac{n^2}{5} = \\Theta(n^2) \\text{ con } c_1 = \\frac{1}{5}, c_2 = 1 \\text{ y } n_0 = 1\n",
    "$$\n",
    "\n",
    "\n",
    "**Ejemplo 2:** Probar que $f(n) \\neq \\Theta(n^2)$.\n",
    "\n",
    "**Solución:**  \n",
    "$$\n",
    "c_1n^2 \\leq n \\leq c_2n^2 \\text{ solo se cumple para: } n \\leq \\frac{1}{c_1}\n",
    "$$\n",
    "\n",
    "Por lo tanto:  \n",
    "$$\n",
    "n \\notin \\Theta(n^2)\n",
    "$$\n",
    "\n",
    "\n",
    "**Ejemplo 3:** Probar que $6n^3 \\neq \\Theta(n^2)$.\n",
    "\n",
    "**Solución:**  \n",
    "$$\n",
    "c_1n^2 \\leq 6n^3 \\leq c_2n^2 \\text{ solo se cumple para: } n \\leq \\frac{c_2}{6}\n",
    "$$  \n",
    "Por lo tanto:  \n",
    "$$\n",
    "6n^3 \\neq \\Theta(n^2)\n",
    "$$\n",
    "\n",
    "\n",
    "**Ejemplo 4:** Probar que $$n \\neq \\Theta(\\log n)$$.\n",
    "\n",
    "**Solución:**  \n",
    "$$\n",
    "c_1\\log n \\leq n \\leq c_2\\log n \\Rightarrow c_2 \\geq \\frac{n}{\\log n}, \\forall n \\geq n_0\n",
    "$$  \n",
    "\n",
    "**Imposible.**\n",
    "\n",
    "\n",
    "**Notas importantes:**  \n",
    "\n",
    "Para el análisis (mejor caso, peor caso y promedio), tratamos de dar la cota superior ($O$) y la cota inferior ($\\Omega$) junto con el tiempo de ejecución promedio ($\\Theta$).\n",
    "\n",
    "A partir de los ejemplos anteriores, también debe quedar claro que, para una función (algoritmo) dada, obtener la cota superior ($O$) y la cota inferior ($\\Omega$) y el tiempo de ejecución promedio ($\\Theta$) puede no ser siempre factible. Por ejemplo, si estamos discutiendo el mejor caso de un algoritmo, tratamos de dar la cota superior ($O$) y el tiempo de ejecución promedio ($\\Theta$).  \n",
    "\n",
    "#### ¿Por qué se llama análisis asintótico?\n",
    "\n",
    "A partir de la discusión anterior (para las tres notaciones: peor caso, mejor caso y caso promedio), podemos entender fácilmente que, en cada caso para una función dada $f(n)$, tratamos de encontrar otra función $g(n)$ que **aproxime** $f(n)$ cuando $n$ toma valores grandes. Esto significa que $g(n)$ también es una curva que aproxima $f(n)$ en valores grandes de $n$.\n",
    "\n",
    "En matemáticas, a una curva de este tipo se le llama **[curva asintótica](https://medium.com/@MA/asymptotic-notations-for-the-analysis-of-algorithms-71fdc3a48ee4)**. En otras palabras, $g(n)$ es la curva asintótica de $f(n)$. Por esta razón, al análisis de algoritmos se le llama **análisis asintótico**.\n",
    "\n",
    "\n",
    "#### Guías para el análisis asintótico\n",
    "\n",
    "Existen algunas reglas generales que nos ayudan a determinar el tiempo de ejecución de un algoritmo.\n",
    "\n",
    "1. **Bucles (loops)**  \n",
    "   El tiempo de ejecución de un bucle es, como máximo, el tiempo de ejecución de las sentencias dentro del bucle (incluyendo las evaluaciones de la condición) multiplicado por el número de iteraciones.\n",
    "\n",
    "   ```python\n",
    "   # se ejecuta n veces\n",
    "   for i in range(0, n):\n",
    "       print('Actual numero:', i)  # tiempo constante\n",
    "   # Tiempo total = una constante c x n = c*n => O(n).\n",
    "   ```\n",
    "\n",
    "2. **Bucles anidados**  \n",
    "   Analiza desde el interior hacia afuera. El tiempo de ejecución total es el producto de los tamaños de todos los bucles.\n",
    "\n",
    "   ```python\n",
    "   # bucle externo se ejecuta n veces\n",
    "   for i in range(0, n):\n",
    "       # bucle interno se ejecuta n veces\n",
    "       for j in range(0, n):\n",
    "           print('valor i  %d y valor j  %d' % (i, j))  # tiempo constante\n",
    "\n",
    "   # Tiempo total: c * n * n = c*n^2 => O(n^2).\n",
    "   ```\n",
    "\n",
    "3. **Sentencias consecutivas**  \n",
    "   Suma las complejidades de cada sentencia.\n",
    "\n",
    "   ```python\n",
    "   n = 100  # tiempo constante c0\n",
    "\n",
    "   # se ejecuta n veces\n",
    "   for i in range(0, n):\n",
    "       print('Actual numero:', i)  # tiempo constante c1\n",
    "\n",
    "   # bucle externo n veces\n",
    "   for i in range(0, n):\n",
    "       # bucle interno n veces\n",
    "       for j in range(0, n):\n",
    "           print('Valor i  %d y valor j %d' % (i, j))  # tiempo constante c2\n",
    "\n",
    "   # Tiempo total = c0 + c1*n + c2*n^2 => O(n^2).\n",
    "   ```\n",
    "\n",
    "4. **Sentencias if-then-else**  \n",
    "   El tiempo de ejecución en el peor caso es el tiempo de la comparación, más el tiempo de la parte `then` o la parte `else` (la que tome más tiempo).\n",
    "\n",
    "   ```python\n",
    "   if n < 1:\n",
    "       print(\"Valor equivocado\")  # tiempo constante\n",
    "       print(n)              # tiempo constante\n",
    "   else:\n",
    "       for i in range(0, n):\n",
    "           print('Actual numero:', i)  # se ejecuta n veces\n",
    "\n",
    "   # Tiempo total = c0 + c1*n => O(n).\n",
    "   ```\n",
    "\n",
    "5. **Complejidad logarítmica**  \n",
    "   Un algoritmo es $O(\\log n)$ si le toma tiempo constante reducir el **tamaño del problema** en una fracción (usualmente la mitad). Por ejemplo:\n",
    "\n",
    "   ```python\n",
    "   def Logarithms(n):\n",
    "       i = 1\n",
    "       while i <= n:\n",
    "           i = i * 2\n",
    "           print(i)\n",
    "\n",
    "   Logarithms(100)\n",
    "   ```\n",
    "   Si observamos con cuidado, el valor de `i` se **duplica** cada vez. Suponiendo que el bucle se ejecute $k$ veces, al salir se cumple $2^k \\approx n$.  \n",
    "   Tomando logaritmo a ambos lados:  \n",
    "   $$\n",
    "   \\log(2^k) = \\log(n) \\quad \\Rightarrow \\quad k = \\log_2 n\n",
    "   $$  \n",
    "   Por lo tanto, el tiempo total es $O(\\log n)$.\n",
    "\n",
    "   > **Nota**: Para el caso inverso (disminuir a la mitad), también obtenemos $O(\\log n)$. Un ejemplo típico es la **búsqueda binaria**, en la que cada vez descartamos la mitad del espacio de búsqueda.\n",
    "\n",
    "   ```python\n",
    "   def Logarithms(n):\n",
    "       i = n\n",
    "       while i >= 1:\n",
    "           i = i // 2\n",
    "           print(i)\n",
    "\n",
    "       Logarithms(100)\n",
    "   ```\n",
    "\n",
    "\n",
    "#### Propiedades de las notaciones\n",
    "\n",
    "- **Transitividad**:  \n",
    "  Si $f(n) = O(g(n))$ y $g(n) = O(h(n))$, entonces $f(n) = O(h(n))$. Esto también aplica para $\\Omega$.  \n",
    "- **Reflexividad**:  \n",
    "  $f(n) = O(f(n))$. Válido para $O$ y $\\Omega$.  \n",
    "- **Simetría**:  \n",
    "  $f(n) = O(g(n))$ si y solo si $g(n) = \\Omega(f(n))$.  \n",
    "- **Transposición simétrica**:  \n",
    "  $f(n) = O(g(n))$ si y solo si $g(n) = \\Omega(f(n))$. (Es la misma idea de la propiedad de simetría.)\n",
    "\n",
    "#### Análisis amortizado\n",
    "\n",
    "El análisis amortizado se refiere a determinar el **tiempo de ejecución promedio** para una **secuencia de operaciones**. Es distinto al **análisis de caso promedio**, porque en el análisis amortizado no se hacen suposiciones sobre la distribución de los datos, mientras que el análisis de caso promedio supone que los datos no son \"malos\" (por ejemplo, algunos algoritmos de ordenamiento funcionan bien en promedio, pero muy mal en ciertos ordenamientos de entrada).El análisis amortizado es un análisis de **peor caso** para **toda la secuencia** de operaciones, no para operaciones individuales.  \n",
    "\n",
    "Se motiva para entender mejor el tiempo de ejecución de ciertas técnicas, cuando la mayoría de operaciones son \"baratas\" pero algunas pocas pueden ser \"caras\". Si se puede mostrar que las operaciones costosas son raras, se compensa con las baratas.\n",
    "\n",
    "La idea es asignar un \"costo artificial\" a cada operación de la secuencia, tal que la **suma de los costos artificiales** limite o \"amortigüe\" la suma de los costos reales. Ese costo artificial se llama **costo amortizado** de la operación. \n",
    "Para analizar el tiempo total de ejecución, el costo amortizado provee una manera correcta de entender el tiempo global. Sin embargo, no limita el tiempo de ejecución de una operación individual (que aún podría ser costosa en un punto aislado).\n",
    "\n",
    "**Ejemplo:** Consideremos un arreglo de elementos del cual queremos encontrar el k-ésimo elemento más pequeño. Podemos resolver este problema utilizando ordenamiento. Después de ordenar el arreglo dado, solo necesitamos devolver el $k$-ésimo elemento.  \n",
    "El costo de realizar el ordenamiento (suponiendo un algoritmo de ordenamiento basado en comparaciones) es $O(n \\log n)$. Si realizamos $n$ selecciones de este tipo, el costo promedio de cada selección es $O(n \\log n /n) = O(\\log n)$. Esto indica claramente que ordenar una sola vez reduce la complejidad de las operaciones posteriores.\n",
    "\n",
    "#### Casos\n",
    "\n",
    "##### **1. Arreglos dinámicos**\n",
    "\n",
    "**Descripción del ejemplo:**\n",
    "Los arreglos dinámicos, como los `ArrayList` en Java o los `vector` en C++, permiten cambiar su tamaño durante la ejecución. Cuando se agrega un elemento y el arreglo está lleno, se crea un nuevo arreglo con mayor capacidad (generalmente el doble), y se copian los elementos existentes al nuevo arreglo.\n",
    "\n",
    "**Análisis amortizado:**\n",
    "Aunque una operación de inserción puede requerir una copia de todos los elementos existentes (lo que tiene un costo de $O(n)$), la mayoría de las inserciones son de costo constante $O(1)$. Usando el análisis amortizado, el costo promedio por inserción sigue siendo $O(1)$ a lo largo de una secuencia de operaciones, ya que las operaciones costosas de copia ocurren raramente.\n",
    "\n",
    "##### **2. Pilas con operaciones de apilado y desapilado**\n",
    "\n",
    "**Descripción del ejemplo:**\n",
    "Consideremos una pila que soporta operaciones `push` (apilar) y `pop` (desapilar). Además, supongamos que la pila puede ocasionalmente realizar operaciones adicionales, como invertir los elementos.\n",
    "\n",
    "**Análisis amortizado:**\n",
    "Aunque una operación individual como invertir la pila puede tener un costo alto ($O(n)$), si esta operación se realiza solo después de muchas operaciones de `push` y `pop`, el costo se distribuye a lo largo de todas las operaciones. Por lo tanto, el costo amortizado por operación sigue siendo $O(1)$, ya que las operaciones costosas son compensadas por muchas operaciones de bajo costo.\n",
    "\n",
    "##### **3. Estructuras de unión-find con compresión de caminos**\n",
    "\n",
    "**Descripción del ejemplo:**\n",
    "La estructura de datos unión-find es utilizada para gestionar conjuntos disjuntos y soporta operaciones de `find` y `union`. Al implementar técnicas como la compresión de caminos y la unión por rango, se optimiza el tiempo de ejecución de estas operaciones.\n",
    "\n",
    "**Análisis amortizado:**\n",
    "Aunque una operación `find` individual podría parecer costosa, las optimizaciones aseguran que una secuencia de $m$ operaciones sobre $n$ elementos tenga un tiempo total de casi $O(m)$. Por lo tanto, el costo amortizado por operación es prácticamente constante, aunque algunas operaciones específicas puedan tener un costo mayor.\n",
    "\n",
    "##### **Diferencias con el análisis de costo promedio**\n",
    "\n",
    "- **Análisis amortizado:**\n",
    "  - **Enfoque:** Considera una secuencia de operaciones y distribuye el costo total de la secuencia entre todas las operaciones.\n",
    "  - **Garantía:** Proporciona una cota superior garantizada para el costo promedio por operación, independientemente de la distribución de las entradas.\n",
    "  - **Aplicabilidad:** Es útil para estructuras de datos donde ciertas operaciones ocasionales son costosas, pero el costo se amortiza a lo largo de muchas operaciones de bajo costo.\n",
    "\n",
    "- **Análisis de costo promedio:**\n",
    "  - **Enfoque:** Calcula el costo esperado por operación, asumiendo una distribución de probabilidad específica para las entradas.\n",
    "  - **Dependencia:** Depende de supuestos sobre cómo se distribuyen las operaciones o los datos de entrada.\n",
    "  - **Limitación:** No siempre proporciona garantías en el peor de los casos, ya que está basado en promedios probabilísticos.\n",
    "\n",
    "Mientras que el análisis amortizado garantiza que el costo promedio por operación será bajo en una secuencia de operaciones sin asumir nada sobre la distribución de las entradas, el análisis de costo promedio se basa en supuestos probabilísticos sobre cómo se comportarán las entradas o las operaciones, lo que puede no siempre reflejar el peor de los casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131172f-84b1-455c-95fb-f1d0a2e0c9e2",
   "metadata": {},
   "source": [
    "**Caso de análisis: caché LRU**\n",
    "\n",
    "Implementaremos una caché LRU (Least Recently Used) utilizando un diccionario (dict) y una lista doblemente enlazada (collections.OrderedDict). Esta estructura permite gestionar operaciones de inserción, acceso y eliminación de elementos. Luego, compararemos el costo amortizado con el costo promedio al acceder repetidamente a elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f305a521-347b-4b0b-9946-3f113a2f7fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de análisis\n",
      "Operaciones: 100000, Capacidad de caché: 1000\n",
      "\n",
      "Caso promedio (tiempo total promedio): 0.066863 segundos\n",
      "Costo amortizado, promedio por operación: 0.00000085 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.cache = OrderedDict()  # Almacena los pares clave-valor\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def get(self, key):\n",
    "        # Si el elemento está en la caché, lo movemos al final (más recientemente usado)\n",
    "        if key in self.cache:\n",
    "            value = self.cache.pop(key)\n",
    "            self.cache[key] = value\n",
    "            return value\n",
    "        return -1  # Clave no encontrada\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            self.cache.pop(key)  # Eliminamos para actualizar el orden\n",
    "        elif len(self.cache) >= self.capacity:\n",
    "            self.cache.popitem(last=False)  # Eliminamos el menos recientemente usado (primer elemento)\n",
    "        self.cache[key] = value  # Insertamos el nuevo par clave-valor\n",
    "\n",
    "# Función para medir el tiempo de operaciones\n",
    "def measure_lru_operations(cache, operations):\n",
    "    start_time = time.time()\n",
    "    for operation in operations:\n",
    "        if operation[0] == \"get\":\n",
    "            cache.get(operation[1])\n",
    "        elif operation[0] == \"put\":\n",
    "            cache.put(operation[1], operation[2])\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Generación de operaciones simuladas\n",
    "def generate_operations(num_operations, cache_capacity):\n",
    "    operations = []\n",
    "    for i in range(num_operations):\n",
    "        if i % 3 == 0:\n",
    "            # 1 de cada 3 operaciones es un acceso de lectura\n",
    "            operations.append((\"get\", i % cache_capacity))\n",
    "        else:\n",
    "            # Operaciones de escritura con claves aleatorias\n",
    "            operations.append((\"put\", i, i * 100))\n",
    "    return operations\n",
    "\n",
    "# Comparación del análisis\n",
    "def amortized_vs_average_test(num_operations, cache_capacity, num_runs):\n",
    "    print(f\"Comparación de análisis\")\n",
    "    print(f\"Operaciones: {num_operations}, Capacidad de caché: {cache_capacity}\\n\")\n",
    "    \n",
    "    total_time_average = 0\n",
    "    total_time_amortized = 0\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        operations = generate_operations(num_operations, cache_capacity)\n",
    "        cache = LRUCache(cache_capacity)\n",
    "        \n",
    "        # Caso promedio\n",
    "        total_time_average += measure_lru_operations(cache, operations)\n",
    "        \n",
    "        # Reiniciar caché y medir tiempo amortizado\n",
    "        amortized_cost = []\n",
    "        for op in operations:\n",
    "            start_time = time.time()\n",
    "            if op[0] == \"get\":\n",
    "                cache.get(op[1])\n",
    "            elif op[0] == \"put\":\n",
    "                cache.put(op[1], op[2])\n",
    "            end_time = time.time()\n",
    "            amortized_cost.append(end_time - start_time)\n",
    "        \n",
    "        avg_amortized_cost = sum(amortized_cost) / len(amortized_cost)\n",
    "        total_time_amortized += avg_amortized_cost\n",
    "    \n",
    "    print(f\"Caso promedio (tiempo total promedio): {total_time_average / num_runs:.6f} segundos\")\n",
    "    print(f\"Costo amortizado, promedio por operación: {total_time_amortized / num_runs:.8f} segundos\")\n",
    "\n",
    "#Prueba con valores grandes\n",
    "num_operations = 100000  # Número de operaciones (accesos y escrituras)\n",
    "cache_capacity = 1000  # Tamaño máximo de la caché LRU\n",
    "num_runs = 5  # Número de repeticiones para el caso promedio\n",
    "amortized_vs_average_test(num_operations, cache_capacity, num_runs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26683385-e859-47ae-8cc5-e18e4d1de841",
   "metadata": {},
   "source": [
    "**Caso promedio**:\n",
    "- El tiempo promedio es el resultado de medir múltiples ejecuciones de operaciones, sin considerar cuándo ocurren las operaciones costosas (como eliminaciones al alcanzar la capacidad).\n",
    "\n",
    "**Costo amortizado**:\n",
    "- El análisis amortizado distribuye el costo de operaciones costosas (como eliminar el elemento menos usado) entre las operaciones frecuentes (get, put). Aunque algunas operaciones son costosas, el costo promedio por operación sigue siendo muy bajo, cercano a $O(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe805c-1897-4ca9-84f9-e7a274ed74a5",
   "metadata": {},
   "source": [
    "#### **Ejemplos generales**\n",
    "\n",
    "##### **Ejemplo 1**\n",
    "\n",
    "¿Cuál es el tiempo de ejecución del siguiente código?\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    i = 1\n",
    "    s = 1\n",
    "    while s < n:\n",
    "        i = i + 1\n",
    "        s = s + i\n",
    "        print(\"*\")\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**: La variable `s` se incrementa de manera que en la k-ésima iteración es la suma de los **primeros k enteros**. Si $k$ es el número de iteraciones, el bucle termina cuando\n",
    "\n",
    "$$\n",
    "1 + 2 + 3 + \\dots + k \\ge n \\quad \\Rightarrow \\quad \\frac{k(k+1)}{2} \\approx n,\n",
    "$$\n",
    "\n",
    "por lo cual $(k = O(\\sqrt{n})$. De ahí que la complejidad sea $O(\\sqrt{n})$.\n",
    "\n",
    "##### **Ejemplo 2**\n",
    "\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    i = 1\n",
    "    count = 0\n",
    "    while i*i < n:\n",
    "        count = count + 1\n",
    "        i = i + 1\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**: Se repite el bucle mientras $i^2 < n$. Esto implica $i < \\sqrt{n}$. Por lo tanto, la complejidad es $O(\\sqrt{n})$.\n",
    "\n",
    "##### **Ejemplo 3**\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    for i in range(n/2, n):\n",
    "        j = 1\n",
    "        while j + n/2 <= n:\n",
    "            k = 1\n",
    "            while k <= n:\n",
    "                count = count + 1\n",
    "                k = k * 2\n",
    "            j = j + 1\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**:\n",
    "\n",
    "- `for i in range(n/2, n)`: se itera aproximadamente $n/2$ veces.  \n",
    "- `while j + n//2 <= n`: se itera otras $n/2$ veces.  \n",
    "- `while k <= n`: se itera $\\log n$ veces (porque `k` se duplica cada vez).  \n",
    "\n",
    "Multiplicando: $\\tfrac{n}{2} \\times \\tfrac{n}{2} \\times \\log n = O(n^2 \\log n)$.\n",
    "\n",
    "##### **Ejemplo 4**\n",
    "\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    for i in range(n/2, n):\n",
    "        j = 1\n",
    "        while j + n/2 <= n:\n",
    "            k = 1\n",
    "            while k <= n:\n",
    "                count = count + 1\n",
    "                k = k * 2\n",
    "            j = j * 2\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**:\n",
    "\n",
    "- Bucle externo: $(n/2$ veces.  \n",
    "- Bucle medio: ahora es $j = j * 2$, así que se ejecuta $\\log n$ veces.  \n",
    "- Bucle interno: $\\log n$ veces también.  \n",
    "\n",
    "El total es: $\\tfrac{n}{2} \\times \\log n \\times \\log n = O(n \\log^2 n)$.\n",
    "\n",
    "##### **Ejemplo 5**\n",
    "\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    for i in range(n/2, n):\n",
    "        j = 1\n",
    "        while j + n/2 <= n:\n",
    "            break\n",
    "            j = j * 2\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**:\n",
    "\n",
    "- Bucle externo: se ejecuta $n/2$ veces.  \n",
    "- Bucle interno: **tiene un `break` inmediato**, así que apenas se ejecuta una vez por cada iteración del bucle externo.  \n",
    "\n",
    "La complejidad es $O(n)$.\n",
    "\n",
    "##### **Ejemplo 6**\n",
    "\n",
    "Analiza el tiempo de ejecución del siguiente programa:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    if n <= 0:\n",
    "        return\n",
    "    for i in range(0, n):\n",
    "        j = 1\n",
    "        while j < n:\n",
    "            j = j + i\n",
    "            count = count + 1\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "##### Comentarios\n",
    "\n",
    "- El bucle externo: se ejecuta $n$ veces.  \n",
    "- El bucle interno: la variable `j` se incrementa de `j = j + i`.  \n",
    "  - Si $i = 0$, el bucle interno se vuelve infinito, **pero** con `i=0` no se incrementa `j`, así que habría que ver si sale del while. (Si es un caso particular, quizá el programa no está bien definido para $i=0$).  \n",
    "  - Si $i>0$, la cantidad de iteraciones internas es $\\approx n / i$.  \n",
    "\n",
    "Asumiendo que el código real tiene un manejo diferente de $i=0$ o que se salta ese caso, la **suma** de iteraciones ~ $\\sum_{i=1}^{n-1} (n/i)$. Esa sumatoria es $n\\cdot\\sum_{i=1}^{n} 1/i = n \\log n$.  \n",
    "\n",
    "Por tanto, el tiempo de ejecución es $O(n \\log n)$.\n",
    "\n",
    "*(Si el caso $i=0$ produce un bucle infinito, habría un error; a veces se asume $i$ inicia en 1).*\n",
    "\n",
    "##### **Ejemplo 7**\n",
    "\n",
    "¿Cuál es la complejidad de $\\sum_{i=1}^{n} \\log i$?\n",
    "\n",
    "**Solución**  \n",
    "Usando la propiedad logarítmica:  \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\log i = \\log\\Bigl(\\prod_{i=1}^{n} i\\Bigr) = \\log(n!) \\approx n \\log n.\n",
    "$$  \n",
    "\n",
    "Por lo tanto, $\\sum_{i=1}^{n} \\log i = O(n \\log n)$.\n",
    "\n",
    "##### **Ejemplo 8**\n",
    "Analiza el tiempo de ejecución del programa:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    for i in range(1, n):\n",
    "        j = 1\n",
    "        while j <= n:\n",
    "            j = j * 2\n",
    "        print(\"*\")\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**  \n",
    "- El bucle externo (`for i in range(1, n)`) se ejecuta $n$ veces.  \n",
    "- El bucle interno (`while j <= n: j = j * 2`) se ejecuta $\\log n$ veces (ver regla para bucles logarítmicos).  \n",
    "- Complejidad total: $O(n \\log n)$.\n",
    "\n",
    "\n",
    "##### **Ejemplo 9**\n",
    "Dado el siguiente código:\n",
    "\n",
    "```python\n",
    "import math\n",
    "count = 0\n",
    "\n",
    "def Logarithms(n):\n",
    "    global count\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        j = n\n",
    "        while j > 0:\n",
    "            j = j // 2\n",
    "            count = count + 1\n",
    "        i = i * 2\n",
    "    return count\n",
    "\n",
    "print(Logarithms(10))\n",
    "```\n",
    "\n",
    "**Solución**  \n",
    "- El bucle externo (`while i <= n: i = i * 2`) se ejecuta $\\log n$ veces.  \n",
    "- Dentro, el bucle `while j > 0: j = j//2` se ejecuta $\\log n$ veces.  \n",
    "- Multiplicando: $\\log n \\times \\log n = (\\log n)^2$.  \n",
    "Por lo tanto, la complejidad es $O\\bigl((\\log n)^2\\bigr)$, a veces se escribe $O(\\log^2 n)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959c57d-9c1a-4d19-bc64-d9c96c403ea8",
   "metadata": {},
   "source": [
    "#### Ejercicios\n",
    "\n",
    "##### **Ejercicio 1**\n",
    "\n",
    "El siguiente es un fragmento de código de un algoritmo de ordenamiento por inserción en Python:\n",
    "\n",
    "```python\n",
    "def insertion_sort(arr):\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        j = i - 1\n",
    "        while j >=0 and key < arr[j]:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad asintótica en el peor caso de `insertion_sort`.\n",
    "2. Determina la complejidad asintótica en el mejor caso de `insertion_sort`.\n",
    "3. Explica por qué la complejidad en el caso promedio de `insertion_sort` es $\\Theta(n^2)$.\n",
    "\n",
    "\n",
    "##### **Ejercicio 2**\n",
    "\n",
    "Considera dos algoritmos, **Algoritmo A** y **Algoritmo B**, con las siguientes complejidades en el peor caso:\n",
    "\n",
    "- **Algoritmo A:** $T_A(n) = 3n^3 + 2n^2 + 5n + 7$\n",
    "- **Algoritmo B:** $T_B(n) = 4n \\log n + 10n + 20$\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina las notaciones big-O, omega y theta para ambos algoritmos.\n",
    "2. Para valores grandes de $n$, cuál de los dos algoritmos será más eficiente y por qué.\n",
    "3. Si se ejecutan ambos algoritmos con $n = 1000$, cuál podría ser una observación práctica sobre su rendimiento relativo.\n",
    "\n",
    "\n",
    "\n",
    "##### **Ejercicio 3**\n",
    "\n",
    "Considera la siguiente función recursiva en Python que calcula la suma de los primeros $n$ números enteros:\n",
    "\n",
    "```python\n",
    "def recursive_sum(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return n + recursive_sum(n - 1)\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Plantea la relación de recurrencia para $T(n)$, donde $T(n)$ es el tiempo de ejecución de `recursive_sum(n)`.\n",
    "2. Resuelve la relación de recurrencia utilizando el método maestro o cualquier otro método apropiado para determinar la complejidad asintótica de la función.\n",
    "\n",
    "\n",
    "##### **Ejercicio 4**\n",
    "\n",
    "Supón que tienes una estructura de datos tipo pila (`stack`) que soporta operaciones de `push` y `pop`. Además, la pila tiene una operación adicional `double_push` que duplica el elemento superior de la pila.\n",
    "\n",
    "**Operaciones:**\n",
    "\n",
    "- `push(x)`: Agrega el elemento $x$ al tope de la pila. Tiempo de ejecución $O(1)$.\n",
    "- `pop()`: Elimina y devuelve el elemento en el tope de la pila. Tiempo de ejecución $O(1)$.\n",
    "- `double_push()`: Duplica el elemento en el tope de la pila. Es decir, si el tope es $x$, después de la operación el tope será $x$ y se agrega otro $x$. Tiempo de ejecución $O(1)$.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Realiza un análisis amortizado para determinar la complejidad promedio de una secuencia de $m$ operaciones en esta pila, considerando que `double_push` puede ser llamada en cualquier momento.\n",
    "2. Explica si la operación `double_push` afecta el análisis amortizado de la estructura de datos y por qué.\n",
    "\n",
    "\n",
    "##### **Ejercicio 5**\n",
    "\n",
    "\n",
    "Considera un árbol binario de búsqueda ([BST](https://en.wikipedia.org/wiki/Binary_search_tree)) implementado de manera que cada operación de inserción y búsqueda tiene una complejidad asintótica determinada por la altura del árbol.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad en el peor caso para las operaciones de inserción y búsqueda en un BST.\n",
    "2. Si el árbol está balanceado, cómo cambia la complejidad de estas operaciones?.\n",
    "3. Relaciona las notaciones big-O, omega y theta con respecto a la altura del árbol en ambos escenarios (balanceado y no balanceado).\n",
    "\n",
    "\n",
    "##### **Ejercicio 6**\n",
    "\n",
    "Considera la siguiente función en Python:\n",
    "\n",
    "```python\n",
    "def complex_function(n):\n",
    "    count = 0\n",
    "    for i in range(1, n):\n",
    "        j = 1\n",
    "        while j < n:\n",
    "            k = 1\n",
    "            while k < n:\n",
    "                count += 1\n",
    "                k *= 2\n",
    "            j += 1\n",
    "    return count\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad asintótica de `complex_function(n)` utilizando las guías para el análisis asintótico.\n",
    "2. Explica detalladamente cómo llegas a la conclusión sobre la complejidad, identificando las tasas de crecimiento de cada bucle.\n",
    "\n",
    "##### **Ejercicio 7**\n",
    "\n",
    "Considera el siguiente algoritmo de búsqueda que combina búsqueda lineal y binaria:\n",
    "\n",
    "```python\n",
    "def mixed_search(arr, target):\n",
    "    n = len(arr)\n",
    "    for i in range(0, n//2):\n",
    "        if arr[i] == target:\n",
    "            return i\n",
    "    # Si no se encuentra en la primera mitad, realizar búsqueda binaria en la segunda mitad\n",
    "    left = n//2\n",
    "    right = n - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad en el peor caso de `mixed_search`.\n",
    "2. Explica cómo la combinación de búsqueda lineal y binaria afecta la complejidad total del algoritmo.\n",
    "3. Determina si existe una notación asintótica que capture exactamente la complejidad de este algoritmo y justifica tu respuesta.\n",
    "\n",
    "\n",
    "##### **Ejercicio 8**\n",
    "\n",
    "Considera la siguiente función que combina un bucle condicional con una llamada recursiva:\n",
    "\n",
    "```python\n",
    "def conditional_recursive(n):\n",
    "    count = 0\n",
    "    for i in range(1, n):\n",
    "        if i % 2 == 0:\n",
    "            count += conditional_recursive(i)\n",
    "        else:\n",
    "            count += 1\n",
    "    return count\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Plantea la relación de recurrencia para $T(n)$, donde $T(n)$ es el tiempo de ejecución de `conditional_recursive(n)`.\n",
    "2. Resuelve la relación de recurrencia para determinar la complejidad asintótica de la función.\n",
    "3. Discute cómo la condición $i \\% 2 == 0$ influye en el análisis de la complejidad.\n",
    "\n",
    "\n",
    "\n",
    "##### **Ejercicio 9**\n",
    "\n",
    "Diseña un ADT llamado `ConjuntoAcotado`. Este ADT debe almacenar números enteros en un rango definido `a`, `b` y debe permitir al menos las siguientes operaciones:  \n",
    "     1. `insertar(x)`: Inserta el elemento `x` si está dentro del rango `a`, `b`.  \n",
    "     2. `eliminar(x)`: Elimina el elemento `x`.  \n",
    "     3. `contiene(x)`: Verifica si el elemento `x` está en el conjunto.  \n",
    "     4. `union(otroConjunto)`: Devuelve un nuevo `ConjuntoAcotado` que contiene los elementos de ambos conjuntos dentro del rango permitido.  \n",
    "     5. `interseccion(otroConjunto)`: Devuelve un nuevo `ConjuntoAcotado` con la intersección de elementos.  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Proponer **dos** implementaciones distintas (por ejemplo, utilizando un **arreglo booleano** versus un **árbol balanceado** o una **tabla hash**).  \n",
    "     b) Analizar teóricamente la complejidad de cada operación para ambas implementaciones en **peor**, **mejor** y, si es relevante, **caso promedio**.  \n",
    "     c) Comparar las dos implementaciones en términos de uso de memoria y facilidad de implementación.\n",
    "     d) Justifica formalmente por qué, por ejemplo, `insertar(x)` podría ser $O(1)$ promedio en una tabla hash y $O(\\log n)$ en un árbol balanceado, etc.\n",
    "\n",
    "##### **Ejercicio 10**\n",
    "\n",
    "Se cuenta con una gran base de datos (por ejemplo, de ~1 millón de registros) en la que cada registro contiene un `id` numérico (único) y varios campos adicionales. Se requiere **buscar** un registro dado su `id`.  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Diseñar **tres** estrategias distintas para abordar la búsqueda:  \n",
    "        - **Búsqueda secuencial** en un arreglo desordenado.  \n",
    "        - **Búsqueda binaria** en un arreglo ordenado.  \n",
    "        - **Búsqueda** usando una **tabla hash**.  \n",
    "     b) Explicar la complejidad en **peor** y **mejor** caso para cada enfoque.  \n",
    "     c) Considerar qué ocurre si la tabla hash tiene colisiones (usa diferentes técnicas de resolución de colisiones: encadenamiento, direccionamiento abierto, etc.).  \n",
    "     d) Realiza un **modelo probabilístico** que estime el tiempo promedio de las búsquedas bajo ciertas distribuciones de `id`s y colisiones, y evalúa la eficiencia de cada estrategia según dicho modelo.\n",
    "\n",
    "##### **Ejercicio 11**\n",
    "\n",
    "Considera los siguientes algoritmos de ordenamiento: **inserción**, **selección**, **merge sort**, **quick sort**, **heap sort** y **radix sort**.  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Elabora **pseudocódigo** para cada uno, destacando los puntos de decisión clave (comparaciones e intercambios).  \n",
    "     b) Analiza su **complejidad temporal** en términos de $n$ en los casos **mejor**, **peor** y **promedio** (si aplica).  \n",
    "     c) Propón situaciones (tipo de datos o patrones de entrada) donde cada algoritmo destaque o se vea penalizado.  \n",
    "     d) Discute la posibilidad de que el uso de ciertas **estructuras de datos** (como colas de prioridad) pueda optimizar o perjudicar uno de esos algoritmos de ordenamiento. Analiza la **complejidad espacial** y no solo la temporal.\n",
    "\n",
    "\n",
    "#####  **Ejercicio 12**\n",
    "\n",
    "Tienes un grafo dirigido con pesos no negativos. Se requiere calcular la distancia mínima desde un vértice origen $s$ a todos los demás.  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Implementar dos algoritmos distintos (por ejemplo, **Dijkstra** y **Bellman-Ford**).  \n",
    "     b) Justificar la complejidad de ambos en función del número de vértices ($V$) y el número de aristas ($E$).  \n",
    "     c) Discute bajo qué circunstancias uno es más eficiente que el otro y por qué.  \n",
    "     d) Agrega **condiciones especiales** (por ejemplo, el grafo es denso, o se permite algún número reducido de aristas negativas) y discute cómo **se afectan** las complejidades y la factibilidad de los algoritmos.\n",
    "\n",
    "#####  **Ejercicio 13**\n",
    "\n",
    "Diseña un algoritmo que:  \n",
    "     1. Divide la entrada de tamaño $n$ en 4 subproblemas de tamaño $\\frac{n}{2}$.  \n",
    "     2. Cada subproblema genera **2 resultados** que deben combinarse en una etapa final, cuya complejidad es proporcional a $n$.  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Escribir la recurrencia que describe el tiempo de ejecución, por ejemplo:  \n",
    "        $$\n",
    "          T(n) = 4 \\cdot T\\left(\\frac{n}{2}\\right) + 2\\cdot\\left(\\text{algo}\\right) + O(n).\n",
    "        $$  \n",
    "       (Analizar con cuidado el término correspondiente a la combinación de los 8 resultados.)  \n",
    "     b) Resolver la recurrencia aplicando **el método maestro** (o, si no aplica directamente, usando expansión recursiva o árbol de recurrencia).  \n",
    "     c) Determinar el orden de crecimiento resultante (por ejemplo, $n^2$, $n^{\\log_2 4}$, etc.).  \n",
    "     d) Propón variaciones del algoritmo (por ejemplo, que en vez de 4 subproblemas sean $k$ subproblemas de tamaño $\\alpha \\cdot n$) y discute cómo cambia la complejidad en función de $k$ y $\\alpha$.  \n",
    "\n",
    "##### **Ejercicio 14**\n",
    "\n",
    "Una **skip list** es una estructura probabilística que permite operaciones como búsqueda, inserción y eliminación en promedio $O(\\log n)$. Sin embargo, su **peor caso** puede ser $O(n)$.  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Explica la **estructura** y el **mecanismo** de niveles en una skip list.  \n",
    "     b) Demuestra por qué las operaciones de búsqueda tienen **complejidad promedio** $O(\\log n)$, discutiendo la probabilidad de que cada nivel reduzca efectivamente la mitad de los elementos.  \n",
    "     c) Realiza un **análisis formal** de la **altura** esperada de una skip list con $n$ elementos.  \n",
    "     d) Compara la skip list con un **árbol rojo-negro** (Red-Black Tree) o **AVL** en términos de:  \n",
    "        - Complejidad en peor y mejor caso.  \n",
    "        - Complejidad promedio.  \n",
    "        - Facilidad de implementación y **costos ocultos** (rotaciones, probabilidades, etc.).\n",
    "\n",
    "##### **Ejercicio 15**\n",
    "\n",
    "Considera un problema **NP-hard**, como el **problema del viajante** (TSP). Diseña un **algoritmo aproximado** o un heurístico (por ejemplo, el **algoritmo del vecino más cercano** o **inserción**).  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Explica el funcionamiento de la heurística elegida y su **complejidad temporal** en función del número de ciudades.  \n",
    "     b) Analiza la **calidad** de la solución: ¿cuán cerca está del óptimo en promedio o en el peor caso?  \n",
    "     c) Discute si se puede dar una **cota de aproximación** garantizada (por ejemplo, 2 veces el óptimo) y justifica por qué.  \n",
    "     d) Opcionalmente, contrasta con un método exacto (tal como **búsqueda en amplitud** con poda o **branch & bound**) y analiza **cuándo** uno es factible y cuándo no, basándote en la complejidad.\n",
    "\n",
    "##### **Ejercicio 16**\n",
    "Elabora un ejercicio donde se utilice una de estas estructuras avanzadas. Por ejemplo:  \n",
    "     - **Union-Find (Disjoint Sets)** para manejar **consulta de componentes** en un grafo dinámico.  \n",
    "     - **Segment Tree** o **Fenwick (binary indexed) Tree** para contestar **sumas parciales** o **rangos** dinámicos en un arreglo de datos.  \n",
    "\n",
    "   - **Tareas:**  \n",
    "     a) Describir la operación principal (por ejemplo, `union` y `find` en disjoint sets; `update` y `query` en segment trees).  \n",
    "     b) Analizar la complejidad en función del número de **operaciones** (por ejemplo, $m$) y el tamaño **máximo** de la estructura (por ejemplo, $n$).  \n",
    "     c) Mostrar cómo la **técnica de compresión de caminos** y la **unión por rango** en Union-Find logran casi $O(1)$ amortizado. O cómo las **lazy updates** en segment trees mejoran la eficiencia de actualizaciones en intervalos.  \n",
    "     d) Discutir posibles aplicaciones reales (por ejemplo, consultas de conectividad en redes, sumas acumuladas en análisis de grandes datos, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "##### **Recomendaciones para las resoluciones**\n",
    "\n",
    "- En todos los ejercicios, se sugiere acompañar el **análisis teórico** (p. ej. mediante el método maestro, árboles de recurrencia, probabilidades, etc.) con **pruebas empíricas** sobre datos de distintos tamaños.  \n",
    "- Desarrollar un **informe** que incluya tanto la parte **teórica** (justificaciones de complejidad) como la **práctica** (implementaciones, experimentos y discusión de resultados).  \n",
    "- Utilizar técnicas de **profiling** para medir el tiempo real de cada operación/algoritmo y confrontarlo con la **estimación asintótica**.  \n",
    "- Explorar las **diferencias** entre el rendimiento en **teoría** (complejidad asintótica) y la **realidad práctica** (detalles de implementación, caché, constantes ocultas, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f93d3-c21e-49f6-a618-dfed4563f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
