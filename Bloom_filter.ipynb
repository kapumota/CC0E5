{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5490f61b-86e3-44e5-95f9-64a9302caab7",
   "metadata": {},
   "source": [
    "### **Algoritmos aleatorizados**\n",
    "\n",
    "Un **algoritmo aleatorizado** (randomized algorithm) es un procedimiento computacional que introduce aleatoriedad para influir en su comportamiento. Estos algoritmos no son deterministas: pueden producir resultados distintos con las mismas entradas, dependiendo de las decisiones tomadas mediante variables aleatorias internas.\n",
    "\n",
    "#### ¿Por qué usar aleatoriedad?\n",
    "\n",
    "1. **Eficiencia**: Algunos problemas tienen soluciones exactas costosas, pero versiones aleatorizadas ofrecen respuestas \"suficientemente buenas\" más rápidamente.\n",
    "2. **Simplicidad**: La introducción de aleatoriedad permite estructuras algorítmicas más simples para problemas complejos (como el balanceo de árboles en promedio).\n",
    "3. **Evitar peores casos sistemáticos**: Por ejemplo, el algoritmo de ordenamiento *QuickSort* puede tener peor caso $O(n^2)$ con ciertas entradas, pero si se elige el pivote aleatoriamente, se evita este comportamiento de forma probabilística.\n",
    "\n",
    "#### Clasificación\n",
    "\n",
    "1. **Las Vegas**: Garantizan resultados correctos, pero el tiempo de ejecución es aleatorio.\n",
    "   - Ejemplo: Algoritmo de selección aleatoria para encontrar la mediana.\n",
    "2. **Monte Carlo**: Garantizan tiempos de ejecución limitados, pero pueden retornar resultados incorrectos con baja probabilidad.\n",
    "   - Ejemplo: Algoritmo de Rabin-Miller para primalidad.\n",
    "\n",
    "Ambos tipos se utilizan extensamente en algoritmos distribuidos, estructuras probabilísticas, algoritmos de aproximación, hashing, y criptografía.\n",
    "\n",
    "#### Hashing aleatorizado\n",
    "\n",
    "En estructuras como el **Bloom filter**, el hashing aleatorizado cumple un papel esencial. Las funciones hash deben distribuir uniformemente los elementos, incluso en presencia de entradas sesgadas. El uso de una **semilla aleatoria** permite garantizar independencia entre funciones de hash o simularla mediante técnicas como el *double hashing*.\n",
    "\n",
    "En el código:\n",
    "\n",
    "```python\n",
    "h1 = murmurhash3_32(key, seed)\n",
    "h2 = fnv1_hash32(key)\n",
    "```\n",
    "\n",
    "La combinación:\n",
    "\n",
    "$$\n",
    "\\text{hash}_i(x) = h_1(x) + i \\cdot h_2(x) + i^2 \\bmod m\n",
    "$$\n",
    "\n",
    "...es una forma práctica de obtener múltiples funciones de hash independientes desde dos funciones base, minimizando colisiones y distribuyendo uniformemente los bits activados en el filtro.\n",
    "\n",
    "Esto garantiza una distribución lo más cercana posible al comportamiento de funciones verdaderamente independientes, crucial para la precisión del filtro.\n",
    "\n",
    "### Bloom filters\n",
    "\n",
    "Un **Bloom filter**, propuesto por Burton Howard Bloom en 1970, es una estructura de datos probabilística diseñada para resolver un problema clásico:\n",
    "\n",
    "> ¿Existe una forma eficiente de verificar si un elemento pertenece a un conjunto muy grande, sin almacenar todos los elementos?\n",
    "\n",
    "#### Principio de funcionamiento\n",
    "\n",
    "- Se define un vector de bits de tamaño $m$.\n",
    "- Se escogen $k$ funciones hash.\n",
    "- Para cada elemento insertado, se computan sus $k$ hashes y se marcan los bits correspondientes.\n",
    "\n",
    "**Consulta**: Para verificar si un elemento está presente, se comprueba si los $k$ bits están en 1. Si alguno está en 0, se garantiza que el elemento no fue insertado. Si todos están en 1, puede tratarse de un falso positivo.\n",
    "\n",
    "#### Propiedades clave\n",
    "\n",
    "- **No hay falsos negativos**.\n",
    "- **Hay falsos positivos**, cuya probabilidad se puede controlar ajustando parámetros.\n",
    "- **Muy eficiente en memoria**, mucho más que mantener una tabla hash.\n",
    "- **Operaciones básicas en $ O(k) $**, con $ k $ pequeño.\n",
    "\n",
    "\n",
    "#### Formulación matemática\n",
    "\n",
    "Para un filtro con:\n",
    "- $ m $: número de bits,\n",
    "- $ n $: número esperado de elementos insertados,\n",
    "- $ k $: número de funciones hash,\n",
    "\n",
    "La probabilidad de que un bit permanezca 0 después de insertar $ n $ elementos es:\n",
    "\n",
    "$$\n",
    "p_0 = \\left(1 - \\frac{1}{m}\\right)^{kn} \\approx e^{-kn/m}\n",
    "$$\n",
    "\n",
    "La probabilidad de que un bit esté en 1:\n",
    "\n",
    "$$\n",
    "p_1 = 1 - e^{-kn/m}\n",
    "$$\n",
    "\n",
    "La probabilidad de un falso positivo (todos los $ k $ bits estén en 1 para un elemento no insertado):\n",
    "\n",
    "$$\n",
    "P_{fp} = (1 - e^{-kn/m})^k\n",
    "$$\n",
    "\n",
    "Esta probabilidad disminuye si aumentamos $ m $ o usamos el número óptimo de hash functions $ k \\approx \\frac{m}{n} \\ln 2 $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d0f9d0-6eac-4951-85bc-044f15b43df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Función de hash FNV-1 de 32 bits (retorna un entero sin signo)\n",
    "def fnv1_hash32(key: str) -> int:\n",
    "    fnv_prime = 0x01000193  # Constante primo FNV\n",
    "    hash_ = 0x811c9dc5      # Valor inicial offset basis\n",
    "    for c in key:\n",
    "        hash_ = (hash_ * fnv_prime) & 0xFFFFFFFF  # Multiplica por el primo y limita a 32 bits\n",
    "        hash_ ^= ord(c)                            # XOR con el valor ASCII del carácter\n",
    "    return hash_\n",
    "\n",
    "# Implementación de MurmurHash3 x86 32 bits\n",
    "def murmurhash3_32(key: str, seed: int = 0) -> int:\n",
    "    data = key.encode('utf-8')\n",
    "    length = len(data)\n",
    "    nblocks = length // 4\n",
    "\n",
    "    h1 = seed & 0xFFFFFFFF\n",
    "    c1 = 0xcc9e2d51\n",
    "    c2 = 0x1b873593\n",
    "\n",
    "    # Procesamiento de bloques de 4 bytes\n",
    "    for block_start in range(0, nblocks * 4, 4):\n",
    "        # Combina 4 bytes en un entero de 32 bits\n",
    "        k1 = (data[block_start]\n",
    "              | (data[block_start+1] << 8)\n",
    "              | (data[block_start+2] << 16)\n",
    "              | (data[block_start+3] << 24))\n",
    "        k1 = (k1 * c1) & 0xFFFFFFFF\n",
    "        k1 = ((k1 << 15) | (k1 >> 17)) & 0xFFFFFFFF  # Rotación izquierda de 15 bits\n",
    "        k1 = (k1 * c2) & 0xFFFFFFFF\n",
    "\n",
    "        # Mezcla con el hash\n",
    "        h1 ^= k1\n",
    "        h1 = ((h1 << 13) | (h1 >> 19)) & 0xFFFFFFFF\n",
    "        h1 = (h1 * 5 + 0xe6546b64) & 0xFFFFFFFF\n",
    "\n",
    "    # Procesamiento de la cola (últimos bytes)\n",
    "    tail_index = nblocks * 4\n",
    "    tail_size = length & 3\n",
    "    k1 = 0\n",
    "    if tail_size == 3:\n",
    "        k1 ^= data[tail_index + 2] << 16\n",
    "    if tail_size >= 2:\n",
    "        k1 ^= data[tail_index + 1] << 8\n",
    "    if tail_size >= 1:\n",
    "        k1 ^= data[tail_index]\n",
    "        k1 = (k1 * c1) & 0xFFFFFFFF\n",
    "        k1 = ((k1 << 15) | (k1 >> 17)) & 0xFFFFFFFF\n",
    "        k1 = (k1 * c2) & 0xFFFFFFFF\n",
    "        h1 ^= k1\n",
    "\n",
    "    # Finalización (avalancha de bits)\n",
    "    h1 ^= length\n",
    "    h1 &= 0xFFFFFFFF\n",
    "    h1 ^= (h1 >> 16)\n",
    "    h1  = (h1 * 0x85ebca6b) & 0xFFFFFFFF\n",
    "    h1 ^= (h1 >> 13)\n",
    "    h1  = (h1 * 0xc2b2ae35) & 0xFFFFFFFF\n",
    "    h1 ^= (h1 >> 16)\n",
    "    return h1\n",
    "\n",
    "# Serializa valores de forma determinista (JSON ordenado)\n",
    "def consistent_stringify(value) -> str:\n",
    "    return json.dumps(value, sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "class BloomFilter:\n",
    "    \"\"\"\n",
    "    Implementación de un Bloom filter con FNV-1 y MurmurHash3 para hashing múltiple.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_size: int, max_tolerance: float = 0.01, seed: int = None):\n",
    "        # Validación de parámetros\n",
    "        if not isinstance(max_size, int) or max_size <= 0:\n",
    "            raise TypeError(f\"maxSize debe ser un entero positivo, recibido: {max_size}\")\n",
    "        try:\n",
    "            tol = float(max_tolerance)\n",
    "        except:\n",
    "            raise TypeError(f\"tolerance debe ser un número en (0,1), recibido: {max_tolerance}\")\n",
    "        if tol <= 0 or tol >= 1:\n",
    "            raise TypeError(f\"tolerance debe cumplir 0 < t < 1, recibido: {max_tolerance}\")\n",
    "        if seed is None:\n",
    "            seed = random.getrandbits(32)  # Semilla aleatoria si no se provee\n",
    "        if not isinstance(seed, int):\n",
    "            raise TypeError(f\"seed debe ser un entero, recibido: {seed}\")\n",
    "\n",
    "        self._max_size = max_size\n",
    "        self._seed = seed\n",
    "\n",
    "        ln2 = math.log(2)\n",
    "        # Número de bits: m = -n ln p / (ln 2)^2\n",
    "        self._num_bits = math.ceil(-max_size * math.log(tol) / (ln2**2))\n",
    "        # Número de hashes: k = (m/n) ln 2  =>  k = -ln p / ln 2\n",
    "        self._num_hashes = math.ceil(-math.log(tol) / ln2)\n",
    "\n",
    "        # Prevención de filtros excesivamente grandes\n",
    "        if self._num_bits > 1_000_000_000:\n",
    "            raise MemoryError(\"Demasiada memoria requerida para el Bloom filter\")\n",
    "\n",
    "        num_bytes = math.ceil(self._num_bits / 8)\n",
    "        self._bits = bytearray(num_bytes)  # Array de bytes para los bits\n",
    "        self._size = 0                     # Conteo de inserciones únicas\n",
    "\n",
    "    def _bit_coords(self, index: int):\n",
    "        \"\"\"Devuelve el índice de byte y el desplazamiento de bit para un índice global.\"\"\"\n",
    "        byte_idx = index // 8\n",
    "        bit_idx = index % 8\n",
    "        return byte_idx, bit_idx\n",
    "\n",
    "    def _read_bit(self, index: int) -> int:\n",
    "        \"\"\"Lee el valor de un bit (0 o 1).\"\"\"\n",
    "        b, i = self._bit_coords(index)\n",
    "        return (self._bits[b] >> i) & 1\n",
    "\n",
    "    def _write_bit(self, index: int) -> bool:\n",
    "        \"\"\"Establece un bit a 1. Devuelve True si cambió de estado.\"\"\"\n",
    "        b, i = self._bit_coords(index)\n",
    "        mask = 1 << i\n",
    "        old = self._bits[b]\n",
    "        self._bits[b] |= mask\n",
    "        return old != self._bits[b]\n",
    "\n",
    "    def _key_positions(self, key: str):\n",
    "        \"\"\"Genera las posiciones de bit para una clave usando hashing doble.\"\"\"\n",
    "        s = consistent_stringify(key)\n",
    "        h1 = murmurhash3_32(s, self._seed)\n",
    "        h2 = fnv1_hash32(s)\n",
    "        for i in range(self._num_hashes):\n",
    "            # Combinación lineal de los hashes (double hashing + cuadrática)\n",
    "            yield (h1 + i * h2 + i * i) % self._num_bits\n",
    "\n",
    "    def add(self, value) -> \"BloomFilter\":\n",
    "        \"\"\"Añade un valor al filtro. Incrementa _size si algún bit cambió.\"\"\"\n",
    "        key = consistent_stringify(value)\n",
    "        flipped = False\n",
    "        for pos in self._key_positions(key):\n",
    "            if self._write_bit(pos):\n",
    "                flipped = True\n",
    "        if flipped:\n",
    "            self._size += 1\n",
    "        return self\n",
    "\n",
    "    def contains(self, value) -> bool:\n",
    "        \"\"\"Comprueba si un valor podría estar en el filtro (puede haber falsos positivos).\"\"\"\n",
    "        key = consistent_stringify(value)\n",
    "        return all(self._read_bit(pos) for pos in self._key_positions(key))\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Número de valores únicos insertados (aproximado).\"\"\"\n",
    "        return self._size\n",
    "\n",
    "    def false_positive_probability(self) -> float:\n",
    "        \"\"\"Calcula la probabilidad teórica de falso positivo.\"\"\"\n",
    "        k, n, m = self._num_hashes, self._size, self._num_bits\n",
    "        return (1 - math.exp(-k * n / m))**k\n",
    "\n",
    "    def confidence(self) -> float:\n",
    "        \"\"\"Devuelve la confianza (1 - probabilidad de falso positivo).\"\"\"\n",
    "        return 1 - self.false_positive_probability()\n",
    "\n",
    "    @property\n",
    "    def max_remaining_capacity(self) -> int:\n",
    "        \"\"\"Capacidad restante antes de alcanzar max_size.\"\"\"\n",
    "        return max(0, self._max_size - self._size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c374e-bd74-4e30-b4e1-d7732ac4ce0f",
   "metadata": {},
   "source": [
    "### **Pruebas unitarias**\n",
    "\n",
    "Las **pruebas unitarias** permiten verificar que los componentes individuales de un programa (como clases o funciones) se comporten correctamente bajo distintos escenarios. En este caso, se usa el módulo `unittest` de Python para validar exhaustivamente la clase `BloomFilter`.\n",
    "\n",
    "Cada método dentro de `TestBloomFilter(unittest.TestCase)` representa una prueba. Se utilizan aserciones como `assertTrue`, `assertEqual`, `assertRaises`, `assertGreater` y `assertLess` para comprobar el comportamiento esperado.\n",
    "\n",
    "El código realiza lo siguiente:\n",
    "\n",
    "1. **Prueba de interfaz (`test_interface`)**: Verifica que `BloomFilter` tenga los métodos públicos esperados (`add`, `contains`, etc.) y atributos (`size`, `max_remaining_capacity`).\n",
    "\n",
    "2. **Validación de entradas inválidas (`test_invalid_max_size`, `test_invalid_tolerance`, `test_invalid_seed`)**: Se asegura de que el constructor rechace tipos incorrectos para `max_size`, `tolerance` y `seed`, lanzando `TypeError`.\n",
    "\n",
    "3. **Errores por uso excesivo de memoria (`test_allocation_error`)**: Prueba que se lance un `MemoryError` si se intenta crear un filtro con parámetros poco realistas.\n",
    "\n",
    "4. **Estado del filtro (`test_size_and_capacity`)**: Comprueba que `size` y `max_remaining_capacity` se actualicen correctamente, y que no aumente la cuenta al agregar duplicados.\n",
    "\n",
    "5. **Precisión del filtro (`test_false_positive_and_confidence`)**: Evalúa el comportamiento del filtro conforme se agregan elementos y cambia la probabilidad de falsos positivos.\n",
    "\n",
    "6. **Correctitud de `contains` (`test_contains_behavior`)**: Valida que un filtro vacío nunca contenga elementos, que se reconozcan los insertados, y que se produzcan falsos positivos solo con tolerancias altas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4f2ee-9f3a-46dd-b212-581b2a44bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestBloomFilter(unittest.TestCase):\n",
    "\n",
    "    def test_interface(self):\n",
    "        self.assertTrue(callable(BloomFilter))\n",
    "        bf = BloomFilter(3)\n",
    "        for method in ['contains', 'add', 'confidence', 'false_positive_probability']:\n",
    "            self.assertTrue(hasattr(bf, method))\n",
    "        for attr in ['size', 'max_remaining_capacity']:\n",
    "            self.assertTrue(hasattr(bf, attr))\n",
    "\n",
    "    def test_invalid_max_size(self):\n",
    "        for invalid in ([], 'h', {'4':4}, None):\n",
    "            with self.assertRaises(TypeError):\n",
    "                BloomFilter(invalid)\n",
    "\n",
    "    def test_invalid_tolerance(self):\n",
    "        for tol in ([], 'g', {'1':2}, 0, -1, 1, 1.001):\n",
    "            with self.assertRaises(TypeError):\n",
    "                BloomFilter(3, tol)\n",
    "\n",
    "    def test_invalid_seed(self):\n",
    "        for seed in ([], 'g', {'1':2}, 0.1, 1.1):\n",
    "            with self.assertRaises(TypeError):\n",
    "                BloomFilter(3, 0.1, seed)\n",
    "\n",
    "    def test_allocation_error(self):\n",
    "        with self.assertRaises(MemoryError):\n",
    "            BloomFilter(10**8, 1e-9)\n",
    "        with self.assertRaises(MemoryError):\n",
    "            BloomFilter(10**9, 1e-10)\n",
    "\n",
    "    def test_size_and_capacity(self):\n",
    "        maxS = 5\n",
    "        bf = BloomFilter(maxS)\n",
    "        self.assertEqual(bf.size, 0)\n",
    "        self.assertEqual(bf.max_remaining_capacity, maxS)\n",
    "        bf.add(12)\n",
    "        self.assertEqual(bf.size, 1)\n",
    "        bf.add(11); bf.add(13)\n",
    "        self.assertEqual(bf.size, 3)\n",
    "        self.assertEqual(bf.max_remaining_capacity, maxS - 3)\n",
    "        bf.add(13); bf.add(11)\n",
    "        self.assertEqual(bf.size, 3)\n",
    "        for i in range(1, maxS+2):\n",
    "            bf.add(i)\n",
    "        self.assertEqual(bf.max_remaining_capacity, 0)\n",
    "\n",
    "    def test_false_positive_and_confidence(self):\n",
    "        maxS, maxT = 10, 0.1\n",
    "        bf = BloomFilter(maxS, maxT)\n",
    "        self.assertEqual(bf.false_positive_probability(), 0)\n",
    "        bf.add('x')\n",
    "        self.assertGreater(bf.false_positive_probability(), 0)\n",
    "        while bf.size < maxS:\n",
    "            bf.add(random.randint(0, maxS*2))\n",
    "        self.assertGreater(bf.false_positive_probability(), maxT)\n",
    "        bf2 = BloomFilter(15, 0.01)\n",
    "        self.assertEqual(bf2.confidence(), 1)\n",
    "        bf2.add('y')\n",
    "        self.assertLess(bf2.confidence(), 1)\n",
    "\n",
    "    def test_contains_behavior(self):\n",
    "        maxS = 15\n",
    "        bf = BloomFilter(maxS)\n",
    "        self.assertTrue(all(not bf.contains(i) for i in range(maxS)))\n",
    "        bf_low = BloomFilter(maxS, 1e-20)\n",
    "        for i in range(maxS):\n",
    "            bf_low.add(i)\n",
    "        self.assertTrue(all(not bf_low.contains(maxS+i) for i in range(maxS*2)))\n",
    "        bf_high = BloomFilter(maxS, 1e-1)\n",
    "        for i in range(maxS):\n",
    "            bf_high.add(i)\n",
    "        self.assertTrue(any(bf_high.contains(maxS+i) for i in range(maxS*3)))\n",
    "        bf3 = BloomFilter(maxS)\n",
    "        for i in range(maxS):\n",
    "            bf3.add(i)\n",
    "        self.assertTrue(all(bf3.contains(i) for i in range(maxS)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False, verbosity=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca364c8-7b5b-47d4-b2e1-a54bc308231c",
   "metadata": {},
   "source": [
    "#### **Rendimiento y comportamiento interno de una estructura Bloom filter**\n",
    "\n",
    "Utilizamos  dos herramientas comunes en Python:\n",
    "\n",
    "- `%prun`: para **profiling puntual** de funciones individuales.\n",
    "- `%timeit`: para **benchmark estadístico** de bloques de código repetidos.\n",
    "\n",
    "\n",
    "Se inicializa un Bloom filter para hasta 5000 elementos con una tolerancia de falsos positivos del 1%. Luego se insertan 2000 valores para \"calentar\" el filtro y simular un uso realista.\n",
    "\n",
    "`%prun` es una *magic command* de IPython que utiliza `cProfile` para mostrar estadísticas detalladas del tiempo de ejecución de cada función durante una llamada.\n",
    "\n",
    "**Resultados**\n",
    "\n",
    "```\n",
    "Inserción de 2000 elementos:\n",
    "19.3 ms ± 270 μs\n",
    "\n",
    "Búsqueda de 2000 elementos existentes:\n",
    "19.8 ms ± 307 μs\n",
    "\n",
    "Búsqueda de 2000 elementos NO existentes:\n",
    "14.9 ms ± 281 μs\n",
    "```\n",
    "\n",
    "\n",
    "**Análisis:**\n",
    "\n",
    "| Operación | Tiempo Total (ms) | Tiempo Medio por elemento (μs) | Comentario |\n",
    "|----------|------------------|-----------------------------|------------|\n",
    "| `add(i)` | 19.3 ms           | ~9.65 μs                   | Muy eficiente |\n",
    "| `contains(i)` en insertados | 19.8 ms           | ~9.9 μs                    | Ligeramente más costoso que insertar |\n",
    "| `contains(i+10000)` no insertados | 14.9 ms | ~7.45 μs            | Más rápido: se detectan ceros antes |\n",
    "\n",
    "- La búsqueda de **elementos no insertados** es más rápida porque en promedio encuentra bits en 0 más temprano, evitando completar las `k` verificaciones.\n",
    "- Todos los tiempos están por debajo de los 10 microsegundos por operación, lo cual valida que Bloom Filter es **óptimo para pruebas de pertenencia en masa**.\n",
    "- Las funciones `add` y `contains` realizan operaciones **muy eficientes**, con tiempos constantes.\n",
    "- El perfil muestra que las operaciones clave (`hashing`, `bit setting`, `bit checking`) son rápidas y con mínimo *overhead* de serialización (`json.dumps`).\n",
    "- El benchmark muestra tiempos competitivos incluso para grandes cantidades de operaciones, destacando la utilidad de Bloom filters en sistemas de alto rendimiento como bases de datos, motores de búsqueda o sistemas distribuidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffa824-c310-4337-aadd-a9847b8f46ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepara un filtro y caliéntalo con unas inserciones\n",
    "bf = BloomFilter(5000, 0.01, seed=42)\n",
    "for i in range(2000):\n",
    "    bf.add(i)\n",
    "\n",
    "# Perfilado de operaciones puntuales (método add y contains)\n",
    "print(\"Perfilado con %prun (top 10)\")\n",
    "print(\"bf.add(1234):\")\n",
    "%prun -l 10 bf.add(1234)\n",
    "\n",
    "print(\"\\nbf.contains(1234):\")\n",
    "%prun -l 10 bf.contains(1234)\n",
    "\n",
    "# Benchmark de rendimiento con %timeit\n",
    "print(\"\\nBenchmark con %timeit \")\n",
    "print(\"Inserción de 2000 elementos:\")\n",
    "%timeit -n5 -r3 [bf.add(i) for i in range(2000)]\n",
    "\n",
    "print(\"\\nBúsqueda de 2000 elementos existentes:\")\n",
    "%timeit -n5 -r3 [bf.contains(i) for i in range(2000)]\n",
    "\n",
    "print(\"\\nBúsqueda de 2000 elementos NO existentes:\")\n",
    "%timeit -n5 -r3 [bf.contains(i+10000) for i in range(2000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780fc0e-07a8-42d4-a1a0-eec7c8c2060b",
   "metadata": {},
   "source": [
    "### **Estadísticas y gráficos adicionales**\n",
    "\n",
    "Este código realiza un análisis estadístico y visual del rendimiento de tres operaciones en un **Bloom Filter**:\n",
    "\n",
    "1. `bf.add(1234)`\n",
    "2. `bf.contains(1234)` (elemento insertado)\n",
    "3. `bf.contains(10000)` (elemento no insertado)\n",
    "\n",
    "Se ejecutan **30 veces** cada una con `timeit.repeat()` y se almacenan los tiempos en segundos. Luego, se calcula la **media**, **mediana** y **desviación estándar** usando el módulo `statistics`.\n",
    "\n",
    "Los resultados se organizan en un `DataFrame` de **pandas**, que se muestra como tabla. Y produce los siguiente gráficos:\n",
    "\n",
    "- **Gráfico de barras**: compara los **tiempos medios** por operación. Ayuda a identificar cuál es más costosa.\n",
    "- **Histograma**: muestra la **distribución de los tiempos** para `bf.add()`, revelando la variabilidad o estabilidad del rendimiento.\n",
    "\n",
    "Este análisis permite observar que:\n",
    "\n",
    "- `contains(10000)` suele ser más rápido (detecta ausencia temprana).\n",
    "- `add` y `contains` para elementos existentes tienen mayor consistencia pero tiempos similares.\n",
    "- El uso de estadísticas robustas como mediana y desviación da contexto sobre la **estabilidad temporal** de cada operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e77ded-87f6-4bb5-a699-0c30feb87ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepara de nuevo el filtro (o reutiliza el 'bf' de antes si sigue en memoria)\n",
    "bf = BloomFilter(5000, 0.01, seed=42)\n",
    "for i in range(2000):\n",
    "    bf.add(i)\n",
    "\n",
    "# Número de muestras para cada operación\n",
    "repeats = 30\n",
    "\n",
    "# Recopila los tiempos como listas de floats (segundos)\n",
    "times_add = timeit.repeat(lambda: bf.add(1234), repeat=repeats, number=1)\n",
    "times_contains_exist = timeit.repeat(lambda: bf.contains(1234), repeat=repeats, number=1)\n",
    "times_contains_not = timeit.repeat(lambda: bf.contains(10000), repeat=repeats, number=1)\n",
    "\n",
    "# Calcula media, mediana y desviación típica\n",
    "stats = {\n",
    "    'operación': ['add', 'contains_exist', 'contains_not'],\n",
    "    'media (s)': [\n",
    "        statistics.mean(times_add),\n",
    "        statistics.mean(times_contains_exist),\n",
    "        statistics.mean(times_contains_not)\n",
    "    ],\n",
    "    'mediana (s)': [\n",
    "        statistics.median(times_add),\n",
    "        statistics.median(times_contains_exist),\n",
    "        statistics.median(times_contains_not)\n",
    "    ],\n",
    "    'desviación (s)': [\n",
    "        statistics.stdev(times_add),\n",
    "        statistics.stdev(times_contains_exist),\n",
    "        statistics.stdev(times_contains_not)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Muestra la tabla de estadísticas\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(stats)\n",
    "display(df)\n",
    "\n",
    "# — Gráfico 1: Barras del tiempo medio por operación —\n",
    "plt.figure()\n",
    "plt.bar(df['operación'], df['media (s)'])\n",
    "plt.ylabel('Tiempo medio (s)')\n",
    "plt.title('Tiempo medio por operación')\n",
    "plt.show()\n",
    "\n",
    "# — Gráfico 2: Histograma de distribución de bf.add() —\n",
    "plt.figure()\n",
    "plt.hist(times_add, bins=10)\n",
    "plt.xlabel('Tiempo de ejecución (s)')\n",
    "plt.title('Distribución de tiempos de bf.add()')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aebe05-5a6c-4fa4-a4b9-7d565205a5fe",
   "metadata": {},
   "source": [
    "### **Probabilidad de falso positivo y uso de memoria**\n",
    "\n",
    "Este código realiza un **análisis empírico y teórico del comportamiento de un Bloom filter**, evaluando dos aspectos fundamentales:\n",
    "\n",
    "1. La **probabilidad de falso positivo** (teórica vs. empírica).\n",
    "2. El **uso de memoria** en función del número de elementos insertados.\n",
    "\n",
    "\n",
    "Se define una serie de tamaños de carga (`sizes`) desde 0 hasta 5000 elementos, en pasos de 500. Para cada carga se mide:\n",
    "\n",
    "- **FP teórica**: basada en la fórmula matemática del filtro.\n",
    "- **FP empírica**: midiendo cuántos valores *no insertados* son reconocidos erróneamente como presentes.\n",
    "- **Uso de memoria**: en bytes del `bytearray` del filtro.\n",
    "\n",
    "\n",
    "Para cada valor de `n` en `sizes`:\n",
    "\n",
    "1. Se crea un nuevo filtro con capacidad máxima de 5000 y tolerancia de error de 0.01.\n",
    "2. Se insertan `n` elementos únicos (`0, 1, ..., n-1`).\n",
    "3. Se calcula:\n",
    "   - `bf.false_positive_probability()`: estimación teórica.\n",
    "   - `fp_count / test_samples`: estimación empírica sobre `test_samples` enteros aleatorios que no han sido insertados.\n",
    "   - `sys.getsizeof(bf._bits)`: memoria usada por el arreglo de bits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b3235-86de-4b3e-b2ec-389a66fbb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parámetros de barrido\n",
    "max_inserts = 5000\n",
    "step = 500\n",
    "test_samples = 2000  # cuántos valores no insertados probamos para FP\n",
    "sizes = list(range(0, max_inserts + 1, step))\n",
    "\n",
    "# Listas para almacenar resultados\n",
    "fp_theoretical = []\n",
    "fp_empirical  = []\n",
    "mem_usage_bytes = []\n",
    "\n",
    "for n in sizes:\n",
    "    # Crea y rellena el filtro con n elementos\n",
    "    bf = BloomFilter(5000, 0.01, seed=42)\n",
    "    for i in range(n):\n",
    "        bf.add(i)\n",
    "    \n",
    "    # 1) Probabilidad teórica de FP\n",
    "    fp_theoretical.append(bf.false_positive_probability())\n",
    "    \n",
    "    # 2) Medición empírica de FP\n",
    "    fp_count = 0\n",
    "    for _ in range(test_samples):\n",
    "        candidate = random.randint(max_inserts*2, max_inserts*3)\n",
    "        if bf.contains(candidate):\n",
    "            fp_count += 1\n",
    "    fp_empirical.append(fp_count / test_samples)\n",
    "    \n",
    "    # 3) Memoria usada por el array de bits\n",
    "    mem_usage_bytes.append(sys.getsizeof(bf._bits))\n",
    "\n",
    "# Gráfica 1: FP teórica vs empírica\n",
    "plt.figure()\n",
    "plt.plot(sizes, fp_theoretical, label='Teórica')\n",
    "plt.plot(sizes, fp_empirical,  label='Empírica', linestyle='--')\n",
    "plt.xlabel('Número de elementos insertados')\n",
    "plt.ylabel('Probabilidad de falso positivo')\n",
    "plt.title('FP teórica vs FP empírica')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfica 2: Uso de memoria del bitarray\n",
    "plt.figure()\n",
    "plt.plot(sizes, mem_usage_bytes)\n",
    "plt.xlabel('Número de elementos insertados')\n",
    "plt.ylabel('Bytes usados por el bitarray')\n",
    "plt.title('Consumo de memoria según cargas')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93715e4-5ff5-47b1-859b-125227f84e88",
   "metadata": {},
   "source": [
    "La primera gráfica compara la probabilidad **teórica** de falsos positivos frente a la **medida empíricamente**, a medida que se insertan más elementos.\n",
    "\n",
    "- La curva **teórica** (azul sólida) sigue la fórmula:\n",
    "  $$\n",
    "  P_{fp} = \\left(1 - e^{-kn/m}\\right)^k\n",
    "  $$\n",
    "  donde $n$ = número de elementos insertados.\n",
    "- La curva **empírica** (naranja discontinua) se basa en la proporción real de falsos positivos.\n",
    "- Ambas curvas coinciden en general, validando el modelo teórico.\n",
    "- Hacia el final (más carga), la curva empírica tiende a superar levemente la teórica, lo cual es esperado por el efecto de colisiones y límite de capacidad.\n",
    "\n",
    "\n",
    "La segunda gráfica muestra el uso de memoria del arreglo de bits del filtro (`bf._bits`), medido en bytes.\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "- La línea es **horizontal**, constante en todos los puntos.\n",
    "- Esto refleja una propiedad clave de los Bloom filters: **el tamaño del arreglo de bits no crece con el número de elementos insertados**, sino que se fija en el momento de la construcción del filtro.\n",
    "- En este caso, el arreglo tiene aproximadamente 6031 bytes desde el inicio.\n",
    "- El comportamiento no cambia aunque el filtro esté vacío o completamente lleno.\n",
    "\n",
    "Este experimento ilustra claramente dos propiedades fundamentales de los Bloom filters:\n",
    "\n",
    "- **Eficiencia de espacio**: uso de memoria constante y predecible, lo que los hace ideales para aplicaciones con restricciones de memoria.\n",
    "- **Naturaleza probabilística**: los falsos positivos crecen de manera predecible conforme se llena el filtro. La concordancia entre teoría y observación empírica valida su formulación matemática.\n",
    "\n",
    "Este tipo de visualización es crucial para comprender cuándo un Bloom filter comienza a ser menos confiable y para ajustar sus parámetros de diseño (capacidad máxima, tolerancia al error) en sistemas reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27859953-8ae1-4317-b0f0-e36c678b6280",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1. **Análisis de complejidad y eficiencia**  \n",
    "   Justifica matemáticamente por qué un Bloom filter puede considerarse una estructura de datos con tiempo constante $ O(k) $ tanto en inserción como en consulta, e identifica los límites de esta afirmación bajo implementaciones reales (por ejemplo, en entornos con restricciones de memoria caché o compresión).\n",
    "\n",
    "2. **Optimización del número de funciones hash**  \n",
    "   Demuestra a partir de la fórmula de falsos positivos que existe un valor óptimo de $ k $, el número de funciones hash, y deduce la expresión $ k = \\frac{m}{n} \\ln 2 $. ¿Qué implicaría usar más o menos funciones hash que este valor óptimo?\n",
    "\n",
    "3. **Diseño de variantes del Bloom filter**  \n",
    "   Explica cómo se podría diseñar un Counting Bloom Filter para permitir eliminaciones, y analiza su sobrecosto de memoria. Luego, describe un escenario donde esta variante es indispensable.\n",
    "\n",
    "4. **Evaluación del error empírico**  \n",
    "   Suponiendo que insertas 4000 elementos en un Bloom filter con $ m = 48000 $ bits y $ k = 7 $, estima la probabilidad empírica de falso positivo. Luego, diseña un experimento que pueda validar esta estimación con un margen de error del 1%.\n",
    "\n",
    "5. **Hashing y colisiones**  \n",
    "   Describe cómo el uso de funciones hash con poca dispersión puede afectar gravemente la tasa de falsos positivos en Bloom filters. ¿Qué propiedades debe tener una función hash para minimizar este problema?\n",
    "\n",
    "6. **Diseño para sistemas distribuidos**  \n",
    "   Analiza cómo se pueden usar Bloom filters en arquitecturas distribuidas para reducir latencia y tráfico de red. Menciona al menos tres casos reales donde esto tenga impacto en bases de datos o redes.\n",
    "\n",
    "7. **Límites teóricos y físicos**  \n",
    "   Si quisiéramos reducir la tasa de falsos positivos a $10^{-6}$ para almacenar 1 millón de elementos, ¿cuánto espacio en bits se requeriría? ¿Sería práctico usar este filtro en una aplicación en memoria en un sistema embebido?\n",
    "\n",
    "8. **Construcción dinámica**  \n",
    "   Implementa un Scalable Bloom Filter que se expanda automáticamente al superar la capacidad prevista, generando nuevas capas de filtros con tasas de error progresivamente más pequeñas.\n",
    "\n",
    "9. **Medición empírica**  \n",
    "   Diseña un script que compare la tasa de falsos positivos en distintos escenarios (diferentes tamaños de filtro y valores de $ k $) y genera gráficos automáticos para comparar curvas teóricas vs empíricas.\n",
    "\n",
    "10. **Carga y serialización eficiente**  \n",
    "   Implementa funciones para exportar e importar Bloom filter a disco en formato comprimido y serializado, asegurando que el filtro pueda ser restaurado exactamente con su semilla y estado.\n",
    "\n",
    "11. **Análisis de sensibilidad**  \n",
    "   Programa un experimento que mida cómo varía el rendimiento (tiempo de inserción y consulta) cuando se cambia el número de funciones hash $ k $, manteniendo $ m $ y $ n $ fijos.\n",
    "\n",
    "12. **Validación cruzada**  \n",
    "   Crea un conjunto de pruebas unitarias robustas que verifiquen que el filtro:\n",
    "       - No presenta falsos negativos.\n",
    "       - Presenta una tasa de falsos positivos dentro del margen teórico esperado.\n",
    "       - Se comporta igual con elementos serializados en diferente orden (test de `consistent_stringify`).\n",
    "\n",
    "13. **Interfaz tipo set probabilístico**  \n",
    "   Diseña una clase que envuelva un Bloom filter con una API similar a la clase `set` de Python (`add`, `__contains__`, `len`), y que devuelva advertencias si la probabilidad de falso positivo excede cierto umbral.\n",
    "\n",
    "14. **Compresión del bitarray**  \n",
    "   Implementa una técnica de compresión del `bitarray` (como RLE o gzip) para enviar Bloom filters entre nodos en una red, y evalúa cuánto se reduce el tamaño sin perder precisión en falsos positivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3d2c6-d242-476e-b6f6-63871d464603",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
